<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GNN图神经网络详解, JackHCC">
    <meta name="description" content="GNN图神经网络学习实践记录">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>GNN图神经网络详解 | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GNN图神经网络详解</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="container content">

    
    <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/GNN/">
                                <span class="chip bg-color">GNN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-08-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-08-29
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    69 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="图基础与中心指标"><a href="#图基础与中心指标" class="headerlink" title="图基础与中心指标"></a>图基础与中心指标</h2><h3 id="一-基础属性"><a href="#一-基础属性" class="headerlink" title="一.基础属性"></a>一.基础属性</h3><p><strong>基本定义</strong>：节点、边<br><strong>基本类型</strong>：有向图、无向图；加权图，非加权图；连通图，非连通图；连通分量，强连通分量，弱连通分量；二部图<br><strong>邻居，𝑘阶邻居，度</strong><br><strong>子图、𝑘阶子图、路径、图直径</strong><br><strong>表示方式</strong>: 邻接矩阵，关联矩阵<br><strong>遍历方式</strong>：深度优先，广度优先</p>
<pre><code>#构建图
%matplotlib inline
from matplotlib import pyplot as plt
import networkx as nx
G=nx.Graph()#无向图，有向图用DiGraph
G.add_nodes_from(["A","B","C","D","E","F","G","H"])
G.add_edges_from([("A","B"),("A","C"),("B","C"),("C","D"),("E","F"),("F","G"),("G","H")])
nx.draw_networkx(G)
plt.show()</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/image-20210829195032100.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#度</span>
nx<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>DegreeView({'A': 2, 'B': 2, 'C': 3, 'D': 1, 'E': 1, 'F': 2, 'G': 2, 'H': 1})</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#连通分量</span>
list<span class="token punctuation">(</span>nx<span class="token punctuation">.</span>connected_components<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>[{'A', 'B', 'C', 'D'}, {'E', 'F', 'G', 'H'}]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#图直径:所有两两节点直接最短路径的最大值</span>
subG<span class="token operator">=</span>nx<span class="token punctuation">.</span>subgraph<span class="token punctuation">(</span>G<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>diameter<span class="token punctuation">(</span>subG<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>2</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#路径长度</span>
nx<span class="token punctuation">.</span>shortest_path_length<span class="token punctuation">(</span>G<span class="token punctuation">,</span>source<span class="token operator">=</span><span class="token string">"A"</span><span class="token punctuation">,</span>target<span class="token operator">=</span><span class="token string">"D"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>2</code></pre><h3 id="二-中心性指标"><a href="#二-中心性指标" class="headerlink" title="二.中心性指标"></a>二.中心性指标</h3><p>中心性指标主要用于衡量节点在图中的重要性/影响力，我们对节点重要性的解释有很多，不同的解释下判定中心性的指标也有所不同，通常有这些：点度中心性，中介中心性，接近中心性，特征向量中心性，PageRank，hits</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#点度中心性</span>
<span class="token comment" spellcheck="true">#节点的邻居越多，它就越重要，定义为：度/(节点数-1)</span>
nx<span class="token punctuation">.</span>degree_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.2857142857142857,
 'B': 0.2857142857142857,
 'C': 0.42857142857142855,
 'D': 0.14285714285714285,
 'E': 0.14285714285714285,
 'F': 0.2857142857142857,
 'G': 0.2857142857142857,
 'H': 0.14285714285714285}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#中介中心性</span>
<span class="token comment" spellcheck="true">#如果该节点出现该其它两两节点路径上的次数越多，它就越重要</span>
nx<span class="token punctuation">.</span>betweenness_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.0,
 'B': 0.0,
 'C': 0.09523809523809523,
 'D': 0.0,
 'E': 0.0,
 'F': 0.09523809523809523,
 'G': 0.09523809523809523,
 'H': 0.0}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#接近中心性</span>
<span class="token comment" spellcheck="true">#如果该节点与其它节点之间的距离越近，它就越重要</span>
nx<span class="token punctuation">.</span>closeness_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.3214285714285714,
 'B': 0.3214285714285714,
 'C': 0.42857142857142855,
 'D': 0.2571428571428571,
 'E': 0.21428571428571427,
 'F': 0.3214285714285714,
 'G': 0.3214285714285714,
 'H': 0.21428571428571427}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#特征向量中心性</span>
<span class="token comment" spellcheck="true">#定义：取邻接矩阵特征分解后，最大特征值对应的特征向量</span>
<span class="token comment" spellcheck="true">#与某节点连接的节点的邻居越多，就越重要</span>
<span class="token comment" spellcheck="true">#新增加一个节点I来连接两块连通分量</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">,</span><span class="token string">"E"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">,</span><span class="token string">"G"</span><span class="token punctuation">,</span><span class="token string">"H"</span><span class="token punctuation">,</span><span class="token string">"I"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"E"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"F"</span><span class="token punctuation">,</span><span class="token string">"G"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"G"</span><span class="token punctuation">,</span><span class="token string">"H"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"I"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"I"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> &gt;&gt;&gt;<br><img src="/images/loading.gif" data-original="../images/ML/output_10_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python">nx<span class="token punctuation">.</span>eigenvector_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.44885390912200857,
 'B': 0.5468450989996043,
 'C': 0.5135021004101872,
 'D': 0.21736961615213216,
 'E': 0.09799461776528895,
 'F': 0.2314938976977582,
 'G': 0.11938887762076224,
 'H': 0.0505393145300136,
 'I': 0.3294789107351654}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#pagerank</span>
nx<span class="token punctuation">.</span>pagerank<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.10252135128679807,
 'B': 0.14929077894067944,
 'C': 0.153726203840718,
 'D': 0.06022249294537078,
 'E': 0.06475108608528522,
 'F': 0.16971188372812845,
 'G': 0.1235500933464885,
 'H': 0.06917616539981883,
 'I': 0.1070499444267125}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#hits</span>
nx<span class="token punctuation">.</span>hits<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>({'A': 0.17564701604305502,
  'B': 0.21399245433642766,
  'C': 0.2009454874842481,
  'D': 0.08506205753671801,
  'E': 0.03834543957793587,
  'F': 0.09058495722206274,
  'G': 0.04671661924357704,
  'H': 0.019775570471702603,
  'I': 0.1289303980842729},
 {'A': 0.1756470158158291,
  'B': 0.21399245588711766,
  'C': 0.2009454869245228,
  'D': 0.085062057946483,
  'E': 0.03834543855419052,
  'F': 0.09058495938682286,
  'G': 0.04671661787549817,
  'H': 0.01977557118599924,
  'I': 0.1289303964235366})</code></pre><h2 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h2><h3 id="一-DeepWalk原理"><a href="#一-DeepWalk原理" class="headerlink" title="一. DeepWalk原理"></a>一. DeepWalk原理</h3><p>其实就两个阶段：<br>1）对图随机游走得到一个序列；<br>2）将该序列进行word2vec训练得到embedding  </p>
<p>下面利用对word进行embbeding训练举例，我选择了当前的一条关于新冠的新闻，对其分词构建一个带权有向图，权重为其相邻两词的出现的次数</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#准备预料</span>
corpus<span class="token operator">=</span><span class="token triple-quoted-string string">"""新华社河内5月29日电（记者蒋声雄 黄硕）越南卫生部长阮青龙29日宣布该国发现新的新冠病毒变异毒株，它是此前在英国和印度发现的变异毒株的混合体。
阮青龙当天在越南全国新冠疫情防控视频会议上说，这种变异毒株混合体“非常危险”，传播性更强，能在空气中迅速传播。这一新发现的毒株混合体尚未命名。
据“越南快报网”报道，此前在越南已发现7种新冠病毒变异毒株，包括最早在印度和英国发现的变异毒株。
越南于今年4月底出现新一轮新冠疫情，首都河内、南部胡志明市、中部岘港市等主要城市出现多个本土病例，北部北江省某工业园内发生大规模感染新冠病毒事件。据越通社报道，截至当地时间29日12时，越南累计确诊新冠本土病例5213例，其中自4月27日以来新增确诊新冠本土病例3643例"""</span>\
<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"，"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"、"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"（"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"）"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"“"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"”"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"。"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">corpus<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['新华社河内5月29日电记者蒋声雄黄硕越南卫生部长阮青龙29日宣布该国发现新的新冠病毒变异毒株它是此前在英国和印度发现的变异毒株的混合体',
 '阮青龙当天在越南全国新冠疫情防控视频会议上说这种变异毒株混合体非常危险传播性更强能在空气中迅速传播',
 '这一新发现的毒株混合体尚未命名',
 '据越南快报网报道此前在越南已发现7种新冠病毒变异毒株包括最早在印度和英国发现的变异毒株',
 '越南于今年4月底出现新一轮新冠疫情首都河内南部胡志明市中部岘港市等主要城市出现多个本土病例北部北江省某工业园内发生大规模感染新冠病毒事件',
 '据越通社报道截至当地时间29日12时越南累计确诊新冠本土病例5213例其中自4月27日以来新增确诊新冠本土病例3643例']</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> jieba
lines<span class="token operator">=</span><span class="token punctuation">[</span>list<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> corpus<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#分词</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>Building prefix dict from the default dictionary ...
Loading model from cache C:\Users\Alei\AppData\Local\Temp\jieba.cache
Loading model cost 0.619 seconds.
Prefix dict has been built successfully.</code></pre><pre class="line-numbers language-python"><code class="language-python">word_cnt<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
word_set<span class="token operator">=</span>set<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pre_cnt<span class="token operator">=</span>word_cnt<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
        word_cnt<span class="token punctuation">[</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">1</span><span class="token operator">+</span>pre_cnt
        word_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        word_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建图</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>DiGraph<span class="token punctuation">(</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>key<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>key<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key <span class="token keyword">in</span> word_cnt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_5_0.png" alt=""></p>
<h3 id="二-随机游走实现"><a href="#二-随机游走实现" class="headerlink" title="二.随机游走实现"></a>二.随机游走实现</h3><p>随机游走的核心也很简单，大概流程如下：   </p>
<p>1）从图中随机选择一个起始node<br>2）从它的（箭头指向的）邻居中随机选择一个新node<br>3）重复第2）步，直到满足终止条件，上面的所有node组成的序列即是我们所需   </p>
<p>另外，上面的每一步都可以自定义自己的策略，比如第1）步初始点不从图中随机选择，而是从实际句子的初始词中选择，第2）步，随机选择下一个节点时，考虑边的权值，权值越大越容易被选择，第3）步，通常可以设置一个最大游走长度</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">walk_one_time</span><span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">,</span>walk_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    seq<span class="token operator">=</span><span class="token punctuation">[</span>start_node<span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>walk_len<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        current_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#获取seq的最有一个节点</span>
        next_nodes<span class="token operator">=</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>current_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取所有邻居节点</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>next_nodes<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        selected_next_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>next_nodes<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#从所有邻居中随机选择一个</span>
        seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>selected_next_node<span class="token punctuation">)</span>
    <span class="token keyword">return</span> seq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#test</span>
walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span><span class="token string">"变异"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['变异', '毒株', '它', '是', '此前']</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#将上面的过程重复多次，即可得到一个新的corpus</span>
<span class="token keyword">def</span> <span class="token function">deep_walk</span><span class="token punctuation">(</span>G<span class="token punctuation">,</span>walk_len<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>num_seqs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    corpus<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_seqs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>G<span class="token punctuation">.</span>nodes<span class="token punctuation">)</span>
        corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">,</span>walk_len<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> corpus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">new_corpus<span class="token operator">=</span>deep_walk<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
new_corpus<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['包括', '最早', '在', '越南', '快报', '网', '报道', '截至', '当地', '时间']</code></pre><h3 id="三-Word2Vec的训练"><a href="#三-Word2Vec的训练" class="headerlink" title="三.Word2Vec的训练"></a>三.Word2Vec的训练</h3><p>word2vec的训练可以使用gensim工具包，word2vec的原理包括两点：    </p>
<p>1）基于语言模型的原理，语言模型的作用用于判断一个句子出现的概率，由于句子通常会被分词，所有语言模型可以看作判断一个词语序列的出现概率，好的语言模型应该能做到比如如下的判断：   </p>
<p>$$<br>Proba([[变异],[毒株],[混合体],[非常],[危险]])&gt;Proba([[变异],[危险],[混合体],[非常],[毒株]])<br>$$</p>
<p>显然，第一句是人话，第二句读不通  </p>
<p>2）而word2vec就是利用极大似然估计的方式让我们的人话出现的概率尽可能高，而鬼话的概率尽可能小，它采用三层的网络结构，  </p>
<blockquote>
<p>2.1）第一层是input层，它与我们的词典一一对应   </p>
</blockquote>
<blockquote>
<p>2.2）中间层是hidden层，它就是我们embedding的维度    </p>
</blockquote>
<blockquote>
<p>2.3）最后一层是output层，它同样与我们的词典一一对应  </p>
</blockquote>
<p>它的训练如下图，  </p>
<blockquote>
<p>1）我们对输入的文本截取一定的窗口，比如window_size=2，那么我们选取目标次前后的2X2+1=5个词语，比如[[变异],[毒株],[混合体],[非常],[危险]]这5个词语  </p>
</blockquote>
<blockquote>
<p>2）然后，我们构建([变异],[毒株],[非常],[危险])-&gt;([混合体])的映射，其中前半部分，我们称作[混合体]的上下文   </p>
</blockquote>
<blockquote>
<p>3）最后，我们利用极大似然估计估计上面的上下文和目标词的映射概率尽可能的大</p>
</blockquote>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200204048.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec
model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>new_corpus<span class="token punctuation">,</span>window<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>vector_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看embedding</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">"变异"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([-0.19377613,  0.10809163, -0.16566691, -0.09616406,  0.00191299],
      dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">"混合体"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([ 0.15368475, -0.18145339,  0.00444265,  0.05817473, -0.01261494],
      dtype=float32)</code></pre><p>这样，我们就为图上的每个节点训练出了一个embedding，另外上面的训练过程实际是采用了CBOW的方式，即用上下文来预测某个词，而实际deepwalk更多是使用<strong>skip-gram</strong>的方式，即利用单个词去预测它的上下文（上面图中的箭头反向），这样训练的embedding效果通常会更好</p>
<h3 id="四-Node2Vec原理"><a href="#四-Node2Vec原理" class="headerlink" title="四.Node2Vec原理"></a>四.Node2Vec原理</h3><p>Node2vec其实是对于DeepWalk中第2)步，随机游走方式的调整，以学习到图结构的同质性和结构性信息。这里：  </p>
<p>1）同质性是指相邻两节点之间应该具有较高的相似度；    </p>
<p>2）结构性是指邻居结构相似的两节点之间应该具有较高的相似度，即使这两节点之间没有路径连接    </p>
<p>如下图，u与s1,s2,s3,s4之间在同质性上应该具有较高的相似度，而u与s6在结构性上应该具有较高相似度<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200439020.png" alt=""></p>
<p>那如何游走才能提现同质性和结构性呢，这其实可以利用我们常见的图搜索算法，深度优先搜索(DFS)和广度优先搜索(BFS):   </p>
<p>1)DFS:深度优先搜索，在相俩节点间游走，倾向于获取同质性信息；   </p>
<p>2)BFS:广度优先搜索，优先获取节点周围邻居序列，倾向于获取结构性信息；    </p>
<p>具体的游走方式如下<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200449990.png" alt=""></p>
<p>已知，当前序列的最后两节点为[t,v]，即最后一步游走为t-&gt;v，那么接下的游走方式满足如下公式：<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200501619.png" alt=""><br>下面直观解释一下这三种情况：   </p>
<blockquote>
<p>(1) $d_{tx}=0$，表示$t$节点与$x$节点距离为0，所以它们是同一节点，言外之意是说从$v$节点又跳回了前节点$t$，它的跳转概率定义为$\frac{1}{p}$<br>(2) $d_{tx}=1$，表示既与$t$相连，又与$v$相连的节点，如图中的$x_1$，它的跳转概率定义为1<br>(3) $d_{tx}=2$，即图中的$x_2,x_3$节点，它们的跳转概率被定义为$\frac{1}{q}$  </p>
</blockquote>
<p>注意，上面的“概率”都未归一化，最终需要进行归一化操作，另外node2vec还需要考虑边的权重$w_{vx}$，所以它实际是对$\pi_{vx}=\alpha_{pq}(t,x)\cdot w_{vx}$进行归一化，下面对超参数$p,q$进行讨论；   </p>
<blockquote>
<p>对于p：如果$p&gt;max(q,1)$,那么采样倾向于不会往回走，而如何$p&lt;min(q,1)$，采样倾向于返回上一个节点，在初始点周围游走  </p>
</blockquote>
<blockquote>
<p>对于q: 如果$q&gt;1$，采样点倾向于在起始点周围游走做BFS采样，而如果$q&lt;1$，倾向于远离起始点，做DFS采样   </p>
</blockquote>
<h3 id="五-实现"><a href="#五-实现" class="headerlink" title="五.实现"></a>五.实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建图</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>DiGraph<span class="token punctuation">(</span><span class="token punctuation">)</span>
edges<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span><span class="token string">"s3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token punctuation">(</span><span class="token string">"s2"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s5"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s4"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s9"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token punctuation">(</span><span class="token string">"s5"</span><span class="token punctuation">,</span><span class="token string">"s7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s7"</span><span class="token punctuation">,</span><span class="token string">"s8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s8"</span><span class="token punctuation">,</span><span class="token string">"s9"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">(</span>edge<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>edge<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> edge <span class="token keyword">in</span> edges<span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_1_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">class</span> <span class="token class-name">Node2Vec</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>walk_len<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>num_seqs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>q<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>walk_len<span class="token operator">=</span>walk_len
        self<span class="token punctuation">.</span>num_seqs<span class="token operator">=</span>num_seqs
        self<span class="token punctuation">.</span>p<span class="token operator">=</span>p
        self<span class="token punctuation">.</span>q<span class="token operator">=</span>q
    <span class="token keyword">def</span> <span class="token function">walk_one_time</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#添加第二个点</span>
        second_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>start_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        seq<span class="token operator">=</span><span class="token punctuation">[</span>start_node<span class="token punctuation">,</span>second_node<span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>walk_len<span class="token number">-2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            t_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
            v_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            next_nodes<span class="token operator">=</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>v_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取所有邻居节点</span>
            proba<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#记录概率</span>
            <span class="token keyword">for</span> next_node <span class="token keyword">in</span> next_nodes<span class="token punctuation">:</span>
                path_len<span class="token operator">=</span>nx<span class="token punctuation">.</span>shortest_path_length<span class="token punctuation">(</span>G<span class="token punctuation">,</span>source<span class="token operator">=</span>t_node<span class="token punctuation">,</span>target<span class="token operator">=</span>next_node<span class="token punctuation">)</span>
                <span class="token keyword">if</span> path_len<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>self<span class="token punctuation">.</span>p<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> path_len<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>self<span class="token punctuation">.</span>q<span class="token punctuation">)</span>
            proba<span class="token operator">=</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>proba<span class="token punctuation">)</span>
            proba<span class="token operator">=</span>proba<span class="token operator">/</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>proba<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#归一化</span>
            selected_next_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>next_nodes<span class="token punctuation">,</span>p<span class="token operator">=</span>proba<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#从所有邻居中随机选择一个</span>
            seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>selected_next_node<span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq
    <span class="token keyword">def</span> <span class="token function">deep_walk</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>G<span class="token punctuation">)</span><span class="token punctuation">:</span>
        corpus<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_seqs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            start_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>G<span class="token punctuation">.</span>nodes<span class="token punctuation">)</span>
            corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> corpus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">node2vec<span class="token operator">=</span>Node2Vec<span class="token punctuation">(</span>q<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
corpus<span class="token operator">=</span>node2vec<span class="token punctuation">.</span>deep_walk<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">corpus<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>[['s1', 'u', 's3', 's4', 's2', 'u', 's1', 's3', 'u', 's1']]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#训练</span>
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec
model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span>window<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>vector_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看embedding</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">'u'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([-0.14191031,  0.13018166,  0.1809364 , -0.10049632, -0.07593277],
      dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#计算相似度</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>0.07862966</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>0.6219288</code></pre><h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><h3 id="GCN原理"><a href="#GCN原理" class="headerlink" title="GCN原理"></a>GCN原理</h3><p><strong>1.1  问题1：</strong> 先看一个例子，假如我们有如下的5个用户，他们编号为0~4，且知道他们的关系如下，假如我们现在面对的是车险反欺诈的预测场景，已知编号1，2的为欺诈客户（正样本），编号4的为正常客户（负样本），现在要我们预测剩下的编号0，3的客户是欺诈客户还是正常客户？该怎么办呢？<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200722942.png" alt=""></p>
<p>我想基于前三节的内容至少可以有两个思路：   </p>
<p>（1）基于度指标：计算当前节点的邻居节点中欺诈客户的占比，那么0号客户周围1/1的客户都是欺诈客户，所以他也是欺诈客户，而客户3周围有2/3的客户都是欺诈客户，所以他也是欺诈客户<br>（2）基于Graph Embedding：基于DeepWalk或者Node2Vec的方式为每个用户学习一个Embedding，然后计算它与邻居Embedding的相似度，然后统计累计相似度占比最高的标签为当前节点的标签，或者直接将这些Embedding送到一个分类器进行训练    </p>
<p><strong>1.2 问题2：</strong> 而我们在处理实际数据时，可能并不仅仅只有他们之间的关系数据，还会有他们各自的因子数据，比如年龄，最近半年的贷款额，最近一月的消费额度这三项，我们将其加到图中（已经归一化处理）   </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200734312.png" alt=""></p>
<p>那现在如何处理？以往我们可能会只利用他们的因子数据来构建分类模型，比如使用lgbm对这三维度的因子建模预测，但这样又少了结构信息；那如果只利用了上面的结构信息建模又少了因子数据（当然你也可以尝试将Embedding+因子结合起来），那有没有办法同时利用结构信息和因子信息呢？这可以从CNN的卷积操作进行借鉴   </p>
<p><strong>1.3 更一般的认识CNN:</strong> 让我们重新理解一下CNN中卷积操作，</p>
<blockquote>
<p>1) 卷积操作本质上是将某视野域内的像素点数据进行加权聚合，如下图左边将红色区块附近的8个绿块数据加权聚合到红块中（通常会包含红块自身的数据）；<br>2) 那如果我们将这些像素点强行拉开呢？这中间的图不就是一个图结构了吗？（而且现在的边时带权重的，它的权重就对应了卷积块上的数值）；<br>3) 那如果我们再将中图中的某些边切掉，那不就是更一般的图结构了</p>
</blockquote>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200751451.png" alt=""></p>
<p>所以，我们完全可以利用CNN的方式来处理GNN：<strong>将周围邻居的信息加权聚合到中心节点</strong>，这便是GCN的基本思路了：   </p>
<p>1）节点上的信息就是我们的因子，比如上面的年龄，最近半年的贷款额，最近一月的消费额…<br>2）而对邻居的加权聚合便是对于结构信息的处理…   </p>
<p>如此这样，就能同时利用节点的因子信息和结构信息了，下面介绍GCN的详细推导   </p>
<p><strong>1.4 GCN推导</strong>   </p>
<p><strong>结构上</strong>：   </p>
<p>与CNN类似，当前节点的更新信息由当前节点的信息和周围邻居信息累加得到，对于图结构而言，我们需要为每个节点添加一个自连接<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200807156.png" alt=""></p>
<p>比如对于节点1，它的更新后的信息就是：   </p>
<p>$$<br>[0.4,0.2,0.7]+[0.2,0.3,0.5]+[0.3,0.3,0.5]+[0.4,0.2,0.3]=[1.3,1.0,2.0]<br>$$</p>
<p>再比如，对于节点4，它的更新后的信息就是：   </p>
<p>$$<br>[0.2,0.4,0.3]+[0.4,0.2,0.3]=[0.6,0.6,0.6]<br>$$</p>
<p>想必，你也发现问题了，对于邻居很多的节点，聚合后的数值会比其它邻居少的节点大很多，所以我们需要进行归一化，GCN是采用的归一化方式如下，对于节点$v_i,v_j$，它们的度为$d(v_i),d(v_j)$，聚合信息时，会在它们前面乘以一个权重，即度的乘积的平方根的倒数：    </p>
<p>$$<br>\frac{1}{\sqrt{d(v_i)}\cdot \sqrt{d(v_j)}}<br>$$</p>
<p>所以，这时对于节点1的更新就是：   </p>
<p>$$<br>\frac{1}{4}[0.4,0.2,0.7]+\frac{1}{2\sqrt{2}}[0.2,0.3,0.5]+\frac{1}{2\sqrt{3}}[0.3,0.3,0.5]+\frac{1}{2\sqrt{3}}[0.4,0.2,0.3]<br>$$</p>
<p>上面的更新操作，可以对$X$左乘一个矩阵来进行计算：   </p>
<p>$$<br>\tilde{L}_{sym}X<br>$$</p>
<p>这里的$X$就是我们的因子数据，第$i$行就是第$i$个因子的向量表示，比如$X_{0,:}=[0.2,0.3,0.5]$，而   </p>
<p>$$<br>\tilde{L}<em>{sym}=\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2},\tilde{A}=A+I,\tilde{D</em>{ii}}=\sum_j\tilde{A}_{ij}<br>$$</p>
<p>这里的$A$是连接矩阵，$I$是单位矩阵，所以$\tilde{A}X$，就是添加了自连接且没加权的聚合表示，即最上面的表示，如节点1的聚合   </p>
<p>$$<br>[0.4,0.2,0.7]+[0.2,0.3,0.5]+[0.3,0.3,0.5]+[0.4,0.2,0.3]=[1.3,1.0,2.0]<br>$$</p>
<p>而$\tilde{D}$是$\tilde{A}$的度矩阵，它只有对角线上有值，$\tilde{D}_{ii}$的值就是$\tilde{A}$的第$i$行求和，所以$\tilde{A}$矩阵前后分别乘一个$\tilde{D}^{-1/2}$相等于乘以了上文介绍的权重$\frac{1}{\sqrt{d(v_i)}\cdot \sqrt{d(v_j)}}$</p>
<p><strong>因子上：</strong>    </p>
<p>可以发现$\tilde{L}<em>{sym}X$中的$\tilde{L}</em>{sym}$和$X$都是已知的，GCN希望增强模型的表达能力，所以对于$\tilde{L}_{sym}X$在特征上再做了一次线性变换，等价于右乘一个变量矩阵$W$，为了进一步增强表达能力，通常还会对结果进行一个非线性变换$\sigma$，所以最终的更新公式如下：   </p>
<p>$$<br>X’=\sigma(\tilde{L}_{sym}XW)<br>$$</p>
<p>需要注意的是，$W$是对每一层的所有节点共享的，这里可以将其类比为CNN中的卷积核系数   </p>
<p><strong>如何训练？</strong>  </p>
<p>这就和其它ML的任务一样的，构造一个损失函数$loss(X’,Y)$，然后基于梯度，更新参数$W$即可，比如($\eta$为学习率)：</p>
<p>$$<br>W\leftarrow W-\eta\frac{\partial loss(X’,Y)}{\partial W}<br>$$</p>
<h3 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h3><p>下面仅演示代码的核心部分   </p>
<p><strong>2.1 加载数据并构建$\tilde{L}_{sym}$</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gcn <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl
Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl</code></pre><p><strong>链接矩阵</strong>：表示文章之间的引用关系，这里是稀疏矩阵的格式</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>adjacency<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;2708x2708 sparse matrix of type '&lt;class 'numpy.float32'&gt;'
    with 10556 stored elements in COOrdinate format&gt;</code></pre><p><strong>因子信息</strong>：2708X1433的矩阵，即2708篇文章的BOW表示</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       ...,
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)</code></pre><p><strong>标签信息</strong>：2708X1，分别标记了2708篇文章的7种类别</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([3, 4, 4, ..., 3, 3, 3], dtype=int64)</code></pre><p><strong>构建$\tilde{L}_{sym}$的代码</strong>：  </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">normalization</span><span class="token punctuation">(</span>adjacency<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算 L=D^-0.5 * (A+I) * D^-0.5"""</span>
    adjacency <span class="token operator">+=</span> sp<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>adjacency<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 增加自连接</span>
    degree <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>adjacency<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d_hat <span class="token operator">=</span> sp<span class="token punctuation">.</span>diags<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>degree<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> d_hat<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>adjacency<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>d_hat<span class="token punctuation">)</span><span class="token punctuation">.</span>tocoo<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#如果有GPU则使用GPU</span>
device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
<span class="token comment" spellcheck="true">#接着预处理剩下的数据</span>
x <span class="token operator">=</span> dataset<span class="token punctuation">.</span>x <span class="token operator">/</span> dataset<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>trn_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>val_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
normalize_adjacency <span class="token operator">=</span> normalization<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>adjacency<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 规范化邻接矩阵</span>
indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>normalize_adjacency<span class="token punctuation">.</span>row<span class="token punctuation">,</span> normalize_adjacency<span class="token punctuation">.</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>
values <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>normalize_adjacency<span class="token punctuation">.</span>data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_adjacency <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>indices<span class="token punctuation">,</span> values<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">2708</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2.2 构建模型</strong>  </p>
<p>这部分代码拆分为了两块，   </p>
<p>1）第一块是对单次图卷积的操作，对应上面的公式：$X’=\sigma(\tilde{L}_{sym}XW)$，代码如下(这里并没有实现激活函数的功能)：   </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphConvolution</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""图卷积
        input_dim: 节点输入特征的维度
        output_dim: 输出特征维度 
        use_bias : bool, optional"""</span>
        super<span class="token punctuation">(</span>GraphConvolution<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>use_bias <span class="token operator">=</span> use_bias
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reset_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adjacency<span class="token punctuation">,</span> input_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        adjacency: 经过上面归一化后的链接矩阵，即\tilde{L}_{sym}
        input_feature:输入特征，即X """</span>
        support <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>input_feature<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> support<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            output <span class="token operator">+=</span> self<span class="token punctuation">.</span>bias
        <span class="token keyword">return</span> output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2）第二块代码叠加了两层图卷积，第一层将1433维的BOW降低到16维，第二层将16维降低到7维，对应到我们的类别数   </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GCNNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 定义一个包含两层GraphConvolution的模型 """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">1433</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCNNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gcn1 <span class="token operator">=</span> GraphConvolution<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gcn2 <span class="token operator">=</span> GraphConvolution<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adjacency<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gcn1<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">)</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>gcn2<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建模型</span>
model <span class="token operator">=</span> GCNNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><strong>2.3 训练模型</strong>  </p>
<p>主要包括：<br>1）损失函数定义<br>2）优化器定义<br>3）训练过程：  &lt;1&gt;前向得到loss ； &lt;2&gt;loss反向更新参数</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 超参数定义</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">200</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_adjacency<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2.4 预测并查看效果</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># tsne降维，查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span>category<span class="token operator">=</span>DeprecationWarning<span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token comment" spellcheck="true">#对X用tsne降维</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>tensor_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#预测</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_adjacency<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#归一化显示</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_18_0.png" alt=""></p>
<h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><h3 id="GraphSAGE原理"><a href="#GraphSAGE原理" class="headerlink" title="GraphSAGE原理"></a>GraphSAGE原理</h3><p>GraphSAGE是对GCN的优化，其中SAGE是sample和aggreage的缩写，从名称我们也可以看出它主要优化的两个方向：即采样和聚合   </p>
<h4 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h4><p>GCN的训练需要图的全局信息（连接矩阵$\tilde{L}_{sym}$），对于太大的图，可能没有足够的内存或者显存进行训练，借鉴DNN中常用的批量训练方式，GCN也可以利用采样来进行训练，它的采样主要关注两方面：1）<strong>采样训练节点</strong>：由于GCN每增加一层，节点所利用到的邻居信息就要往外扩展一层，所以对于$k$层的GCN网络，我们需要每个训练节点的$k$阶子图样本；2）<strong>采样邻居节点</strong>：另外，由于某些超级节点（度特别大的节点，比如平均度为10的图，某些节点的度可能会有100W）存在，也有造成OOM的风险，对于$k$阶子图的规模也要进行控制，这可以通过限制每层邻居节点数量来控制，如下图第一层采样了3个节点，第二层采样了2个节点（有放回采样）<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201055183.png" alt=""></p>
<h4 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h4><p>这一部分其实都是借鉴的DNN中的常见操作，比如取平均/求和/池化等等，这里可以自己设计，需要满足两点：1）不对不同的邻居数量，需要有相同维度的输出，比如$|Agg(v_1,v_2,v_3)|=|Agg(v_1,v_2)|$（$|\cdot|$表示维度）；2）平移不变性，对于不同的输入顺序需要有相同的输出，比如$|Agg(v_1,v_2)=Agg(v_2,v_1)|$，接下来再利用上面的例子演示一下聚合过程：  </p>
<blockquote>
<p>（1）首先将训练节点周围的3个邻居信息聚合，得到图1；<br>（2）然后再将3个邻居的邻居信息聚合到邻居，得到图2，这时第一层GCN就结束了；<br>（3）最后，再次将3个邻居信息聚合到训练节点，得到图3，第二层GCN结束。   </p>
</blockquote>
<p>其中，淡蓝色的点，表示该次操作后不再被需要的点，粉红的点表示采样点，红色和橘黄色分别表示第一轮GCN和第二轮GCN聚合后的点，红色有向边表示第一层的GCN聚合，橘黄色有向边表示第二层的GCN聚合，无向边表示不操作<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201123170.png" alt=""></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.准备数据</span>
<span class="token keyword">from</span> code<span class="token punctuation">.</span>graph_sage <span class="token keyword">import</span> <span class="token operator">*</span>
data <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data
x <span class="token operator">=</span> data<span class="token punctuation">.</span>x <span class="token operator">/</span> data<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
train_index <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
train_label <span class="token operator">=</span> data<span class="token punctuation">.</span>y
test_index <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using Cached file: E:\datas\Algs\GNN\cora\ch7_cached.pkl</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.训练模型</span>
INPUT_DIM <span class="token operator">=</span> <span class="token number">1433</span>  <span class="token comment" spellcheck="true"># 输入维度</span>
<span class="token comment" spellcheck="true"># Note: 采样的邻居阶数需要与GCN的层数保持一致</span>
HIDDEN_DIM <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 隐藏单元节点数</span>
NUM_NEIGHBORS_LIST <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 每阶采样邻居的节点数</span>
BTACH_SIZE <span class="token operator">=</span> <span class="token number">16</span>  <span class="token comment" spellcheck="true"># 批处理大小</span>
EPOCHS <span class="token operator">=</span> <span class="token number">100</span>
NUM_BATCH_PER_EPOCH <span class="token operator">=</span> <span class="token number">20</span>  <span class="token comment" spellcheck="true"># 每个epoch循环的批次数</span>
LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.01</span>  <span class="token comment" spellcheck="true"># 学习率</span>
DEVICE <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
model <span class="token operator">=</span> GraphSage<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>INPUT_DIM<span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span>HIDDEN_DIM<span class="token punctuation">,</span>
                      num_neighbors_list<span class="token operator">=</span>NUM_NEIGHBORS_LIST<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>GraphSage(
  in_features=1433, num_neighbors_list=[10, 10]
  (gcn): ModuleList(
    (0): SageGCN(
      in_features=1433, out_features=64, aggr_hidden_method=sum
      (aggregator): NeighborAggregator(in_features=1433, out_features=64, aggr_method=mean)
    )
    (1): SageGCN(
      in_features=64, out_features=7, aggr_hidden_method=sum
      (aggregator): NeighborAggregator(in_features=64, out_features=7, aggr_method=mean)
    )
  )
)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> e <span class="token keyword">in</span> range<span class="token punctuation">(</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> range<span class="token punctuation">(</span>NUM_BATCH_PER_EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_src_index <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_index<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>BTACH_SIZE<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        batch_src_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_label<span class="token punctuation">[</span>batch_src_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        batch_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>batch_src_index<span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
        batch_sampling_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> batch_sampling_result<span class="token punctuation">]</span>
        batch_train_logits <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_sampling_x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>batch_train_logits<span class="token punctuation">,</span> batch_src_label<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
<span class="token comment" spellcheck="true">#         print("Epoch {:03d} Batch {:03d} Loss: {:.4f}".format(e, batch, loss.item()))</span>
    <span class="token comment" spellcheck="true"># test</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>test_index<span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
        test_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> test_sampling_result<span class="token punctuation">]</span>
        test_logits <span class="token operator">=</span> model<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
        test_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>test_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        predict_y <span class="token operator">=</span> test_logits<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        accuarcy <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> test_label<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#         print("Test Accuracy: ", accuarcy)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
total_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>list<span class="token punctuation">(</span>range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
total_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> total_sampling_result<span class="token punctuation">]</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>total_x<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 归一化</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_5_0-16302390215222.png" alt=""></p>
<h2 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h2><h3 id="GAT原理"><a href="#GAT原理" class="headerlink" title="GAT原理"></a>GAT原理</h3><p><strong>1.Attention是什么？</strong>   </p>
<p>GAT是Graph Attention Networks的简称，即图注意力网络，借鉴于DNN的发展，将Attention应用于图网络是很自然的想法，在原始的GCN中，我们对俩节点$v_i,v_j$聚合时，会设置它们的权重为：<br>$$<br>w_{ij}=\frac{1}{\sqrt{d(v_i)}\sqrt{d(v_j)}}<br>$$</p>
<p>而Attention机制认为，这个权重应该由算法自己去学习，而不是显示的指定，所以在Attention机制下，权重可以被定义为如下表达：   </p>
<p>$$<br>w_{i,j}=Attention(h_i,h_j,W)<br>$$</p>
<p>这里，$h_i,h_j$分别为$v_i,v_j$在当前层的向量表示，$W$是待学习参数，$Attention(h_i,h_j,W)$输出一个标量值，所以任意满足上面定义的表达式都可以看作是一种Attention，最简单的就是$h_i,h_j$向量做内积：$&lt;h_i,h_j&gt;$    </p>
<p><strong>2. GAT中的Attention</strong>  </p>
<p>它的定义可以表示如下：   </p>
<p>$$<br>e_{ij}=LeakyReLU(a^T[Wh_i||Wh_j])\<br>w_{ij}=\frac{exp(e_{ij})}{\sum_{k\in N(v_i)exp(e_{ik})}}<br>$$</p>
<p>首先，$h_i,h_j$通过矩阵$W$进行一次线性变换，然后通过$||$操作符将俩向量拼接成一个向量，接下来与一个同维度向量$a$做内积，最后通过非线性激活函数$LeakyReLU$得到一个标量$e_{ij}$，然后对其进行softmax归一化得到最终的权重值，按照加权求和的思路，节点$v_i$的新特征向量为：   </p>
<p>$$<br>h’<em>i=\sigma(\sum</em>{j\in N(v_i)}w_{ij}Wh_j)<br>$$</p>
<p>通常我们会将单个attention过程，独立做多次（不同的$W,a$），然后将最终得到的多个新特征向量拼接起来（多头注意力）作为最终的新特征向量</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gat <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data
<span class="token comment" spellcheck="true">#如果有GPU则使用GPU</span>
device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
<span class="token comment" spellcheck="true">#接着预处理剩下的数据</span>
x <span class="token operator">=</span> dataset<span class="token punctuation">.</span>x <span class="token operator">/</span> dataset<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>trn_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>val_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
normalize_adjacency <span class="token operator">=</span> dataset<span class="token punctuation">.</span>adjacency
<span class="token comment" spellcheck="true"># 规范化邻接矩阵</span>
indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>normalize_adjacency<span class="token punctuation">.</span>row<span class="token punctuation">,</span> normalize_adjacency<span class="token punctuation">.</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>
values <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>normalize_adjacency<span class="token punctuation">.</span>data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_adjacency <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>indices<span class="token punctuation">,</span> values<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">2708</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl
Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.构建模型</span>
model <span class="token operator">=</span> GAT<span class="token punctuation">(</span><span class="token number">1433</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练模型</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_x<span class="token punctuation">,</span>tensor_adjacency<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span>category<span class="token operator">=</span>DeprecationWarning<span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token comment" spellcheck="true">#对X用tsne降维</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>tensor_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#预测</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_x<span class="token punctuation">,</span>tensor_adjacency<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#归一化显示</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_6_0.png" alt=""></p>
<h2 id="DGL"><a href="#DGL" class="headerlink" title="DGL"></a>DGL</h2><h3 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h3><p>为了更加高效的运行GNN，我们可以利用一些高效的图计算框架帮助我们训练模型，DGL（Deep Graph Library）便是一种比较方便的框架，它将所有的图计算过程拆分为了三个基本部分，分别介绍如下：   </p>
<p><strong>1.1 消息传递函数</strong><br>该函数是将一条边以及与其关联的两个节点的信息进行聚合，然后将聚合后<strong>消息</strong>重新赋值到边上，可以用如下的表达式抽象表达：   </p>
<p>$$<br>m_{uv}^{(t+1)}=\phi(x_u^{(t)},x_v^{(t)},w_{uv}^{(t)})<br>$$</p>
<p>其中，$w_{uv}^{(t)}$表示边$(u,v)$上的特征，$x_u^{(t)}$表示节点$u$上的特征，$x_v^{(t)}$表示节点$v$上的特征  </p>
<p><strong>1.2 聚合函数</strong><br>聚合函数是将与训练节点关联的边上的消息，进行聚合：    </p>
<p>$$<br>\rho_u^{t+1}=\rho({m_{uk}^{(t+1)}\mid k\in N(u)})<br>$$</p>
<p>这里，$N(u)$表示与节点$u$相连的邻居节点   </p>
<p><strong>1.3 更新函数</strong><br>更新函数的作用是将聚合特征与节点的旧特征进行聚合，然后生成节点的新特征：   </p>
<p>$$<br>x_u^{(t+1)}=\varphi(x_u^{(t)},\rho_u^{t+1})<br>$$</p>
<p>我们之前介绍的GCN，GAT，GraphSAGE便可分解为这三个基本操作函数，接下来我利用DGL库演示一下这3个基本操作</p>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p><strong>2.1 构图</strong>：首先构建一张图，并为节点和边赋值</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><pre class="line-numbers language-python"><code class="language-python">u<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
g<span class="token operator">=</span>dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#转换为networkx可视化</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g<span class="token punctuation">.</span>to_networkx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_4_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#分别为节点和边赋值一个三维的向量</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>g<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"ex"</span><span class="token punctuation">]</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>g<span class="token punctuation">.</span>num_edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"ex"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>(tensor([[ 0.6239,  0.3987, -0.6238],
         [-0.7141, -1.0818, -1.0757],
         [-0.0540,  1.1078,  0.2700],
         [ 0.5681, -1.0023, -1.4963],
         [-1.3526, -0.5072,  0.3111],
         [ 0.4039,  0.1909,  2.4836],
         [ 0.2190,  0.9467, -0.6446],
         [-0.5860, -1.7527, -1.0872],
         [ 0.8450,  0.9458, -0.5495],
         [ 1.3140,  0.4514,  0.5442]]),
 tensor([[-0.5180, -0.1497,  0.4278],
         [ 0.7970, -0.1222, -0.5810],
         [-0.9885,  0.7971, -1.0056],
         [-0.5377,  0.3229, -0.1410],
         [ 1.2062,  1.3272, -0.4768],
         [-0.6856,  0.9685, -1.3733],
         [ 1.0140, -0.1059,  1.4300],
         [-0.4088,  0.5824, -0.4151],
         [ 1.4490, -1.0892,  0.2116],
         [ 0.2986, -0.0652, -0.4363],
         [ 0.7020,  0.6645, -1.1004],
         [ 0.7326,  0.5491,  0.8222],
         [-0.5815, -1.3774,  0.7640],
         [ 1.1323, -1.4232,  0.2073],
         [-0.3632, -1.3108, -1.2507],
         [-0.7597, -1.1140,  0.2626],
         [-0.8476, -1.2887, -0.7922]]))</code></pre><p><strong>2.2 利用apply_edges进行消息传递</strong>  </p>
<p>apply_edges可以完成第一个函数的操作，即将两节点特征和边特征进行某种操作，然后将结果保存回边上，我们先用dgl自带的api，将$u,v$节点的特征相加然后赋值到边上</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第一个nx表示u上的nx特征，第二个表示v上的nx特征，add_x表示赋值到边上的特征</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"add_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[-0.0902, -0.6831, -1.6995],        [ 0.5699,  1.5065, -0.3538],        [ 1.1919, -0.6036, -2.1202],        [-0.7288, -0.1085, -0.3128],        [-0.7681,  0.0260, -0.8057],        [-0.1461, -2.0841, -2.5721],        [-1.4066,  0.6007,  0.5811],        [-0.7846, -1.5095, -1.1853],        [ 0.3500,  1.2987,  2.7536],        [-0.9487, -0.3163,  2.7946],        [ 0.6229,  1.1375,  1.8389],        [-0.1821, -1.5618,  1.3964],        [-0.3670, -0.8060, -1.7318],        [ 1.0640,  1.8925, -1.1941],        [ 1.5330,  1.3981, -0.1005],        [ 0.2589, -0.8069, -1.6367],        [ 2.1590,  1.3972, -0.0053]])</code></pre><p>这个过程也可以写自定义函数进行操作</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'new_add_x'</span><span class="token punctuation">:</span> edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'nx'</span><span class="token punctuation">]</span> <span class="token operator">+</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'nx'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>message_func<span class="token punctuation">)</span>g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"new_add_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[-0.0902, -0.6831, -1.6995],        [ 0.5699,  1.5065, -0.3538],        [ 1.1919, -0.6036, -2.1202],        [-0.7288, -0.1085, -0.3128],        [-0.7681,  0.0260, -0.8057],        [-0.1461, -2.0841, -2.5721],        [-1.4066,  0.6007,  0.5811],        [-0.7846, -1.5095, -1.1853],        [ 0.3500,  1.2987,  2.7536],        [-0.9487, -0.3163,  2.7946],        [ 0.6229,  1.1375,  1.8389],        [-0.1821, -1.5618,  1.3964],        [-0.3670, -0.8060, -1.7318],        [ 1.0640,  1.8925, -1.1941],        [ 1.5330,  1.3981, -0.1005],        [ 0.2589, -0.8069, -1.6367],        [ 2.1590,  1.3972, -0.0053]])</code></pre><p><strong>2.3 利用update_all组合消息传递函数与聚合函数</strong>  </p>
<p>update_all将消息传递和聚合函数一并进行操作，下面演示先将邻居节点特征加到边，然后再将边特征加到节点</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"add_x"</span><span class="token punctuation">,</span><span class="token string">"add_edge_x"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"add_edge_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.0000,  0.0000,  0.0000],        [-0.0902, -0.6831, -1.6995],        [-0.1982,  1.5326, -1.1595],        [ 1.0459, -2.6876, -4.6922],        [-2.9200, -1.0173, -0.9170],        [-0.5987,  0.9824,  5.5482],        [ 0.6229,  1.1375,  1.8389],        [-0.5491, -2.3679, -0.3355],        [ 1.3229,  1.0856, -2.8309],        [ 3.6919,  2.7953, -0.1058]])</code></pre><p>当然，也可以自定义</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">reduce_func</span><span class="token punctuation">(</span>nodes<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'new_add_edge_x'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>nodes<span class="token punctuation">.</span>mailbox<span class="token punctuation">[</span><span class="token string">'add_x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             reduce_func<span class="token punctuation">)</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"new_add_edge_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.0000,  0.0000,  0.0000],        [-0.0902, -0.6831, -1.6995],        [-0.1982,  1.5326, -1.1595],        [ 1.0459, -2.6876, -4.6922],        [-2.9200, -1.0173, -0.9170],        [-0.5987,  0.9824,  5.5482],        [ 0.6229,  1.1375,  1.8389],        [-0.5491, -2.3679, -0.3355],        [ 1.3229,  1.0856, -2.8309],        [ 3.6919,  2.7953, -0.1058]])</code></pre><p><strong>2.3 更新函数：最后组合聚合特征和原特征</strong><br>这部分操作就很容易了，因为聚合特征和原特征都在节点上了，所以我们直接操作即可，比如相加</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.6239,  0.3987, -0.6238],
        [-0.7141, -1.0818, -1.0757],
        [-0.0540,  1.1078,  0.2700],
        [ 0.5681, -1.0023, -1.4963],
        [-1.3526, -0.5072,  0.3111],
        [ 0.4039,  0.1909,  2.4836],
        [ 0.2190,  0.9467, -0.6446],
        [-0.5860, -1.7527, -1.0872],
        [ 0.8450,  0.9458, -0.5495],
        [ 1.3140,  0.4514,  0.5442]])</code></pre><pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">=</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">+</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"add_edge_x"</span><span class="token punctuation">]</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#注意从第二行开始看</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.6239,  0.3987, -0.6238],
        [-0.8044, -1.7649, -2.7753],
        [-0.2522,  2.6404, -0.8895],
        [ 1.6139, -3.6899, -6.1886],
        [-4.2726, -1.5244, -0.6059],
        [-0.1948,  1.1733,  8.0318],
        [ 0.8419,  2.0842,  1.1943],
        [-1.1352, -4.1206, -1.4227],
        [ 2.1679,  2.0314, -3.3804],
        [ 5.0059,  3.2467,  0.4384]])</code></pre><h3 id="PageRank算法"><a href="#PageRank算法" class="headerlink" title="PageRank算法"></a>PageRank算法</h3><p>关于PageRank的原理，大家可以参考<a href="https://nbviewer.jupyter.org/github/zhulei227/ML_Notes/blob/master/notebooks/12_07_PGM_%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE_PageRank%E7%AE%97%E6%B3%95.ipynb" target="_blank" rel="noopener">&gt;&gt;note</a><br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201724741.png" alt=""></p>
<p>如图，以节点A举例，他的PR更新公示可以表示为：   </p>
<p>$$<br>PR_A^{(t+1)}=w_{BA}PR_B^{(t)}+w_{CA}PR_C^{(t)}<br>$$</p>
<p>这里，$w_{BA}$表示边$(B,A)$上的权重，在默认情况下，我们可以设置为节点$B$的出度的倒数，而$PR_{*}$则表示某节点的PR值，下面利用DGL来计算PR，节点编号0 ~ 3分别对应上面的节点A ~ D</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><p><strong>构建图</strong></p>
<pre class="line-numbers language-python"><code class="language-python">u<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
g<span class="token operator">=</span>dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong>计算边权重</strong></p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"out_degrees"</span><span class="token punctuation">]</span><span class="token operator">=</span>g<span class="token punctuation">.</span>out_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"weight"</span><span class="token punctuation">:</span><span class="token number">1.0</span><span class="token operator">/</span>edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">"out_degrees"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>message_func<span class="token punctuation">)</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"weight"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.3333, 0.3333, 0.3333, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000])</code></pre><p><strong>计算PR</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#随机初始化一组PR</span>
prs<span class="token operator">=</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
prs<span class="token operator">=</span>prs<span class="token operator">/</span>torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>prs<span class="token punctuation">)</span>
prs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.1702, 0.3912, 0.1391, 0.2994])</code></pre><pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"pr"</span><span class="token punctuation">]</span><span class="token operator">=</span>prs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_dot_e<span class="token punctuation">(</span><span class="token string">"pr"</span><span class="token punctuation">,</span><span class="token string">"weight"</span><span class="token punctuation">,</span><span class="token string">"weighted_pr"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#将源节点上的pr与边上的weight相乘后放到边上的weighted_pr变量中</span>
                 dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"weighted_pr"</span><span class="token punctuation">,</span><span class="token string">"pr"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将所有入边上的weighted_pr求和后赋值到目标节点的pr变量中</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"pr"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.3333, 0.2222, 0.2222, 0.2222])</code></pre><p>上面的实现不够严谨，为了防止没有出度或者没有入度的节点，其实需要在聚合的时候再添加一个平滑项（见上面链接中的note）</p>
<h3 id="GCN的DGL实现"><a href="#GCN的DGL实现" class="headerlink" title="GCN的DGL实现"></a>GCN的DGL实现</h3><p>我们先拎GCN出来看看，如何将其拆分为3个基本函数的形式，我们先回顾一下它的矩阵更新形式：   </p>
<p>$$<br>X^{(t+1)}=\sigma(\tilde{L}_{sym}X^{(t)}W^{(t)})<br>$$<br>我们可以如下拆解：   </p>
<p><strong>消息传递函数</strong>   </p>
<p>$$<br>m_{uv}^{(t+1)}=\frac{X_{v,:}^{(t)}W^{(t)}}{\sqrt{d_u}\cdot \sqrt{d_v}}<br>$$</p>
<p>这里，$d_u,d_v$分别表示节点$u,v$的度，$X_{v,:}^{(t)}$表示节点$v$的第$t$层的特征向量（这里是行向量表示），$W^{(t)}$是它在第$t$层的训练参数   </p>
<p><strong>聚合函数</strong><br>$$<br>\rho_u^{(t+1)}=\sum_{v\in N(u)}m_{uv}^{(t+1)}<br>$$</p>
<p>这里，只是简单将每条边上的消息相加  </p>
<p><strong>更新函数</strong><br>$$<br>X_{u,:}^{(t+1)}=\sigma(\rho_u^{(t+1)})<br>$$</p>
<p>就在聚合函数的基础上简单添加了一个激活函数即可</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>只需要在之前gcn.py的基础上修改即可，下面说下主要修改的地方    </p>
<p><strong>1 将连接矩阵修改为DGLGraph</strong>    </p>
<pre class="line-numbers language-python"><code class="language-python">    @staticmethod
    <span class="token keyword">def</span> <span class="token function">build_dgl_graph</span><span class="token punctuation">(</span>adj_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""根据邻接表创建邻接矩阵"""</span>
        edge_index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> adj_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>key<span class="token punctuation">,</span> key<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> item <span class="token keyword">in</span> adj_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">:</span>
                edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>key<span class="token punctuation">,</span> item<span class="token punctuation">]</span><span class="token punctuation">)</span>
                edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">,</span> key<span class="token punctuation">]</span><span class="token punctuation">)</span>
        u<span class="token punctuation">,</span> v <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> edge_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> edge_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2 GraphConvolution的Forward修改为DGL实现（核心）</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphConvolution</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GraphConvolution<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>use_bias <span class="token operator">=</span> use_bias
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reset_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
        message <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>
            edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">"in_feature"</span><span class="token punctuation">]</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'degree'</span><span class="token punctuation">]</span> <span class="token operator">*</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'degree'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            message <span class="token operator">+=</span> self<span class="token punctuation">.</span>bias
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"m"</span><span class="token punctuation">:</span> message<span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dgl_graph<span class="token punctuation">:</span> dgl<span class="token punctuation">.</span>graph<span class="token punctuation">,</span> input_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> dgl_graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"in_feature"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_feature
            dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"degree"</span><span class="token punctuation">]</span> <span class="token operator">=</span> dgl_graph<span class="token punctuation">.</span>in_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span>
            dgl_graph<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>message_func<span class="token punctuation">,</span>
                dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"m"</span><span class="token punctuation">,</span> <span class="token string">"neigh_sum"</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token keyword">return</span> dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"neigh_sum"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gcn_dgl <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora_dgl.pkl
Cached file: E:\datas\Algs\GNN\cora\processed_cora_dgl.pkl</code></pre><pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>dgl_graph<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>Graph(num_nodes=2708, num_edges=24424,
      ndata_schemes={}
      edata_schemes={})</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#如果有GPU则使用GPUdevice = "cuda" if torch.cuda.is_available() else "cpu"#接着预处理剩下的数据x = dataset.x / dataset.x.sum(1, keepdims=True)# 归一化数据，使得每一行和为1tensor_x = torch.from_numpy(x).to(device)tensor_y = torch.from_numpy(dataset.y).to(device)tensor_train_mask = torch.from_numpy(dataset.trn_mask).to(device)tensor_val_mask = torch.from_numpy(dataset.val_mask).to(device)tensor_test_mask = torch.from_numpy(dataset.test_mask).to(device)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.构建模型model = GCNNet().to(device)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>dgl_graph<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>        test_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>        predict_y <span class="token operator">=</span> test_mask_logits<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        accuracy <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> tensor_y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> accuracy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练模型</span>
<span class="token comment" spellcheck="true"># 超参数定义</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">200</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
trn_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>dgl_graph<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 计算当前模型在训练集上的准确率</span>
    train_acc <span class="token operator">=</span> accuracy<span class="token punctuation">(</span>tensor_train_mask<span class="token punctuation">)</span>
    trn_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 计算当前模型在验证集上的准确率</span>
    val_acc <span class="token operator">=</span> accuracy<span class="token punctuation">(</span>tensor_val_mask<span class="token punctuation">)</span>
    val_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>val_acc_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>trn_acc_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'val acc'</span><span class="token punctuation">,</span><span class="token string">'trn acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x1a3b8099f60&gt;</code></pre><p>​<br><img src="/images/loading.gif" data-original="../images/ML/output_9_1.png" alt=""><br>​    </p>
<h3 id="异质图RGCN-节点预测"><a href="#异质图RGCN-节点预测" class="headerlink" title="异质图RGCN_节点预测"></a>异质图RGCN_节点预测</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>我们通常处理的更多的还是异构图，异构图包含了多种类型的节点以及多种类型的边，我们之前介绍的GCN/GAT/SAGE目前都只能应用于同质图（只有一种节点类型，一种边类型），那如何将同质图的算法扩展到异构图呢？一种通常的做法是：  </p>
<blockquote>
<p>（1）将异构图按照边的类别将切分为多个子图；<br>（2）然后分别在这些子图上运行图算法；<br>（3）最后将各子图的结果再进行一次聚合  </p>
</blockquote>
<p>相较于之前，我们就再多一次对关系的聚合即可：   </p>
<p>$$<br>h_{i}^{(t+1)}=AGG({GNN_r(h_i^{(t)})\mid r\in R})<br>$$</p>
<p>这里，$GNN_r(h_i^{(t)})$表达在关系$r$上对节点$h_i^{(t)}$运行算法$GNN$后的结果，$R$表示所有关系，$AGG(\cdot)$表示对所有结果进行某种聚合，比如max,mean,sum等</p>
<h4 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h4><p>下面利用官方的示例以及API演示如何构造异构图，如何构造RGCN，并完成节点分类的任务  </p>
<p><strong>1 构造异构图</strong>  </p>
<p>随机构造了1000个用户，500个商品，以及用户与用户之间的follow关系，用户与商品之间的click和dislike关系</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><p><strong>2 构造模型</strong>  </p>
<p>这里对每种关系都训练的GCN模型，然后每种关系的结果采用sum进行聚合</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>3 训练模型</strong></p>
<pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>n_hetero_features<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
labels <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>

node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span>

opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用所有节点的特征进行前向传播计算，并提取输出的user节点嵌入</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 进行反向传播计算</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>1.8662775754928589
1.851954698562622
1.8382809162139893
1.8252463340759277
1.812849998474121</code></pre><h3 id="异质图RGCN-边预测"><a href="#异质图RGCN-边预测" class="headerlink" title="异质图RGCN_边预测"></a>异质图RGCN_边预测</h3><h4 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h4><p>边的预测我们可以基于它所关联的俩节点来计算，对于单个输出预测，等价于我们需要定义如下的一个函数：   </p>
<p>$$<br>score_{(i,j)}=g(h_i,h_j)<br>$$</p>
<p>即构造一个函数，输入俩向量$h_i,h_j$（分别表示俩节点特征），然后输出一个标量（表示边的输出），最简单的我们可以使用内积$&lt;h_i,h_j&gt;$，或者将$h_i,h_j$拼接后再进行一次线性变换$w^T(h_i||h_j)$，或者将$h_i,h_j$相加后再进行一次线性变换$w^T(h_i+h_j)$，这里可以是任意你能想到的方式（不过要可导），而这个操作我们可以利用dgl的<strong>apply_edges</strong>这个api来实现，比如下面分别实现内积和线性变换的操作</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>function <span class="token keyword">as</span> fn
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">class</span> <span class="token class-name">HeteroDotProductPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h   <span class="token comment" spellcheck="true">#一次性为所有节点类型的 'h'赋值</span>
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>fn<span class="token punctuation">.</span>u_dot_v<span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span>
<span class="token keyword">class</span> <span class="token class-name">MLPPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">apply_edges</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h_u <span class="token operator">=</span> edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span>
        h_v <span class="token operator">=</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span>
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>h_u<span class="token punctuation">,</span> h_v<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'score'</span><span class="token punctuation">:</span> score<span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h   <span class="token comment" spellcheck="true">#一次性为所有节点类型的 'h'赋值</span>
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>self<span class="token punctuation">.</span>apply_edges<span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><h4 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h4><p>下面与前一节的实现一样的内容就直接贴进来了</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在RGCN的基础上，我们可以继续构建对边的预测任务</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rgcn <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> HeteroDotProductPredictor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">,</span> x<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>rgcn<span class="token punctuation">(</span>g<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里得到RGCN后各节点的特征</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#然后求得边的score</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>模型训练</p>
<pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
label <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>
node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>pred<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span> <span class="token operator">-</span> label<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>39.65708541870117
37.67030715942383
35.77607727050781
33.9720344543457
32.25625228881836</code></pre><h3 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h3><h4 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h4><p>链接预测是预测边的存在性，注意它与边预测任务很不同，边预测是去预测已存在的边的属性。但通过<strong>负采样</strong>的技巧，我们可以将链接预测的问题转换为边预测的问题，可以看作：   </p>
<p>$$<br>链接预测=负采样+边预测<br>$$</p>
<p>我们可以这样理解，如果两节点间存在边，那么我们定义该边上的属性为1，如果不存在边那么我们定义该边上的属性为0，所以我们将链接预测问题就转换为了边上的1/0预测问题，如果俩节点上的预测值靠近1，我们就可以认为它们之间存在一条边，如果预测值靠近0，就认为它们之间不存在边。但是“不存在的边”的量往往很大，这需要考虑任意两两之间的连接，所以我们采用负采样，从所有不存在的边中随机采样部分出来训练，如下示例图：   </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829203046513.png" alt=""></p>
<p>对于上面的假设，我们可以类似于logistic任务，使用交叉熵损失函数：<br>$$<br>L=-log\sigma(y_{u,v})-\sum{[1-log(y_{u,k})]\mid k\in P(u)}<br>$$</p>
<p>这里，$u,v$是存在连接的点，$P(u)$是对$u$的负采样点的集合，$y_{u,v}$类似于上一节输入两向量，输出一个标量的函数，比如做内积，而$\sigma(\cdot)$是sigmoid函数，将输出约束在(0,1)之间，除了交叉熵，我们还可以选择其他函数，<a href="https://docs.dgl.ai/guide_cn/training-link.html" target="_blank" rel="noopener">参考&gt;&gt;</a></p>
<h4 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h4><p>这里需要实现的内容其实相比上一节主要多了两部分内容：<br>（1）第一部分是多了负采样；<br>（2）另一部分是需要修改损失函数的定义</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> dgl<span class="token punctuation">.</span>function <span class="token keyword">as</span> fn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.生成异构图</span>
n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h


<span class="token keyword">class</span> <span class="token class-name">HeteroDotProductPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># h是从5.1节中对异构图的每种类型的边所计算的节点表示</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>fn<span class="token punctuation">.</span>u_dot_v<span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sage <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> HeteroDotProductPredictor<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">,</span> neg_g<span class="token punctuation">,</span> x<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>sage<span class="token punctuation">(</span>g<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>neg_g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.定义负采样函数，将负样本采样为另外一张图</span>
<span class="token keyword">def</span> <span class="token function">construct_negative_graph</span><span class="token punctuation">(</span>graph<span class="token punctuation">,</span> k<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
    utype<span class="token punctuation">,</span> _<span class="token punctuation">,</span> vtype <span class="token operator">=</span> etype
    src<span class="token punctuation">,</span> dst <span class="token operator">=</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">(</span>etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
    neg_src <span class="token operator">=</span> src<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>k<span class="token punctuation">)</span>
    neg_dst <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> graph<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span>vtype<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>len<span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">*</span> k<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span>
        <span class="token punctuation">{</span>etype<span class="token punctuation">:</span> <span class="token punctuation">(</span>neg_src<span class="token punctuation">,</span> neg_dst<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        num_nodes_dict<span class="token operator">=</span><span class="token punctuation">{</span>ntype<span class="token punctuation">:</span> graph<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span>ntype<span class="token punctuation">)</span> <span class="token keyword">for</span> ntype <span class="token keyword">in</span> graph<span class="token punctuation">.</span>ntypes<span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.定义损失函数</span>
<span class="token keyword">def</span> <span class="token function">compute_loss</span><span class="token punctuation">(</span>pos_score<span class="token punctuation">,</span> neg_score<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 间隔损失</span>
    n_edges <span class="token operator">=</span> pos_score<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pos_score<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> neg_score<span class="token punctuation">.</span>view<span class="token punctuation">(</span>n_edges<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#5.训练模型</span>
k <span class="token operator">=</span> <span class="token number">5</span>
model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    negative_graph <span class="token operator">=</span> construct_negative_graph<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里只对"click"关系进行预测</span>
    pos_score<span class="token punctuation">,</span> neg_score <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> negative_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> compute_loss<span class="token punctuation">(</span>pos_score<span class="token punctuation">,</span> neg_score<span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>1.327864170074463
1.3069148063659668
1.277003288269043
1.2585861682891846
1.246128797531128</code></pre><h3 id="整图预测"><a href="#整图预测" class="headerlink" title="整图预测"></a>整图预测</h3><h4 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h4><p>整图预测是针对图层面的学习任务，比如判断某药物分子是否具有某种理化性质，再比如判断某社团是否具有欺诈可能，这需要我们对整个图提取它的特征表示，然后再基于此构建我们的学习任务，图的整体特征无外乎来源于三部分：1）节点特征；2）边特征；3）结构信息，基于这些信息，我们可以通过许多方式来构建图特征，DGL提供了一些简单的API，比如对各节点特征求和/求平均/pooling等，这可以方便我们构建一些基准图预测模型，下面我们利用对节点特征求平均的方式构建图特征，这可以通过<code>dgl.mean_nodes</code>这个API很方便的实现，它相当于做了如下计算：    </p>
<p>$$<br>h_g=\frac{1}{|V|}\sum_{v\in V }h_v<br>$$</p>
<p>$h_v$表示节点$v$的特征，然后基于$h_g$特征向量，构建我们预测模型</p>
<h4 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h4><p>利用dgl自带的MiniGCDataset数据集，它包括如下的8种类别的图结构<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829203210021.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.导入数据</span>
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>data <span class="token keyword">import</span> MiniGCDataset
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
<span class="token comment" spellcheck="true">#这里，随机构造了80个图，每个图是少10条边，最多30条边</span>
dataset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
graph<span class="token punctuation">,</span> label <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#绘制图像</span>
<span class="token operator">%</span>matplotlib inline
fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>to_networkx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Class: {:d}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/output_2_1.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义模型</span>
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>pytorch <span class="token keyword">import</span> GraphConv
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classify <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#线性分类器</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 以节点度作为初始节点特征。对于无向图，入度与外度相同。</span>
        h <span class="token operator">=</span> g<span class="token punctuation">.</span>in_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 执行图形卷积和激活函数</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>g<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>g<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>
        g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h

        <span class="token comment" spellcheck="true"># 通过对所有节点表示求平均来计算图形表示。</span>
        hg <span class="token operator">=</span> dgl<span class="token punctuation">.</span>mean_nodes<span class="token punctuation">(</span>g<span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>classify<span class="token punctuation">(</span>hg<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment" spellcheck="true"># 将多张图合并为一张图</span>
<span class="token keyword">def</span> <span class="token function">collate</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># The input `samples` is a list of pairs (graph, label).</span>
    graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> map<span class="token punctuation">(</span>list<span class="token punctuation">,</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>samples<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#把一批图 zip成 列表对象</span>
    batched_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#合并为一张图</span>
    <span class="token keyword">return</span> batched_graph<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># 训练集/测试集</span>
trainset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
testset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#batch训练</span>
data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                         collate_fn<span class="token operator">=</span>collate<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 构建模型</span>
model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> trainset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>bg<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>bg<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">/=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#     print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))</span>
    epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_losses<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2658c2b9dd8&gt;</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/output_4_1.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.测试</span>
model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_X<span class="token punctuation">,</span> test_Y <span class="token operator">=</span> map<span class="token punctuation">(</span>list<span class="token punctuation">,</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>testset<span class="token punctuation">)</span><span class="token punctuation">)</span>

test_bg <span class="token operator">=</span> dgl<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span>
test_Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>test_Y<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

pred_Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>model<span class="token punctuation">(</span>test_bg<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy of argmax predictions on the test set: {:4f}%'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
    <span class="token punctuation">(</span>test_Y <span class="token operator">==</span> pred_Y<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>test_Y<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Accuracy of argmax predictions on the test set: 72.500000%</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#5.查看混淆矩阵</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix
confusion_matrix<span class="token punctuation">(</span>test_Y<span class="token punctuation">,</span> pred_Y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([[10,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  5,  0,  0,  3,  2,  0,  0],
       [ 0,  0, 10,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  7,  0,  0,  3,  0],
       [ 0,  0,  3,  0,  0,  0,  0,  7],
       [ 0,  0,  0,  0,  2,  6,  0,  2],
       [ 0,  0,  0,  0,  0,  0, 10,  0],
       [ 0,  0,  0,  0,  0,  0,  0, 10]], dtype=int64)</code></pre><h3 id="批量采样训练"><a href="#批量采样训练" class="headerlink" title="批量采样训练"></a>批量采样训练</h3><p>实际业务中，我们需要处理的图往往很大，可能会有上亿的节点和边，如果把这些数据进行全量训练，GPU显存很难放的下，所以我们需要使用类似于DNN中那样的随机批量学习的方式进行训练，与DNN中的批量学习不同，GNN对单个训练样本的训练还需要利用到它的邻居节点，而且每多增加一层网络，所需的邻居样本还要往外扩展一层，所以对于$k$层的GNN网络，我们需要对训练样本进行$k$阶的子图采样操作（回想一下之前GraphSAGE代码中采样…），借助于DGL的api，我们只需要多添加2行代码就可以了…</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.准备数据</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>pytorch <span class="token keyword">import</span> HeteroGraphConv<span class="token punctuation">,</span> GraphConv

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>

user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
labels <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>
train_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>train_mask<span class="token punctuation">,</span> as_tuple<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><p>我们使用<code>MultiLayerFullNeighborSampler</code>进行采样，它会采样当前节点的所有邻居节点，利用<code>NodeDataLoader</code>进行数据的批量读取</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义采样器</span>
sampler <span class="token operator">=</span> dgl<span class="token punctuation">.</span>dataloading<span class="token punctuation">.</span>MultiLayerFullNeighborSampler<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#采样2阶子图，对应了GNN中2层网络</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">dataloader <span class="token operator">=</span> dgl<span class="token punctuation">.</span>dataloading<span class="token punctuation">.</span>NodeDataLoader<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"user"</span><span class="token punctuation">:</span> train_idx<span class="token punctuation">}</span><span class="token punctuation">,</span> sampler<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>通过对dataloader迭代，我们每次可以取出input_nodes, output_nodes, blocks这三个变量，其中：<br><strong>input_nodes</strong>：包括训练所需的所有节点ID<br><strong>output_nodes</strong>：包括训练目标的节点，对应上面128个随机的user节点<br><strong>blocks</strong>：是个list,从blocks[0],blocks[1]….分别对应了节点的$k$阶子图，$k-1$阶子图…..直到这128个user节点自身的$0$阶子图</p>
<pre class="line-numbers language-python"><code class="language-python">input_nodes<span class="token punctuation">,</span> output_nodes<span class="token punctuation">,</span> blocks <span class="token operator">=</span> next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>由于将原始的大图切分为了一个一个的block，所以对于模型定义中的<code>forward</code>阶段需要做一点修改，改动也很简单，将原始的全图变量，依层替换为对应的block即可</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> blocks<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>blocks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#2阶子图</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>blocks<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#1阶子图</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.训练模型</span>
<span class="token comment" spellcheck="true">#训练阶段没太大差异，注意输入、输出的具体格式</span>
losses<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
model <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>n_hetero_features<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> input_nodes<span class="token punctuation">,</span> output_nodes<span class="token punctuation">,</span> blocks <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># blocks = [b.to(torch.device('cuda')) for b in blocks]</span>
            input_features <span class="token operator">=</span> blocks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>srcdata<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># returns a dict</span>
            output_labels <span class="token operator">=</span> blocks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dstdata<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># returns a dict</span>
            output_predictions <span class="token operator">=</span> model<span class="token punctuation">(</span>blocks<span class="token punctuation">,</span> input_features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>output_predictions<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> output_labels<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x281a2e53fd0&gt;</code></pre><p>​<br><img src="/images/loading.gif" data-original="../images/ML/output_10_1.png" alt=""><br>​    </p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/gnn.html">https://jackhcc.github.io/posts/gnn.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/GNN/">
                                    <span class="chip bg-color">GNN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-08-24T21-32-27',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/sqlite.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/7.jpg" class="responsive-img" alt="SQLite详解">
                        
                        <span class="card-title">SQLite详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            SQLite数据库详解
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-08-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Database/" class="post-category">
                                    Database
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/SQLite/">
                        <span class="chip bg-color">SQLite</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/gan.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="GAN详解">
                        
                        <span class="card-title">GAN详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 学习纪录
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-08-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1254k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

