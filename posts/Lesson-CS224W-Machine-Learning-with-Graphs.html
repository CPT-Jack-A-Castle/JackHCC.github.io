<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CS224W-Machine Learning with Graphs, JackHCC">
    <meta name="description" content="Machine Learning with Graphs Notes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>CS224W-Machine Learning with Graphs | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CS224W-Machine Learning with Graphs</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Lesson/">
                                <span class="chip bg-color">Lesson</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-11-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-11-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    69 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a href="http://web.stanford.edu/class/cs224w/" target="_blank" rel="noopener">CS224W | Home (stanford.edu)</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Machine-Learning-with-Graphs"><a href="#Machine-Learning-with-Graphs" class="headerlink" title="Machine Learning with Graphs"></a>Machine Learning with Graphs</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150408195.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150422199.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150432882.png" alt=""></p>
<h3 id="Why-is-Graph-Deep-Learning-Hard"><a href="#Why-is-Graph-Deep-Learning-Hard" class="headerlink" title="Why is Graph Deep Learning Hard?"></a>Why is Graph Deep Learning Hard?</h3><ul>
<li>Networks are complex<ul>
<li>Arbitrary size and complex topological structure (i.e., no spatial locality like grids)</li>
<li>No fixed node ordering or reference point </li>
<li>Often dynamic and have multimodal features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150633660.png" alt=""></p>
<h3 id="Deep-Learning-in-Graphs"><a href="#Deep-Learning-in-Graphs" class="headerlink" title="Deep Learning in Graphs"></a>Deep Learning in Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150708217.png" alt=""></p>
<h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p>(Supervised) Machine Learning Lifecycle:  This feature, that feature. Every single time!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151141340.png" alt=""></p>
<p>Map nodes to d-dimensional  embeddings such that similar nodes in  the network are embedded close  together</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151205981.png" alt=""></p>
<h3 id="Course-Outline"><a href="#Course-Outline" class="headerlink" title="Course Outline"></a>Course Outline</h3><p>We are going to cover various topics in Machine  Learning and Representation Learning for graph  structured data: </p>
<ul>
<li>Traditional methods: Graphlets, Graph Kernels </li>
<li>Methods for node embeddings: DeepWalk, Node2Vec</li>
<li>Graph Neural Networks: GCN, GraphSAGE, GAT,  Theory of GNNs </li>
<li>Knowledge graphs and reasoning: TransE, BetaE </li>
<li>Deep generative models for graphs: GraphRNN </li>
<li>Applications to Biomedicine, Science, Industry</li>
</ul>
<h2 id="Applications-of-Graph-ML"><a href="#Applications-of-Graph-ML" class="headerlink" title="Applications of Graph ML"></a>Applications of Graph ML</h2><h3 id="Different-Types-of-Tasks"><a href="#Different-Types-of-Tasks" class="headerlink" title="Different Types of Tasks"></a>Different Types of Tasks</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151422981.png" alt=""></p>
<h3 id="Classic-Graph-ML-Tasks"><a href="#Classic-Graph-ML-Tasks" class="headerlink" title="Classic Graph ML Tasks"></a>Classic Graph ML Tasks</h3><ul>
<li>Node classification: Predict a property of a node <ul>
<li>Example: Categorize online users / items </li>
</ul>
</li>
<li>Link prediction: Predict whether there are missing  links between two nodes <ul>
<li>Example: Knowledge graph completion </li>
</ul>
</li>
<li>Graph classification: Categorize different graphs <ul>
<li>Example: Molecule property prediction </li>
</ul>
</li>
<li>Clustering: Detect if nodes form a community <ul>
<li>Example: Social circle detection </li>
</ul>
</li>
<li>Other tasks: <ul>
<li>Graph generation: Drug discovery </li>
<li>Graph evolution: Physical simulation</li>
</ul>
</li>
</ul>
<h2 id="Node-level-ML-Tasks"><a href="#Node-level-ML-Tasks" class="headerlink" title="Node-level ML Tasks"></a>Node-level ML Tasks</h2><h3 id="Protein-Folding"><a href="#Protein-Folding" class="headerlink" title="Protein Folding"></a>Protein Folding</h3><p><strong>A protein chain acquires its native 3D structure</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151653238.png" alt=""></p>
<p><strong>The Protein Folding Problem</strong></p>
<p>Computationally predict a protein’s 3D structure  based solely on its amino acid sequence</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151741995.png" alt=""></p>
<h3 id="Alphafold-Impact"><a href="#Alphafold-Impact" class="headerlink" title="Alphafold: Impact"></a>Alphafold: Impact</h3><ul>
<li>Key idea: “Spatial graph” <ul>
<li>Nodes: Amino acids in a protein sequence </li>
<li>Edges: Proximity between amino acids (residues)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151833311.png" alt=""></p>
<h2 id="Edge-level-ML-Tasks"><a href="#Edge-level-ML-Tasks" class="headerlink" title="Edge-level ML Tasks"></a>Edge-level ML Tasks</h2><h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><ul>
<li>Users interacts with items <ul>
<li>Watch movies, buy merchandise, listen to music </li>
<li>Nodes: Users and items </li>
<li>Edges: User-item interactions </li>
</ul>
</li>
<li>Goal: Recommend items users might like</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151940591.png" alt=""></p>
<h3 id="Pinsage-Graph-based-Recommender"><a href="#Pinsage-Graph-based-Recommender" class="headerlink" title="Pinsage: Graph-based Recommender"></a>Pinsage: Graph-based Recommender</h3><p><a href="https://arxiv.org/pdf/1806.01973.pdf" target="_blank" rel="noopener">Ying et al., Graph Convolutional Neural Networks for Web-Scale Recommender Systems, KDD 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152019114.png" alt=""></p>
<h3 id="Drug-Side-Effects"><a href="#Drug-Side-Effects" class="headerlink" title="Drug Side Effects"></a>Drug Side Effects</h3><ul>
<li>Many patients take multiple drugs to treat  complex or co-existing diseases:<ul>
<li>46% of people ages 70-79 take more than 5 drugs </li>
<li>Many patients take more than 20 drugs to treat  heart disease, depression, insomnia, etc.</li>
</ul>
</li>
<li>Task: Given a pair of drugs predict  adverse side effects</li>
</ul>
<h3 id="Biomedical-Graph-Link-Prediction"><a href="#Biomedical-Graph-Link-Prediction" class="headerlink" title="Biomedical Graph Link Prediction"></a>Biomedical Graph Link Prediction</h3><p><a href="https://arxiv.org/pdf/1802.00543.pdf" target="_blank" rel="noopener">Zitnik et al., Modeling Polypharmacy Side Effects with Graph Convolutional Networks, Bioinformatics 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152134532.png" alt=""></p>
<h2 id="Subgraph-level-ML-Tasks"><a href="#Subgraph-level-ML-Tasks" class="headerlink" title="Subgraph-level ML Tasks"></a>Subgraph-level ML Tasks</h2><h3 id="Traffic-Prediction"><a href="#Traffic-Prediction" class="headerlink" title="Traffic Prediction"></a>Traffic Prediction</h3><p><strong>Road Network as a Graph</strong></p>
<ul>
<li>Nodes: Road segments </li>
<li>Edges: Connectivity between road segments </li>
<li>Prediction: Time of Arrival (ETA)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152251501.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152307879.png" alt=""></p>
<h2 id="Graph-level-ML-Tasks"><a href="#Graph-level-ML-Tasks" class="headerlink" title="Graph-level ML Tasks"></a>Graph-level ML Tasks</h2><h3 id="Drug-Discovery"><a href="#Drug-Discovery" class="headerlink" title="Drug Discovery"></a>Drug Discovery</h3><ul>
<li>Antibiotics are small molecular graphs <ul>
<li>Nodes: Atoms </li>
<li>Edges: Chemical bonds</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152411240.png" alt=""></p>
<p><a href="https://www.mdpi.com/2079-6382/3/2/128" target="_blank" rel="noopener">Konaklieva, Monika I. “Molecular targets of β-lactam-based antimicrobials:  beyond the usual suspects.” Antibiotics 3.2 (2014): 128-142.</a></p>
<h3 id="Deep-Learning-for-Antibiotic-Discovery"><a href="#Deep-Learning-for-Antibiotic-Discovery" class="headerlink" title="Deep Learning for Antibiotic Discovery"></a>Deep Learning for Antibiotic Discovery</h3><p><a href="https://www.sciencedirect.com/science/article/pii/S0092867420301021" target="_blank" rel="noopener">Stokeset al., A Deep Learning Approach to Antibiotic Discovery, Cell 2020</a></p>
<ul>
<li>A Graph Neural Network graph classification model </li>
<li>Predict promising molecules from a pool of candidates</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152915938.png" alt=""></p>
<h3 id="Molecule-Generation-Optimization"><a href="#Molecule-Generation-Optimization" class="headerlink" title="Molecule Generation/Optimization"></a>Molecule Generation/Optimization</h3><p><a href="https://arxiv.org/pdf/1806.02473.pdf" target="_blank" rel="noopener">Youet al., Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation, NeurIPS 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152955374.png" alt=""></p>
<h3 id="Physics-Simulation"><a href="#Physics-Simulation" class="headerlink" title="Physics Simulation"></a>Physics Simulation</h3><p><a href="https://arxiv.org/pdf/2002.09405.pdf" target="_blank" rel="noopener">Sanchez-Gonzalez et al., Learning to simulate complex physics with graph networks, ICML 2020</a></p>
<ul>
<li>Physical simulation as a graph: <ul>
<li>Nodes: Particles</li>
<li>Edges: Interaction between particles</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153108274.png" alt=""></p>
<h4 id="Simulation-Learning-Framework"><a href="#Simulation-Learning-Framework" class="headerlink" title="Simulation Learning Framework"></a>Simulation Learning Framework</h4><p>A graph evolution task: </p>
<ul>
<li>Goal: Predict how a graph will evolve over</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153212413.png" alt=""></p>
<h2 id="Choice-of-Graph-Representation"><a href="#Choice-of-Graph-Representation" class="headerlink" title="Choice of Graph Representation"></a>Choice of Graph Representation</h2><h3 id="Components-of-a-Network"><a href="#Components-of-a-Network" class="headerlink" title="Components of a Network"></a>Components of a Network</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153253676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153319772.png" alt=""></p>
<h3 id="Choosing-a-Proper-Representation"><a href="#Choosing-a-Proper-Representation" class="headerlink" title="Choosing a Proper Representation"></a>Choosing a Proper Representation</h3><ul>
<li>If you connect individuals that work  with each other, you will explore a  professional network </li>
<li>If you connect those that have a  sexual relationship, you will be  exploring sexual networks </li>
<li>If you connect scientific papers that cite each other, you will be studying the citation network</li>
<li>If you connect all papers with the same word in the title,  what will you be exploring? It is a network, nevertheless</li>
</ul>
<h3 id="How-do-you-define-a-graph"><a href="#How-do-you-define-a-graph" class="headerlink" title="How do you define a graph"></a>How do you define a graph</h3><ul>
<li>How to build a graph: <ul>
<li>What are nodes? </li>
<li>What are edges? </li>
</ul>
</li>
<li>Choice of the proper network representation  of a given domain/problem determines our  ability to use networks successfully: <ul>
<li>In some cases, there is a unique, unambiguous  representation</li>
<li>In other cases, the representation is by no means unique </li>
<li>The way you assign links will determine the nature  of the question you can study</li>
</ul>
</li>
</ul>
<h3 id="Directed-vs-Undirected-Graphs"><a href="#Directed-vs-Undirected-Graphs" class="headerlink" title="Directed vs Undirected Graphs"></a>Directed vs Undirected Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153516654.png" alt=""></p>
<h3 id="Heterogeneous-Graphs"><a href="#Heterogeneous-Graphs" class="headerlink" title="Heterogeneous Graphs"></a>Heterogeneous Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153544194.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153559429.png" alt=""></p>
<h3 id="Node-Degrees"><a href="#Node-Degrees" class="headerlink" title="Node Degrees"></a>Node Degrees</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153620904.png" alt=""></p>
<h3 id="Bipartite-Graph"><a href="#Bipartite-Graph" class="headerlink" title="Bipartite Graph"></a>Bipartite Graph</h3><ul>
<li>Bipartite graph is a graph whose nodes can  be divided into two disjoint sets U and V such that  every link connects a node in U to one in V; that is,  U and V are independent sets </li>
<li>Examples: <ul>
<li>Authors-to-Papers (they authored) </li>
<li>Actors-to-Movies (they appeared in) </li>
<li>Users-to-Movies (they rated) </li>
<li>Recipes-to-Ingredients (they contain) </li>
</ul>
</li>
<li>“Folded” networks: <ul>
<li>Author collaboration networks </li>
<li>Movie co-rating networks</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153743707.png" alt=""></p>
<h3 id="FoldedProjected-Bipartite-Graphs"><a href="#FoldedProjected-Bipartite-Graphs" class="headerlink" title="FoldedProjected Bipartite Graphs"></a>FoldedProjected Bipartite Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153806330.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-Matrix"><a href="#Representing-Graphs-Adjacency-Matrix" class="headerlink" title="Representing Graphs: Adjacency Matrix"></a>Representing Graphs: Adjacency Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153828291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153842858.png" alt=""></p>
<h3 id="Networks-are-Sparse-Graphs"><a href="#Networks-are-Sparse-Graphs" class="headerlink" title="Networks are Sparse Graphs"></a>Networks are Sparse Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153938780.png" alt=""></p>
<h3 id="Representing-Graphs-Edge-list"><a href="#Representing-Graphs-Edge-list" class="headerlink" title="Representing Graphs: Edge list"></a>Representing Graphs: Edge list</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154021381.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-list"><a href="#Representing-Graphs-Adjacency-list" class="headerlink" title="Representing Graphs: Adjacency list"></a>Representing Graphs: Adjacency list</h3><ul>
<li><p>Adjacency list: </p>
<ul>
<li><p>Easier to work with if network is </p>
<ul>
<li><p>Large </p>
</li>
<li><p>Sparse </p>
</li>
</ul>
</li>
<li><p>Allows us to quickly retrieve all  neighbors of a given node </p>
<ul>
<li><p>1: </p>
</li>
<li><p>2: 3, 4 </p>
</li>
<li><p>3: 2, 4 </p>
</li>
<li><p>4: 5 </p>
</li>
<li><p>5: 1, 2</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Node-and-Edge-Attributes"><a href="#Node-and-Edge-Attributes" class="headerlink" title="Node and Edge Attributes"></a>Node and Edge Attributes</h3><ul>
<li>Possible options: <ul>
<li>Weight (e.g., frequency of communication) </li>
<li>Ranking (best friend, second best friend…) </li>
<li>Type (friend, relative, co-worker) </li>
<li>Sign: Friend vs. Foe, Trust vs. Distrust </li>
<li>Properties depending on the structure of the rest  of the graph: Number of common friends</li>
</ul>
</li>
</ul>
<h3 id="More-Types-of-Graphs"><a href="#More-Types-of-Graphs" class="headerlink" title="More Types of Graphs"></a>More Types of Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154354051.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154418078.png" alt=""></p>
<h3 id="Connectivity-of-Undirected-Graphs"><a href="#Connectivity-of-Undirected-Graphs" class="headerlink" title="Connectivity of Undirected Graphs"></a>Connectivity of Undirected Graphs</h3><ul>
<li>Connected (undirected) graph: <ul>
<li>Any two vertices can be joined by a path </li>
</ul>
</li>
<li>A disconnected graph is made up by two or  more connected components</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154501411.png" alt=""></p>
<h3 id="Connectivity-Example"><a href="#Connectivity-Example" class="headerlink" title="Connectivity: Example"></a>Connectivity: Example</h3><p>The adjacency matrix of a network with several  components can be written in a block- diagonal  form, so that nonzero elements are confined to  squares, with all other elements being zero:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154537953.png" alt=""></p>
<h3 id="Connectivity-of-Directed-Graphs"><a href="#Connectivity-of-Directed-Graphs" class="headerlink" title="Connectivity of Directed Graphs"></a>Connectivity of Directed Graphs</h3><ul>
<li>Strongly connected directed graph <ul>
<li>has a path from each node to every other node  and vice versa (e.g., A-B path and B-A path)</li>
</ul>
</li>
<li>Weakly connected directed graph <ul>
<li>is connected if we disregard the edge directions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154640547.png" alt=""></p>
<p>Strongly connected components (SCCs) can  be identified, but not every node is part of a  nontrivial strongly connected component.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154659259.png" alt=""></p>
<h1 id="Traditional-Methods-for-Machine-Learning-in-Graphs"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h1><h2 id="Traditional-Methods-for-Machine-Learning-in-Graphs-1"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs-1" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h2><h3 id="Traditional-ML-Pipeline"><a href="#Traditional-ML-Pipeline" class="headerlink" title="Traditional ML Pipeline"></a>Traditional ML Pipeline</h3><p>Design features for nodes/links/graphs </p>
<p>Obtain features for all training data</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155029705.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155040109.png" alt=""></p>
<h3 id="Feature-Desian"><a href="#Feature-Desian" class="headerlink" title="Feature Desian"></a>Feature Desian</h3><ul>
<li><p>Using effective features over graphs is the key  to achieving good model performance. </p>
</li>
<li><p>Traditional ML pipeline uses hand-designed  features. </p>
</li>
<li><p>In this lecture, we overview the traditional  features for: </p>
<ul>
<li>Node-level prediction </li>
<li>Link-level prediction </li>
<li>Graph-level prediction </li>
</ul>
</li>
<li><p>For simplicity, we focus on undirected graphs.</p>
</li>
<li><p>Goal: Make predictions for a set of objects </p>
</li>
<li><p>Design choices: </p>
<ul>
<li>Features: d-dimensional vectors </li>
<li>Objects: Nodes, edges, sets of nodes,  entire graphs </li>
<li>Objective function: <ul>
<li>What task are we aiming to solve?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155314744.png" alt=""></p>
<h2 id="Node-level-Tasks-and-Features"><a href="#Node-level-Tasks-and-Features" class="headerlink" title="Node-level Tasks and Features"></a>Node-level Tasks and Features</h2><h3 id="Node-level-Features-Overview"><a href="#Node-level-Features-Overview" class="headerlink" title="Node-level Features: Overview"></a>Node-level Features: Overview</h3><ul>
<li>Goal: Characterize the structure and position of  a node in the network: <ul>
<li>Node degree </li>
<li>Node centrality </li>
<li>Clustering coefficient </li>
<li>Graphlets</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155446882.png" alt=""></p>
<h3 id="Node-Degree"><a href="#Node-Degree" class="headerlink" title="Node Degree"></a>Node Degree</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155516487.png" alt=""></p>
<h3 id="Node-Centrality"><a href="#Node-Centrality" class="headerlink" title="Node Centrality"></a>Node Centrality</h3><ul>
<li>Node degree counts the neighboring nodes  without capturing their importance. </li>
<li>Node centrality 𝑐_𝑣 takes the node importance  in a graph into account </li>
<li>Different ways to model importance: <ul>
<li>Engienvector centrality </li>
<li>Betweenness centrality </li>
<li>Closeness centrality </li>
<li>and many others…</li>
</ul>
</li>
</ul>
<h4 id="Eigenvector-centrality"><a href="#Eigenvector-centrality" class="headerlink" title="Eigenvector centrality"></a>Eigenvector centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155636291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155651475.png" alt=""></p>
<h4 id="Betweenness-centrality"><a href="#Betweenness-centrality" class="headerlink" title="Betweenness centrality"></a>Betweenness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155709827.png" alt=""></p>
<h4 id="Closeness-centrality"><a href="#Closeness-centrality" class="headerlink" title="Closeness centrality"></a>Closeness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155731340.png" alt=""></p>
<h3 id="Clustering-Coefficient"><a href="#Clustering-Coefficient" class="headerlink" title="Clustering Coefficient"></a>Clustering Coefficient</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155816102.png" alt=""></p>
<h3 id="Graphlets"><a href="#Graphlets" class="headerlink" title="Graphlets"></a>Graphlets</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155840431.png" alt=""></p>
<ul>
<li><p>Goal: Describe network structure around node 𝑢 </p>
<ul>
<li>Graphlets are small subgraphs that describe the  structure of node 𝑢’s network neighborhood Analogy: </li>
</ul>
</li>
<li><p>Degree counts #(edges) that a node touches </p>
</li>
<li><p>Clustering coefficient counts #(triangles) that a  node touches. </p>
</li>
<li><p>Graphlet Degree Vector (GDV): Graphlet-base  features for nodes </p>
<ul>
<li>GDV counts #(graphlets) that a node touches</li>
</ul>
</li>
<li><p>Considering graphlets of size 2-5 nodes we get: </p>
<ul>
<li>Vector of 73 coordinates is a signature of a node  that describes the topology of node’s neighborhood  </li>
</ul>
</li>
<li><p>Graphlet degree vector provides a measure of  a node’s local network topology: </p>
<ul>
<li>Comparing vectors of two nodes provides a more  detailed measure of local topological similarity than  node degrees or clustering coefficient.</li>
</ul>
</li>
</ul>
<h4 id="Induced-Subgraph-Isomorphism"><a href="#Induced-Subgraph-Isomorphism" class="headerlink" title="Induced Subgraph Isomorphism"></a>Induced Subgraph Isomorphism</h4><p>Def: Induced subgraph is another graph, formed  from a subset of vertices and all of the edges  connecting the vertices in that subset.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160056026.png" alt=""></p>
<p>Def: Graph Isomorphism(同构) </p>
<ul>
<li>Two graphs which contain the same number of nodes  connected in the same way are said to be isomorphic.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160128187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160159336.png" alt=""></p>
<p><strong>Graphlet Degree Vector</strong> (GDV): A count  vector of graphlets rooted at a given node</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160238072.png" alt=""></p>
<h3 id="Node-level-Feature-Summary"><a href="#Node-level-Feature-Summary" class="headerlink" title="Node-level Feature: Summary"></a>Node-level Feature: Summary</h3><ul>
<li><p>We have introduced different ways to obtain  node features. </p>
</li>
<li><p>They can be categorized as: </p>
<ul>
<li>Importance-based features: <ul>
<li>Node degree </li>
<li>Different node centrality measures </li>
</ul>
</li>
<li>Structure-based features: <ul>
<li>Node degree </li>
<li>Clustering coefficient </li>
<li>Graphlet count vector</li>
</ul>
</li>
</ul>
</li>
<li><p>Importance-based features: capture the  importance of a node in a graph </p>
<ul>
<li>Node degree: <ul>
<li>Simply counts the number of neighboring nodes </li>
</ul>
</li>
<li>Node centrality: <ul>
<li>Models importance of neighboring nodes in a graph </li>
<li>Different modeling choices: eigenvector centrality,  betweenness centrality, closeness centrality</li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting influential nodes in a graph </p>
<ul>
<li>Example: predicting celebrity users in a social  network</li>
</ul>
</li>
<li><p>Structure-based features: Capture topological  properties of local neighborhood around a node. </p>
<ul>
<li>Node degree: <ul>
<li>Counts the number of neighboring nodes </li>
</ul>
</li>
<li>Clustering coefficient: <ul>
<li>Measures how connected neighboring nodes are </li>
</ul>
</li>
<li>Graphlet degree vector: <ul>
<li>Counts the occurrences of different graphlets </li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting a particular role a node  plays in a graph: </p>
<ul>
<li>Example: Predicting protein functionality in a  protein-protein interaction network</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164204808.png" alt=""></p>
<h2 id="Link-Prediction-Task-and-Features"><a href="#Link-Prediction-Task-and-Features" class="headerlink" title="Link Prediction Task and Features"></a>Link Prediction Task and Features</h2><h3 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h3><ul>
<li>The task is to predict new links based on the  existing links. </li>
<li>At test time, node pairs (with no existing links)  are ranked, and top 𝐾 node pairs are predicted. </li>
<li>The key is to design features for a pair of nodes.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164300332.png" alt=""></p>
<p><strong>Two formulations of the link prediction task:</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164327858.png" alt=""></p>
<h3 id="Link-Prediction-via-Proximity"><a href="#Link-Prediction-via-Proximity" class="headerlink" title="Link Prediction via Proximity"></a>Link Prediction via Proximity</h3><ul>
<li>Methodology: <ul>
<li>For each pair of nodes (x,y) compute score c(x,y) <ul>
<li>For example, c(x,y) could be the # of common neighbors  of x and y </li>
</ul>
</li>
<li>Sort pairs (x,y) by the decreasing score c(x,y) </li>
<li>Predict top n pairs as new links </li>
<li>See which of these links actually appear in 𝐺[𝑡1 ,𝑡1 ′ ]</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164503916.png" alt=""></p>
<h3 id="Link-level-Features-Overview"><a href="#Link-level-Features-Overview" class="headerlink" title="Link-level Features: Overview"></a>Link-level Features: Overview</h3><ul>
<li>Distance-based feature </li>
<li>Local neighborhood overlap </li>
<li>Global neighborhood overlap</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164529982.png" alt=""></p>
<h3 id="Distance-based-Features"><a href="#Distance-based-Features" class="headerlink" title="Distance-based Features"></a>Distance-based Features</h3><p>Shortest-path distance between two nodes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164603800.png" alt=""></p>
<p>However, this does not capture the degree of  neighborhood overlap: </p>
<ul>
<li>Node pair (B, H) has 2 shared neighboring nodes,  while pairs (B, E) and (A, B) only have 1 such node</li>
</ul>
<h3 id="Local-Neighborhood-Overlap"><a href="#Local-Neighborhood-Overlap" class="headerlink" title="Local Neighborhood Overlap"></a>Local Neighborhood Overlap</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164647894.png" alt=""></p>
<h3 id="Global-Neighborhood-Overlap"><a href="#Global-Neighborhood-Overlap" class="headerlink" title="Global Neighborhood Overlap"></a>Global Neighborhood Overlap</h3><ul>
<li><p>Limitation of local neighborhood features: </p>
<ul>
<li><p>Metric is always zero if the two nodes do not have  any neighbors in common.</p>
</li>
<li><p>However, the two nodes may still potentially be  connected in the future. </p>
</li>
</ul>
</li>
<li><p>Global neighborhood overlap metrics resolve  the limitation by considering the entire graph.</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164745624.png" alt=""></p>
<ul>
<li>Katz index: count the number of walks of all  lengths between a given pair of nodes. </li>
<li>Q: How to compute #walks between two  nodes? <ul>
<li>Use powers of the graph adjacency matrix!</li>
</ul>
</li>
</ul>
<h4 id="Intuition-Powers-of-Adj-Matrices"><a href="#Intuition-Powers-of-Adj-Matrices" class="headerlink" title="Intuition: Powers of Adj Matrices"></a>Intuition: Powers of Adj Matrices</h4><p><strong>Computing #walks between two nodes</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164853647.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164908991.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165005720.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165018384.png" alt=""></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Distance-based features: <ul>
<li>Uses the shortest path length between two nodes  but does not capture how neighborhood overlaps. </li>
</ul>
</li>
<li>Local neighborhood overlap: <ul>
<li>Captures how many neighboring nodes are shared  by two nodes. </li>
<li>Becomes zero when no neighbor nodes are shared. </li>
</ul>
</li>
<li>Global neighborhood overlap: <ul>
<li>Uses global graph structure to score two nodes. </li>
<li>Katz index counts #walks of all lengths between two  nodes.</li>
</ul>
</li>
</ul>
<h2 id="Graph-level-Features-and-Graph-Kernels"><a href="#Graph-level-Features-and-Graph-Kernels" class="headerlink" title="Graph-level Features and Graph Kernels"></a>Graph-level Features and Graph Kernels</h2><h3 id="Graph-level-Features"><a href="#Graph-level-Features" class="headerlink" title="Graph-level Features"></a>Graph-level Features</h3><p>Goal: We want features that characterize the  structure of an entire graph</p>
<h3 id="Backaround-Kernel-Methods"><a href="#Backaround-Kernel-Methods" class="headerlink" title="Backaround Kernel Methods"></a>Backaround Kernel Methods</h3><ul>
<li>Kernel methods are widely-used for traditional  ML for graph-level prediction. </li>
<li>Idea: Design kernels instead of feature vectors. </li>
<li>A quick introduction to Kernels:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165703860.png" alt=""></p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li>Graph Kernels: Measure similarity between  two graphs: <ul>
<li>Graphlet Kernel [1] </li>
<li>Weisfeiler-Lehman Kernel [2] </li>
<li>Other kernels are also proposed in the literature  (beyond the scope of this lecture) <ul>
<li>Random-walk kernel </li>
<li>Shortest-path graph kernel </li>
<li>And many more…</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>[1] Shervashidze, Nino, et al. “Efficient graphlet kernels for large graph comparison.” Artificial Intelligence and Statistics. 2009. </p>
<p>[2] Shervashidze, Nino, et al. “Weisfeiler-lehman graph kernels.” Journal of Machine Learning Research 12.9 (2011).</p>
<h3 id="Graph-Kernel-Key-Idea"><a href="#Graph-Kernel-Key-Idea" class="headerlink" title="Graph Kernel: Key Idea"></a>Graph Kernel: Key Idea</h3><ul>
<li>Goal: Design graph feature vector 𝜙(𝐺) </li>
<li>Key idea: Bag-of-Words (BoW) for a graph <ul>
<li>Recall: BoW simply uses the word counts as  features for documents (no ordering considered). </li>
<li>Naïve extension to a graph: Regard nodes as words. </li>
<li>Since both graphs have 4 red nodes, we get the  same feature vector for two different graphs…</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170336494.png" alt=""></p>
<p>What if we use Bag of node degrees?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170358374.png" alt=""></p>
<p>Both Graphlet Kernel and Weisfeiler-Lehman  (WL) Kernel use Bag-of-* representation of  graph, where * is more sophisticated than  node degrees!</p>
<h3 id="Graphlet-Features"><a href="#Graphlet-Features" class="headerlink" title="Graphlet Features"></a>Graphlet Features</h3><ul>
<li>Key idea: Count the number of different  graphlets in a graph. <ul>
<li>Note: Definition of graphlets here is slightly  different from node-level features.  </li>
<li>The two differences are: <ul>
<li>Nodes in graphlets here do not need to be connected (allows for  isolated nodes) </li>
<li>The graphlets here are not rooted. </li>
<li>Examples in the next slide illustrate this.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170616974.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170627979.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170640069.png" alt=""></p>
<h3 id="Graphlet-Kernel"><a href="#Graphlet-Kernel" class="headerlink" title="Graphlet Kernel"></a>Graphlet Kernel</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170712399.png" alt=""></p>
<ul>
<li><p>Limitations: Counting graphlets is expensive! </p>
</li>
<li><p>Counting size-𝑘 graphlets for a graph with size 𝑛 by enumeration takes 𝑛^𝑘 . </p>
</li>
<li><p>This is unavoidable in the worst-case since  subgraph isomorphism test (judging whether a  graph is a subgraph of another graph) is NP-hard. </p>
</li>
<li><p>If a graph’s node degree is bounded by 𝑑, an  𝑂(𝑛𝑑^(𝑘−1)) algorithm exists to count all the  graphlets of size 𝑘.  </p>
<p><strong>Can we design a more efficient graph kernel?</strong></p>
</li>
</ul>
<h3 id="Weisfeiler-lehman-Kernel"><a href="#Weisfeiler-lehman-Kernel" class="headerlink" title="Weisfeiler-lehman Kernel"></a>Weisfeiler-lehman Kernel</h3><ul>
<li>Goal: Design an efficient graph feature  descriptor 𝜙 (𝐺) </li>
<li>Idea: Use neighborhood structure to  iteratively enrich node vocabulary.  </li>
<li>Generalized version of Bag of node degrees since  node degrees are one-hop neighborhood  information. </li>
<li>Algorithm to achieve this: Color refinement</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170929956.png" alt=""></p>
<p>Example of color refinement given two graphs</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170948187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170958604.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171007420.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171017926.png" alt=""></p>
<p>After color refinement, WL kernel counts number  of nodes with a given color.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171038806.png" alt=""></p>
<p>The WL kernel value is computed by the inner  product of the color count vectors: </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171053600.png" alt=""></p>
<ul>
<li>WL kernel is computationally efficient <ul>
<li>The time complexity for color refinement at each step is  linear in #(edges), since it involves aggregating neighboring  colors. </li>
</ul>
</li>
<li>When computing a kernel value, only colors  appeared in the two graphs need to be tracked. <ul>
<li>Thus, #(colors) is at most the total number of nodes. </li>
</ul>
</li>
<li>Counting colors takes linear-time w.r.t. #(nodes). </li>
<li>In total, time complexity is linear in #(edges)</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><p>Graphlet Kernel </p>
<ul>
<li>Graph is represented as Bag-of-graphlets </li>
<li>Computationally expensive </li>
</ul>
</li>
<li><p>Weisfeiler-Lehman Kernel </p>
<ul>
<li>Apply 𝐾-step color refinement algorithm to enrich  node colors <ul>
<li>Different colors capture different 𝐾-hop neighborhood  structures </li>
</ul>
</li>
<li>Graph is represented as Bag-of-colors </li>
<li>Computationally efficient </li>
<li>Closely related to Graph Neural Networks (as we  will see!)</li>
</ul>
</li>
<li><p>Traditional ML Pipeline </p>
<ul>
<li>Hand-crafted feature + ML model </li>
</ul>
</li>
<li><p>Hand-crafted features for graph data </p>
<ul>
<li>Node-level: <ul>
<li>Node degree, centrality, clustering coefficient, graphlets </li>
</ul>
</li>
<li>Link-level: <ul>
<li>distance-based feature </li>
<li>local/global neighborhood overlap </li>
</ul>
</li>
<li>Graph-level: <ul>
<li>Graphlet kernel, WL kernel</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Node-Embeddings"><a href="#Node-Embeddings" class="headerlink" title="Node Embeddings"></a>Node Embeddings</h1><p>Goal: Efficient task-independent feature  learning for machine learning with graphs!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114184930238.png" alt=""></p>
<h2 id="Why-Embedding"><a href="#Why-Embedding" class="headerlink" title="Why Embedding?"></a>Why Embedding?</h2><ul>
<li>Task: Map nodes into an embedding space <ul>
<li>Similarity of embeddings between nodes indicates  their similarity in the network. For example: <ul>
<li>Both nodes are close to each other (connected by an edge) </li>
</ul>
</li>
<li>Encode network information </li>
<li>Potentially used for many downstream predictions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185054537.png" alt=""></p>
<p>2D embedding of nodes of the Zachary’s  Karate Club network:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185117044.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Perozzi et al. DeepWalk: Online Learning of Social Representations. KDD 2014</a></p>
<h2 id="Node-Embeddings-Encoder-and-Decoder"><a href="#Node-Embeddings-Encoder-and-Decoder" class="headerlink" title="Node Embeddings Encoder and Decoder"></a>Node Embeddings Encoder and Decoder</h2><h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><ul>
<li>Assume we have a graph G: <ul>
<li>V is the vertex set. </li>
<li>A is the adjacency matrix (assume binary). </li>
<li>For simplicity: No node features or extra  information is used</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185313810.png" alt=""></p>
<h3 id="Embedding-Nodes"><a href="#Embedding-Nodes" class="headerlink" title="Embedding Nodes"></a>Embedding Nodes</h3><p>Goal is to encode nodes so that similarity in  the embedding space (e.g., dot product)  approximates similarity in the graph</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185343379.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185359370.png" alt=""></p>
<h4 id="Learning-Node-Embeddings"><a href="#Learning-Node-Embeddings" class="headerlink" title="Learning Node Embeddings"></a>Learning Node Embeddings</h4><ol>
<li>Encoder maps from nodes to embeddings </li>
<li>Define a node similarity function (i.e., a  measure of similarity in the original network) </li>
<li>Decoder 𝐃𝐄𝐂 maps from embeddings to the  similarity score </li>
<li>Optimize the parameters of the encoder so  that:</li>
</ol>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185507005.png" alt=""></p>
<h4 id="Two-Key-Components"><a href="#Two-Key-Components" class="headerlink" title="Two Key Components"></a>Two Key Components</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185541120.png" alt=""></p>
<h4 id="“shallow”Encoding"><a href="#“shallow”Encoding" class="headerlink" title="“shallow”Encoding"></a>“shallow”Encoding</h4><p>Simplest encoding approach: Encoder is just an  embedding-lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185622676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185653217.png" alt=""></p>
<ul>
<li>Each node is assigned a unique embedding vector (i.e., we directly optimize the embedding of each node) </li>
<li>Many methods: DeepWalk, node2vec</li>
</ul>
<h3 id="Framework-Summary"><a href="#Framework-Summary" class="headerlink" title="Framework Summary"></a>Framework Summary</h3><p>Encoder + Decoder Framework</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185821145.png" alt=""></p>
<h3 id="How-to-Define-Node-Similarit"><a href="#How-to-Define-Node-Similarit" class="headerlink" title="How to Define Node Similarit"></a>How to Define Node Similarit</h3><ul>
<li>Key choice of methods is how they define node similarity. </li>
<li>Should two nodes have a similar embedding if  they… <ul>
<li>are linked? </li>
<li>share neighbors? </li>
<li>have similar “structural roles”? </li>
</ul>
</li>
<li>We will now learn node similarity definition that uses  random walks, and how to optimize embeddings for  such a similarity measure.</li>
</ul>
<h3 id="Note-on-Node-Embeddings"><a href="#Note-on-Node-Embeddings" class="headerlink" title="Note on Node Embeddings"></a>Note on Node Embeddings</h3><ul>
<li>This is unsupervised/self-supervisedway of  learning node embeddings. <ul>
<li>We are not utilizing node labels </li>
<li>We are not utilizing node features </li>
<li>The goal is to directly estimate a set of coordinates  (i.e., the embedding) of a node so that some aspect  of the network structure (captured by DEC) is  preserved. </li>
</ul>
</li>
<li>These embeddings are task independent <ul>
<li>They are not trained for a specific task but can be  used for any task.</li>
</ul>
</li>
</ul>
<h2 id="Random-Walk-Approaches-for-Node-Embeddings"><a href="#Random-Walk-Approaches-for-Node-Embeddings" class="headerlink" title="Random Walk Approaches for Node Embeddings"></a>Random Walk Approaches for Node Embeddings</h2><h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114190246623.png" alt=""></p>
<h3 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191224897.png" alt=""></p>
<h3 id="Random-walk-Embeddings"><a href="#Random-walk-Embeddings" class="headerlink" title="Random-walk Embeddings"></a>Random-walk Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191304620.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191410904.png" alt=""></p>
<h3 id="Why-Random-Walks"><a href="#Why-Random-Walks" class="headerlink" title="Why Random Walks?"></a>Why Random Walks?</h3><ol>
<li>Expressivity: Flexible stochastic(随机的) definition of  node similarity that incorporates both local  and higher-order neighborhood information Idea: if random walk starting from node 𝑢 visits 𝑣 with high probability, 𝑢 and 𝑣 are  similar (high-order multi-hop information) </li>
<li>Efficiency: Do not need to consider all node  pairs when training; only need to consider  pairs that co-occur on random walks</li>
</ol>
<h3 id="Unsupervised-Feature-Learning"><a href="#Unsupervised-Feature-Learning" class="headerlink" title="Unsupervised Feature Learning"></a>Unsupervised Feature Learning</h3><ul>
<li>Intuition: Find embedding of nodes in  𝑑-dimensional space that preserves similarity </li>
<li>Idea: Learn node embedding such that nearby nodes are close together in the network </li>
<li>Given a node 𝑢, how do we define nearby  nodes?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191744402.png" alt=""></p>
<h3 id="Feature-Learning-as-Optimization"><a href="#Feature-Learning-as-Optimization" class="headerlink" title="Feature Learning as Optimization"></a>Feature Learning as Optimization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191851755.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192332640.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192807843.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193211508.png" alt=""></p>
<p>But doing this naively is too expensive!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193322978.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193414462.png" alt=""></p>
<h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193458015.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194423952.png" alt=""></p>
<h4 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194708482.png" alt=""></p>
<p>Stochastic Gradient Descent: Instead of evaluating  gradients over all examples, evaluate it for each  individual training example.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194843074.png" alt=""></p>
<h3 id="Random-Walks：Summary"><a href="#Random-Walks：Summary" class="headerlink" title="Random Walks：Summary"></a>Random Walks：Summary</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195157506.png" alt=""></p>
<h3 id="How-should-we-randomly-walk"><a href="#How-should-we-randomly-walk" class="headerlink" title="How should we randomly walk?"></a>How should we randomly walk?</h3><ul>
<li>So far we have described how to optimize  embeddings given a random walk strategy R -</li>
<li>What strategies should we use to run these  random walks? <ul>
<li>Simplest idea: Just run fixed-length, unbiased  random walks starting from each node (i.e.,  DeepWalk from Perozzi et al., 2013) <ul>
<li>The issue is that such notion of similarity is too constrained </li>
</ul>
</li>
</ul>
</li>
<li>How can we generalize this?</li>
</ul>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Reference: Perozzi et al. 2014. DeepWalk: Online Learning of Social Representations. KDD</a></p>
<h3 id="Overview-of-node2vec"><a href="#Overview-of-node2vec" class="headerlink" title="Overview of node2vec"></a>Overview of node2vec</h3><p><a href="https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf" target="_blank" rel="noopener">Reference: Grover et al. 2016. node2vec: Scalable Feature Learning for Networks. KDD</a></p>
<ul>
<li>Goal: Embed nodes with similar network  neighborhoods close in the feature space. </li>
<li>We frame this goal as a maximum likelihood  optimization problem, independent to the  downstream prediction task.</li>
<li>Key observation: Flexible notion of network  neighborhood 𝑁_𝑅(𝑢) of node 𝑢 leads to rich node  embeddings</li>
<li>Develop biased 2^nd order random walk 𝑅 to  generate network neighborhood 𝑁_𝑅(𝑢) of node 𝑢</li>
</ul>
<h4 id="node2vec-Biased-Walks"><a href="#node2vec-Biased-Walks" class="headerlink" title="node2vec: Biased Walks"></a>node2vec: Biased Walks</h4><p>Idea: use flexible, biased random walks that can  trade off between local and global views of the  network (Grover and Leskovec, 2016). </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195719803.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195734036.png" alt=""></p>
<h4 id="BFS-VS-DFS"><a href="#BFS-VS-DFS" class="headerlink" title="BFS VS.DFS"></a>BFS VS.DFS</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114200935414.png" alt=""></p>
<ul>
<li>Biased fixed-length random walk 𝑹 that given a  node 𝒖 generates neighborhood 𝑵_𝑹(𝒖) <ul>
<li>Two parameters: <ul>
<li>Return parameter 𝒑: <ul>
<li>Return back to the previous node </li>
</ul>
</li>
</ul>
</li>
<li>In-out parameter 𝒒: <ul>
<li>Moving outwards (DFS) vs. inwards (BFS) </li>
<li>Intuitively, 𝑞 is the “ratio” of BFS vs. DFS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Biased-Random-Walks"><a href="#Biased-Random-Walks" class="headerlink" title="Biased Random Walks"></a>Biased Random Walks</h4><ul>
<li>Biased 2nd -order random walks explore network neighborhoods: <ul>
<li>Rnd. walk just traversed edge (𝑠1 , 𝑤) and is now at 𝑤 </li>
<li>Insight: Neighbors of 𝑤 can only be:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201220400.png" alt=""></p>
<p>Idea: Remember where the walk came from</p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
<li>𝑝, 𝑞 model transition probabilities <ul>
<li>𝑝 … return parameter </li>
<li>𝑞 … ”walk away” parameter</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201325434.png" alt=""></p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201455606.png" alt=""></p>
<h3 id="node2vec-algorithm"><a href="#node2vec-algorithm" class="headerlink" title="node2vec algorithm"></a>node2vec algorithm</h3><p>1) Compute random walk probabilities </p>
<p>2) Simulate 𝑟 random walks of length 𝑙 starting  from each node 𝑢 </p>
<p>3) Optimize the node2vec objective using  Stochastic Gradient Descent </p>
<p>   Linear-time complexity </p>
<p>   All 3 steps are individually parallelizable</p>
<h3 id="Other-Random-Walk-Ideas"><a href="#Other-Random-Walk-Ideas" class="headerlink" title="Other Random Walk Ideas"></a>Other Random Walk Ideas</h3><ul>
<li>Different kinds of biased random walks: <ul>
<li><a href="https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf" target="_blank" rel="noopener">Based on node attributes (Dong et al., 2017).</a> </li>
<li><a href="https://arxiv.org/abs/1710.09599" target="_blank" rel="noopener">Based on learned weights (Abu-El-Haija et al., 2017)</a> </li>
</ul>
</li>
<li>Alternative optimization schemes: <ul>
<li><a href="https://arxiv.org/abs/1503.03578" target="_blank" rel="noopener">Directly optimize based on 1-hop and 2-hop random walk  probabilities (as in LINE from Tang et al. 2015).</a> </li>
</ul>
</li>
<li>Network preprocessing techniques: <ul>
<li><a href="https://arxiv.org/abs/1706.07845" target="_blank" rel="noopener">Run random walks on modified versions of the original  network (e.g., Ribeiro et al. 2017’s struct2vec, Chen et al.  2016’s HARP).</a></li>
</ul>
</li>
</ul>
<h3 id="Summary-so-far"><a href="#Summary-so-far" class="headerlink" title="Summary so far"></a>Summary so far</h3><ul>
<li><p>Core idea: Embed nodes so that distances in  embedding space reflect node similarities in  the original network. </p>
</li>
<li><p>Different notions of node similarity: </p>
<ul>
<li>Naïve: similar if two nodes are connected </li>
<li>Neighborhood overlap (covered in Lecture 2) </li>
<li>Random walk approaches (covered today)</li>
</ul>
</li>
<li><p>So what method should I use..? </p>
</li>
<li><p>No one method wins in all cases…. </p>
<ul>
<li>E.g., node2vec performs better on node classification  while alternative methods perform better on link  prediction (<a href="https://arxiv.org/abs/1705.02801" target="_blank" rel="noopener">Goyal and Ferrara, 2017 survey)</a>. </li>
</ul>
</li>
<li><p>Random walk approaches are generally more  efficient. </p>
</li>
<li><p>In general: Must choose definition of node  similarity that matches your application.</p>
</li>
</ul>
<h2 id="Embedding-Entire-Graphs"><a href="#Embedding-Entire-Graphs" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h2><h3 id="Embedding-Entire-Graphs-1"><a href="#Embedding-Entire-Graphs-1" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114202611575.png" alt=""></p>
<h3 id="Approach-l"><a href="#Approach-l" class="headerlink" title="Approach l"></a>Approach l</h3><ul>
<li><p>Simple (but effective) approach 1:  </p>
<ul>
<li>Run a standard graph embedding  technique on the (sub)graph 𝐺. </li>
<li>Then just sum (or average) the node  embeddings in the (sub)graph 𝐺.</li>
</ul>
<img src="/images/loading.gif" data-original="../images/ML/image-20211114203010880.png" style="zoom:50%;">

</li>
</ul>
<p><a href="https://arxiv.org/abs/1509.09292" target="_blank" rel="noopener">Used by Duvenaud et al., 2016 to classify  molecules based on their graph structure</a></p>
<h3 id="Approach-2"><a href="#Approach-2" class="headerlink" title="Approach 2"></a>Approach 2</h3><p>Approach 2: Introduce a “virtual node” to  represent the (sub)graph and run a standard  graph embedding technique</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203037704.png" alt=""></p>
<p><a href="https://arxiv.org/abs/1511.05493" target="_blank" rel="noopener">Proposed by Li et al., 2016 as a general  technique for subgraph embedding</a></p>
<h3 id="Approach-3-Anonymous-Walk-Embeddings"><a href="#Approach-3-Anonymous-Walk-Embeddings" class="headerlink" title="Approach 3: Anonymous Walk Embeddings"></a>Approach 3: Anonymous Walk Embeddings</h3><p>States in anonymous(匿名的) walks correspond to the index of the first time we visited the node in a  random walk</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203144450.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<ul>
<li><p>Agnostic to the identity of the nodes visited  (hence anonymous) </p>
</li>
<li><p>Example: Random walk w1 :</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203318023.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203337873.png" alt=""></p>
<h4 id="Number-of-Walks-Grows"><a href="#Number-of-Walks-Grows" class="headerlink" title="Number of Walks Grows"></a>Number of Walks Grows</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203413849.png" alt=""></p>
<h4 id="Simple-Use-of-Anonymous-Walks"><a href="#Simple-Use-of-Anonymous-Walks" class="headerlink" title="Simple Use of Anonymous Walks"></a>Simple Use of Anonymous Walks</h4><ul>
<li><p>Simulate anonymous walks 𝑤𝑖 of 𝑙 steps and  record their counts. </p>
</li>
<li><p>Represent the graph as a probability  distribution over these walks. </p>
</li>
<li><p>For example:  </p>
<ul>
<li>Set 𝑙 = 3 </li>
<li>Then we can represent the graph as a 5-dim vector <ul>
<li>Since there are 5 anonymous walks 𝑤𝑖 of length 3: 111, 112,  121, 122, 123 </li>
</ul>
</li>
<li>𝒛_𝑮[𝑖] = probability of anonymous walk 𝑤𝑖 in graph 𝐺.</li>
</ul>
</li>
<li><p>Sampling anonymous walks: Generate  independently a set of 𝑚 random walks. </p>
</li>
<li><p>Represent the graph as a probability distribution  over these walks. </p>
</li>
<li><p>How many random walks 𝑚 do we need?</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203740427.png" alt=""></p>
<h3 id="New-idea-Learn-Walk-Embeddings"><a href="#New-idea-Learn-Walk-Embeddings" class="headerlink" title="New idea: Learn Walk Embeddings"></a>New idea: Learn Walk Embeddings</h3><p>Rather than simply representing each walk by the  fraction of times it occurs, we learn embedding 𝒛_𝒊 of anonymous walk 𝒘_𝒊 .</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203928449.png" alt=""></p>
<p>How to embed walks? </p>
<p>Idea: Embed walks s.t. the next walk can be  predicted</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204007342.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204043648.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204507319.png" alt=""></p>
<h3 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We discussed 3 ideas to graph embeddings: </li>
<li>Approach 1: Embed nodes and sum/avg them </li>
<li>Approach 2: Create super-node that spans the  (sub) graph and then embed that node. </li>
<li>Approach 3: Anonymous Walk Embeddings <ul>
<li>Idea 1: Sample the anon. walks and represent the  graph as fraction of times each anon walk occurs. </li>
<li>Idea 2: Learn graph embedding together with  anonymous walk embeddings.</li>
</ul>
</li>
</ul>
<h3 id="Preview-Hierarchical-Embeddings"><a href="#Preview-Hierarchical-Embeddings" class="headerlink" title="Preview: Hierarchical Embeddings"></a>Preview: Hierarchical Embeddings</h3><ul>
<li>We will discuss more advanced ways to obtain  graph embeddings in Lecture 8. </li>
<li>We can hierarchically cluster nodes in graphs,  and sum/avg the node embeddings according  to these clusters.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204746252.png" alt=""></p>
<h3 id="How-to-Use-Embeddings"><a href="#How-to-Use-Embeddings" class="headerlink" title="How to Use Embeddings"></a>How to Use Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204819921.png" alt=""></p>
<ul>
<li>Encoder-decoder framework: <ul>
<li>Encoder: embedding lookup </li>
<li>Decoder: predict score based on embedding to match  node similarity </li>
</ul>
</li>
<li>Node similarity measure: (biased) random walk <ul>
<li>Examples: DeepWalk, Node2Vec </li>
</ul>
</li>
<li>Extension to Graph embedding: Node embedding  aggregation and Anonymous Walk Embeddings</li>
</ul>
<h1 id="Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings"><a href="#Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings" class="headerlink" title="Graph as Matrix: Pagerank, Random Walks and Embeddings"></a>Graph as Matrix: Pagerank, Random Walks and Embeddings</h1><h2 id="Pagerank-aka-the-Google-Algorithm"><a href="#Pagerank-aka-the-Google-Algorithm" class="headerlink" title="Pagerank(aka the Google Algorithm)"></a>Pagerank(aka the Google Algorithm)</h2><h3 id="Example-The-Web-as-a-Graph"><a href="#Example-The-Web-as-a-Graph" class="headerlink" title="Example: The Web as a Graph"></a>Example: The Web as a Graph</h3><ul>
<li>Q: What does the Web “look like” at  a global level? </li>
<li>Web as a graph: <ul>
<li>Nodes = web pages </li>
<li>Edges = hyperlinks </li>
<li>Side issue: What is a node? <ul>
<li>Dynamic pages created on the fly </li>
<li>“dark matter” – inaccessible  database generated pages</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214917553.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214932840.png" alt=""></p>
<h3 id="What-Does-the-Web-Look-Like"><a href="#What-Does-the-Web-Look-Like" class="headerlink" title="What Does the Web Look Like?"></a>What Does the Web Look Like?</h3><ul>
<li>How is the Web linked? </li>
<li>What is the “map” of the Web? </li>
<li>Web as a directed graph [Broder et al. 2000]: <ul>
<li>Given node v, what nodes can v reach?  </li>
<li>What other nodes can reach v?</li>
</ul>
</li>
</ul>
<h3 id="Ranking-Nodes-on-the-Graph"><a href="#Ranking-Nodes-on-the-Graph" class="headerlink" title="Ranking Nodes on the Graph"></a>Ranking Nodes on the Graph</h3><ul>
<li>All web pages are not equally “important” <a href="http://www.thispersondoesnotexist.com" target="_blank" rel="noopener">www.thispersondoesnotexist.com</a> vs. <a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> </li>
<li>There is large diversity  in the web-graph  node connectivity. </li>
<li>So, let’s rank the pages  using the web graph link structure!</li>
</ul>
<h3 id="Link-Analysis-Algorithms"><a href="#Link-Analysis-Algorithms" class="headerlink" title="Link Analysis Algorithms"></a>Link Analysis Algorithms</h3><ul>
<li>We will cover the following Link Analysis approaches to compute the importance of  nodes in a graph: <ul>
<li>PageRank </li>
<li>Personalized PageRank (PPR) </li>
<li>Random Walk with Restarts</li>
</ul>
</li>
</ul>
<h3 id="Links-as-Votes"><a href="#Links-as-Votes" class="headerlink" title="Links as Votes"></a>Links as Votes</h3><ul>
<li>Idea: Links as votes <ul>
<li>Page is more important if it has more links <ul>
<li>In-coming links? Out-going links? </li>
</ul>
</li>
</ul>
</li>
<li>Think of in-links as votes: <ul>
<li><a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> has 23,400 in-links </li>
<li>thispersondoesnotexist.com has 1 in-link </li>
</ul>
</li>
<li>Are all in-links equal? <ul>
<li>Links from important pages count more </li>
<li>Recursive question! </li>
</ul>
</li>
</ul>
<h3 id="Pagerank-The”Flow”Model"><a href="#Pagerank-The”Flow”Model" class="headerlink" title="Pagerank: The”Flow”Model"></a>Pagerank: The”Flow”Model</h3><ul>
<li>A “vote” from an important page is worth more: <ul>
<li>Each link’s vote is proportional  to the importance of its source  page </li>
<li>If page i with importance ri has  di out-links, each link gets ri / di votes </li>
<li>Page j’s own importance rj is  the sum of the votes on its in-links</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215430610.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215601977.png" alt=""></p>
<h3 id="Pagerank-Matrix-Formulation"><a href="#Pagerank-Matrix-Formulation" class="headerlink" title="Pagerank: Matrix Formulation"></a>Pagerank: Matrix Formulation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215711107.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215755515.png" alt=""></p>
<h3 id="Connection-to-Random-Walk"><a href="#Connection-to-Random-Walk" class="headerlink" title="Connection to Random Walk"></a>Connection to Random Walk</h3><ul>
<li>Imagine a random web surfer: <ul>
<li>At any time 𝒕, surfer is on some page 𝑖 </li>
<li>At time 𝒕 + 𝟏, the surfer follows an  out-link from 𝒊 uniformly at random </li>
<li>Ends up on some page 𝒋 linked from 𝒊 </li>
<li>Process repeats indefinitely </li>
</ul>
</li>
<li>Let: <ul>
<li>𝒑(𝒕) … vector whose 𝑖^th coordinate is the  prob. that the surfer is at page 𝑖 at time 𝑡 </li>
<li>So, 𝒑(𝒕) is a probability distribution over pages</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114220023823.png" alt=""></p>
<h3 id="The-Stationary-Distribution"><a href="#The-Stationary-Distribution" class="headerlink" title="The Stationary Distribution"></a>The Stationary Distribution</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222138055.png" alt=""></p>
<h3 id="Recall-Eigenvector-of-A-Matrix"><a href="#Recall-Eigenvector-of-A-Matrix" class="headerlink" title="Recall Eigenvector of A Matrix"></a>Recall Eigenvector of A Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222334844.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222411167.png" alt=""></p>
<h3 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h3><p>PageRank: </p>
<ul>
<li>Measures importance of nodes in a graph using  the link structure of the web </li>
<li>Models a random web surfer using the stochastic  adjacency matrix 𝑴 </li>
<li>PageRank solves 𝒓 = 𝑴𝒓 where 𝒓 can be viewed  as both the principle eigenvector of 𝑴 and as the  stationary distribution of a random walk over the  graph</li>
</ul>
<h2 id="Pagerank-How-to-solve"><a href="#Pagerank-How-to-solve" class="headerlink" title="Pagerank: How to solve?"></a>Pagerank: How to solve?</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222947387.png" alt=""></p>
<h3 id="Power-Iteration-Method"><a href="#Power-Iteration-Method" class="headerlink" title="Power Iteration Method"></a>Power Iteration Method</h3><p>Given a web graph with N nodes, where the  nodes are pages and edges are hyperlinks</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223059886.png" alt=""></p>
<p>About 50 iterations is sufficient to estimate the limiting solution.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223659426.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223740435.png" alt=""></p>
<h3 id="Three-Ouestions"><a href="#Three-Ouestions" class="headerlink" title="Three Ouestions"></a>Three Ouestions</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223836586.png" alt=""></p>
<ul>
<li>Does this converge? </li>
<li>Does it converge to what we want? </li>
<li>Are results reasonable?</li>
</ul>
<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><p>Two problems: </p>
<p>(1) Some pages are  dead ends (have no out-links) </p>
<p>​    Such pages cause  importance to “leak out” </p>
<p>(2) Spider traps (all out-links are within the group) </p>
<p>​    Eventually spider traps absorb all importance</p>
<h3 id="Does-this-converge"><a href="#Does-this-converge" class="headerlink" title="Does this converge"></a>Does this converge</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224138856.png" alt=""></p>
<h3 id="Does-it-converge-to-what-we-want"><a href="#Does-it-converge-to-what-we-want" class="headerlink" title="Does it converge to what we want?"></a>Does it converge to what we want?</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224207948.png" alt=""></p>
<h3 id="Solution-to-Spider-Traps"><a href="#Solution-to-Spider-Traps" class="headerlink" title="Solution to Spider Traps"></a>Solution to Spider Traps</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224305329.png" alt=""></p>
<h3 id="Solution-to-Dead-Ends"><a href="#Solution-to-Dead-Ends" class="headerlink" title="Solution to Dead Ends"></a>Solution to Dead Ends</h3><ul>
<li>Teleports: Follow random teleport links with  total probability 1.0 from dead-ends <ul>
<li>Adjust matrix accordingly</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224421867.png" alt=""></p>
<h3 id="Why-Teleports-Solve-the-Problem"><a href="#Why-Teleports-Solve-the-Problem" class="headerlink" title="Why Teleports Solve the Problem?"></a>Why Teleports Solve the Problem?</h3><ul>
<li>Why are dead-ends and spider traps a problem  and why do teleports solve the problem? </li>
<li>Spider-traps are not a problem, but with traps  PageRank scores are not what we want <ul>
<li>Solution: Never get stuck in a spider trap by  teleporting out of it in a finite number of steps </li>
</ul>
</li>
<li>Dead-ends are a problem <ul>
<li>The matrix is not column stochastic so our initial  assumptions are not met </li>
<li>Solution: Make matrix column stochastic by always  teleporting when there is nowhere else to go</li>
</ul>
</li>
</ul>
<h3 id="Solution-Random-Teleports"><a href="#Solution-Random-Teleports" class="headerlink" title="Solution: Random Teleports"></a>Solution: Random Teleports</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224754314.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224833186.png" alt=""></p>
<h4 id="Random-Teleports-beta-0-8"><a href="#Random-Teleports-beta-0-8" class="headerlink" title="Random Teleports(beta=0.8)"></a>Random Teleports(beta=0.8)</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224910775.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224924774.png" alt=""></p>
<h3 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank solves for 𝒓 = 𝑮𝒓 and can be  efficiently computed by power iteration of the  stochastic adjacency matrix (𝑮)  </li>
<li>Adding random uniform teleportation solves  issues of dead-ends and spider-traps</li>
</ul>
<h2 id="Random-Walk-with-Restarts-and-Personalized-Pagerank"><a href="#Random-Walk-with-Restarts-and-Personalized-Pagerank" class="headerlink" title="Random Walk with Restarts and Personalized Pagerank"></a>Random Walk with Restarts and Personalized Pagerank</h2><h3 id="Example-Recommendation"><a href="#Example-Recommendation" class="headerlink" title="Example: Recommendation"></a>Example: Recommendation</h3><p>Given:  A bipartite graph representing user and item  interactions (e.g. purchase) </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225052686.png" alt=""></p>
<p>Goal: Proximity on graphs </p>
<ul>
<li>What items should we recommend to a user who  interacts with item Q? </li>
<li>Intuition: if items Q and P are interacted by similar  users, recommend P when user interacts with Q</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225134281.png" alt=""></p>
<p>Which is more related A,A’ or B,B’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225159496.png" alt=""></p>
<h3 id="Node-proximity-Measurements"><a href="#Node-proximity-Measurements" class="headerlink" title="Node proximity Measurements"></a>Node proximity Measurements</h3><p>Which is more related A,A’, B,B’ or C,C’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225227419.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225246889.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225258445.png" alt=""></p>
<h3 id="Proximity-on-Graphs"><a href="#Proximity-on-Graphs" class="headerlink" title="Proximity on Graphs"></a>Proximity on Graphs</h3><p>PageRank: </p>
<ul>
<li>Ranks nodes by “importance” </li>
<li>Teleports(传送) with uniform probability to any node in  the network </li>
</ul>
<p>Personalized PageRank: </p>
<ul>
<li>Ranks proximity of nodes to the teleport nodes 𝑺 </li>
</ul>
<p>Proximity(接近) on graphs: </p>
<ul>
<li>Q: What is most related item to Item Q? </li>
<li>Random Walks with Restarts <ul>
<li>Teleport back to the starting node: 𝑺 = {𝑸}</li>
</ul>
</li>
</ul>
<h3 id="Idea-Random-Walks"><a href="#Idea-Random-Walks" class="headerlink" title="Idea: Random Walks"></a>Idea: Random Walks</h3><ul>
<li>Idea <ul>
<li>Every node has some importance </li>
<li>Importance gets evenly split among all edges and  pushed to the neighbors: </li>
</ul>
</li>
<li>Given a set of QUERY_NODES, we simulate a  random walk: <ul>
<li>Make a step to a random neighbor and record the visit  (visit count) </li>
<li>With probability ALPHA, restart the walk at one of the  QUERY_NODES </li>
<li>The nodes with the highest visit count have highest  proximity to the QUERY_NODES</li>
</ul>
</li>
</ul>
<p>Idea: </p>
<ul>
<li>Every node has some importance <ul>
<li>Importance gets evenly split among all edges and  pushed to the neighbors </li>
<li>Given a set of QUERY NODES Q, simulate a  random walk:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230011267.png" alt=""></p>
<h3 id="Random-Walk-Algorithm"><a href="#Random-Walk-Algorithm" class="headerlink" title="Random Walk Algorithm"></a>Random Walk Algorithm</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230036155.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230058590.png" alt=""></p>
<h3 id="Benefits"><a href="#Benefits" class="headerlink" title="Benefits"></a>Benefits</h3><p>Why is this a good solution? </p>
<p>Because the “similarity” considers: </p>
<ul>
<li>Multiple connections </li>
<li>Multiple paths </li>
<li>Direct and indirect connections </li>
<li>Degree of the node</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230143054.png" alt=""></p>
<h3 id="Summary-Page-Rank-Variants"><a href="#Summary-Page-Rank-Variants" class="headerlink" title="Summary: Page Rank Variants"></a>Summary: Page Rank Variants</h3><ul>
<li><p>PageRank: </p>
<ul>
<li>Teleports to any node </li>
<li>Nodes can have the same probability of the surfer landing: 𝑺 = [0.1,0.1,0.1, 0.1,0.1,0.1, 0.1,0.1,0.1, 0.1] </li>
</ul>
</li>
<li><p>Topic-Specific PageRank aka Personalized PageRank: </p>
<ul>
<li>Teleports to a specific set of nodes </li>
<li>Nodes can have different probabilities of the surfer landing  there: 𝑺 = [0.1,0, 0,0.2, 0, 0,0.5,0,0, 0.2] </li>
</ul>
</li>
<li><p>Random Walk with Restarts: </p>
<ul>
<li>Topic-Specific PageRank where teleport is always to the same  node: 𝑺 = [0,0, 0,0, 𝟏, 0, 0, 0, 0, 0,0]</li>
</ul>
</li>
</ul>
<ul>
<li>A graph is naturally represented as a matrix </li>
<li>We defined a random walk process over the  graph <ul>
<li>Random surfer moving across the links and with  random teleportation </li>
<li>Stochastic adjacency matrix M </li>
</ul>
</li>
<li>PageRank = Limiting distribution of the surfer  location represented node importance <ul>
<li>Corresponds to the leading eigenvector of  transformed adjacency matrix M.</li>
</ul>
</li>
</ul>
<h2 id="Matrix-Factorization-and-Node-Embeddings"><a href="#Matrix-Factorization-and-Node-Embeddings" class="headerlink" title="Matrix Factorization and Node Embeddings"></a>Matrix Factorization and Node Embeddings</h2><h3 id="Embeddings-Matrix-Factorization-因式分解"><a href="#Embeddings-Matrix-Factorization-因式分解" class="headerlink" title="Embeddings Matrix Factorization(因式分解)"></a>Embeddings Matrix Factorization(因式分解)</h3><p>Recall: encoder as an embedding lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230445458.png" alt=""></p>
<h3 id="Connection-to-Matrix-Factorization"><a href="#Connection-to-Matrix-Factorization" class="headerlink" title="Connection to Matrix Factorization"></a>Connection to Matrix Factorization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230551299.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230605362.png" alt=""></p>
<h3 id="Random-Walk-based-Similarity"><a href="#Random-Walk-based-Similarity" class="headerlink" title="Random Walk-based Similarity"></a>Random Walk-based Similarity</h3><ul>
<li>DeepWalk and node2vec have a more  complex node similarity definition based on  random walks </li>
<li>DeepWalk is equivalent to matrix  factorization of the following complex matrix  expression:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230645556.png" alt=""></p>
<p><a href="https://keg.cs.tsinghua.edu.cn/jietang/publications/WSDM18-Qiu-et-al-NetMF-network-embedding.pdf" target="_blank" rel="noopener">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec, WSDM 18</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230726746.png" alt=""></p>
<p>Node2vec can also be formulated as a matrix  factorization (albeit a more complex matrix)</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>Limitations of node embeddings via matrix  factorization and random walks </p>
<ul>
<li>Cannot obtain embeddings for nodes not in the  training set</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230810157.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230825196.png" alt=""></p>
<ul>
<li>Node 1 and 11 are structurally similar – part of  one triangle, degree 2, … </li>
<li>However, they have very different embeddings. <ul>
<li>It’s unlikely that a random walk will reach  node 11 from node 1. </li>
</ul>
</li>
<li>DeepWalk and node2vec do not capture  structural similarity.</li>
<li>Cannot utilize node, edge and graph features</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230907768.png" alt=""></p>
<p>Solution to these limitations: Deep Representation  Learning and Graph Neural Networks </p>
<h3 id="Summary-5"><a href="#Summary-5" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank <ul>
<li>Measures importance of nodes in graph </li>
<li>Can be efficiently computed by power iteration of  adjacency matrix </li>
</ul>
</li>
<li>Personalized PageRank (PPR) <ul>
<li>Measures importance of nodes with respect to a  particular node or set of nodes </li>
<li>Can be efficiently computed by random walk </li>
</ul>
</li>
<li>Node embeddings based on random walks can  be expressed as matrix factorization </li>
<li>Viewing graphs as matrices plays a key role in all  above algorithms!</li>
</ul>
<h1 id="Message-Passing-and-Node-Classification"><a href="#Message-Passing-and-Node-Classification" class="headerlink" title="Message Passing and Node Classification"></a>Message Passing and Node Classification</h1><h2 id="Example-Node-Classification"><a href="#Example-Node-Classification" class="headerlink" title="Example Node Classification"></a>Example Node Classification</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225627573.png" alt=""></p>
<ul>
<li>Given labels of some nodes </li>
<li>Let’s predict labels of unlabeled nodes </li>
<li>This is called <strong>semi-supervised node classification</strong></li>
</ul>
<h3 id="Correlations-相关性-Exist-in-Networks"><a href="#Correlations-相关性-Exist-in-Networks" class="headerlink" title="Correlations(相关性) Exist in Networks"></a>Correlations(相关性) Exist in Networks</h3><ul>
<li><p>Behaviors of nodes are correlated across the  links of the network </p>
</li>
<li><p>Correlation: Nearby nodes have the same  color (belonging to the same class)</p>
</li>
<li><p>Two explanations for why behaviors of nodes  in networks are correlated:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225929813.png" alt=""></p>
<h3 id="Social-Homophily-趋同性"><a href="#Social-Homophily-趋同性" class="headerlink" title="Social Homophily(趋同性)"></a>Social Homophily(趋同性)</h3><ul>
<li>Homophily: The tendency of  individuals to associate and bond  with similar others <ul>
<li>“Birds of a feather flock together”</li>
<li>It has been observed in a vast array of  network studies, based on a variety of  attributes (e.g., age, gender,  organizational role, etc.) </li>
<li>Example: Researchers who focus on  the same research area are more likely  to establish a connection (meeting at  conferences, interacting in academic  talks, etc.)</li>
</ul>
</li>
</ul>
<p><strong>Example of homophily</strong> </p>
<ul>
<li>Online social network <ul>
<li>Nodes = people</li>
<li>Edges = friendship</li>
<li>Node color = interests  (sports, arts, etc.)</li>
</ul>
</li>
<li>People with the same  interest are more closely  connected due to  homophily</li>
</ul>
<h3 id="Social-Influence-Example"><a href="#Social-Influence-Example" class="headerlink" title="Social Influence Example"></a>Social Influence Example</h3><ul>
<li>Influence: Social connections can  influence the individual  characteristics of a person. <ul>
<li>Example: I recommend my musical  preferences to my friends, until one of  them grows to like my same favorite  genres!</li>
</ul>
</li>
</ul>
<h2 id="How-do-we-leverage-node-correlations-in-networks"><a href="#How-do-we-leverage-node-correlations-in-networks" class="headerlink" title="How do we leverage node correlations in networks?"></a>How do we leverage node correlations in networks?</h2><h3 id="Classification-with-Network-Data"><a href="#Classification-with-Network-Data" class="headerlink" title="Classification with Network Data"></a>Classification with Network Data</h3><p>How do we leverage(影响力) this correlation observed  in networks to help predict node labels?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230602159.png" alt=""></p>
<p>How do we predict the labels for the nodes in grey?</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li><p>Similar nodes are typically close together or  directly connected in the network: </p>
<ul>
<li>Guilt-by-association: If I am connected to a  node with label X, then I am likely to have  label X as well. </li>
<li>Example: Malicious/benign web page: Malicious web pages link to one another to  increase visibility, look credible, and rank  higher in search engines</li>
</ul>
</li>
<li><p>Classification label of a node v in network  may depend on: </p>
<ul>
<li>Features of v </li>
<li>Labels of the nodes in v’s neighborhood </li>
<li>Features of the nodes in v’s neighborhood</li>
</ul>
</li>
</ul>
<h3 id="Semi-supervised-Learning"><a href="#Semi-supervised-Learning" class="headerlink" title="Semi-supervised Learning"></a>Semi-supervised Learning</h3><ul>
<li><p>Formal setting: </p>
<ul>
<li>Given:  <ul>
<li>Graph </li>
<li>Few labeled nodes </li>
</ul>
</li>
<li>Find: Class (red/green) of  remaining nodes </li>
<li>Main assumption: There is  homophily in the network</li>
</ul>
</li>
<li><p>Example task:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230940679.png" alt=""></p>
<h4 id="Problem-Setting"><a href="#Problem-Setting" class="headerlink" title="Problem Setting"></a>Problem Setting</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231029875.png" alt=""></p>
<h4 id="Example-applications"><a href="#Example-applications" class="headerlink" title="Example applications"></a>Example applications</h4><ul>
<li>Many applications under this setting: <ul>
<li>Document classification  </li>
<li>Part of speech tagging  </li>
<li>Link prediction  </li>
<li>Optical character recognition  </li>
<li>Image/3D data segmentation  </li>
<li>Entity resolution in sensor networks  </li>
<li>Spam and fraud detection</li>
</ul>
</li>
</ul>
<p>We focus on semi-supervised binary node classification </p>
<p>We will introduce three approaches: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h2 id="Relational-Classification"><a href="#Relational-Classification" class="headerlink" title="Relational Classification"></a>Relational Classification</h2><h3 id="Probabilistic-Relational-Classifier"><a href="#Probabilistic-Relational-Classifier" class="headerlink" title="Probabilistic Relational Classifier"></a>Probabilistic Relational Classifier</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231427817.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231506341.png" alt=""></p>
<p>Challenges: </p>
<ul>
<li>Convergence is not guaranteed </li>
<li>Model cannot use node feature information</li>
</ul>
<h3 id="Example-Initialization"><a href="#Example-Initialization" class="headerlink" title="Example: Initialization"></a>Example: Initialization</h3><p>Initialization: </p>
<ul>
<li>All labeled nodes with their labels </li>
<li>All unlabeled nodes 0.5 (belonging to class 1 with  probability 0.5)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231641765.png" alt=""></p>
<h3 id="Example-lst-Iteration-Update-Node"><a href="#Example-lst-Iteration-Update-Node" class="headerlink" title="Example: lst Iteration, Update Node"></a>Example: lst Iteration, Update Node</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231741748.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231846430.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231924192.png" alt=""></p>
<h3 id="Example-After-1st-Iteration"><a href="#Example-After-1st-Iteration" class="headerlink" title="Example: After 1st Iteration"></a>Example: After 1st Iteration</h3><p>After Iteration 1 (a round of updates for all  unlabeled nodes)</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232015529.png" alt=""></p>
<h3 id="Example-After-2nd-Iteration"><a href="#Example-After-2nd-Iteration" class="headerlink" title="Example: After 2nd Iteration"></a>Example: After 2nd Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232051667.png" alt=""></p>
<h3 id="Example-After-3-Iteration"><a href="#Example-After-3-Iteration" class="headerlink" title="Example: After 3] Iteration"></a>Example: After 3] Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232207605.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232229830.png" alt=""></p>
<h3 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232257216.png" alt=""></p>
<h2 id="Iterative-迭代的-Classification"><a href="#Iterative-迭代的-Classification" class="headerlink" title="Iterative(迭代的) Classification"></a>Iterative(迭代的) Classification</h2><p>Relational classifier does not use node  attributes.  </p>
<p>How can one leverage them?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232406683.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232421194.png" alt=""></p>
<h3 id="Computing-the-Summary-Z-v"><a href="#Computing-the-Summary-Z-v" class="headerlink" title="Computing the Summary Z_v"></a>Computing the Summary Z_v</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232625455.png" alt=""></p>
<h3 id="Architecture-of-Iterative-Classifiers"><a href="#Architecture-of-Iterative-Classifiers" class="headerlink" title="Architecture of Iterative Classifiers"></a>Architecture of Iterative Classifiers</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232728306.png" alt=""></p>
<h3 id="Example-Web-Page-Classification"><a href="#Example-Web-Page-Classification" class="headerlink" title="Example: Web Page Classification"></a>Example: Web Page Classification</h3><ul>
<li>Input: Graph of web pages </li>
<li>Node: Web page </li>
<li>Edge: Hyper-link between web pages </li>
<li>Directed edge: a page points to another page <ul>
<li>Node features: Webpage description </li>
</ul>
</li>
<li>For simplicity, we only consider two binary features <ul>
<li>Task: Predict the topic of the webpage</li>
</ul>
</li>
</ul>
<p>Baseline: Train a classifier (e.g., linear classifier) to  classify pages based on node attributes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232938924.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232956241.png" alt=""></p>
<h3 id="Iterative-Classifier"><a href="#Iterative-Classifier" class="headerlink" title="Iterative Classifier"></a>Iterative Classifier</h3><h4 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233242445.png" alt=""></p>
<h4 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233317039.png" alt=""></p>
<h4 id="step-3-1"><a href="#step-3-1" class="headerlink" title="step 3. 1"></a>step 3. 1<img src="/images/loading.gif" data-original="../images/ML/image-20211116233349992.png" alt=""></h4><h4 id="step-3-2"><a href="#step-3-2" class="headerlink" title="step 3. 2"></a>step 3. 2<img src="/images/loading.gif" data-original="../images/ML/image-20211116233427721.png" alt=""></h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233537476.png" alt=""></p>
<h4 id="Final-Prediction"><a href="#Final-Prediction" class="headerlink" title="Final Prediction"></a>Final Prediction</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233603237.png" alt=""></p>
<h3 id="Summary-6"><a href="#Summary-6" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We talked about 2 approaches to collective  classification </li>
<li>Relational classification <ul>
<li>Iteratively update probabilities of node belonging  to a label class based on its neighbors </li>
</ul>
</li>
<li>Iterative classification <ul>
<li>Improve over collective classification to handle  attribute/feature information </li>
<li>Classify node v based on its features as well as  labels of neighbors</li>
</ul>
</li>
</ul>
<h2 id="Collective-Classification-Correct-amp-Smooth"><a href="#Collective-Classification-Correct-amp-Smooth" class="headerlink" title="Collective Classification Correct &amp; Smooth"></a>Collective Classification Correct &amp; Smooth</h2><h3 id="Correct-amp-Smooth"><a href="#Correct-amp-Smooth" class="headerlink" title="Correct &amp; Smooth"></a>Correct &amp; Smooth</h3><p><a href="https://arxiv.org/abs/2010.13993" target="_blank" rel="noopener">Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</a></p>
<p><a href="https://ogb.stanford.edu/docs/leader_nodeprop/" target="_blank" rel="noopener">OGB leaderboard</a> snapshot at Oct 1st, 2021</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233952486.png" alt=""></p>
<p>Setting: A partially labeled graph and features  over nodes.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234021971.png" alt=""></p>
<p>C&amp;S follows the three-step procedure: </p>
<ol>
<li>Train base predictor </li>
<li>Use the base predictor to predict soft labels of all nodes. </li>
<li>Post-process the predictions using graph structure to  obtain the final predictions of all nodes.</li>
</ol>
<h3 id="Train-Base-Predictor"><a href="#Train-Base-Predictor" class="headerlink" title="Train Base Predictor"></a>Train Base Predictor</h3><p>Train a base predictor that predict soft  labels (class probabilities) over all nodes. </p>
<ul>
<li>Labeled nodes are used for train/validation data. </li>
<li>Base predictor can be simple: <ul>
<li>Linear model/Multi-Layer-Perceptron(MLP) over node  features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234148551.png" alt=""></p>
<h3 id="Predict-Over-All-Nodes"><a href="#Predict-Over-All-Nodes" class="headerlink" title="Predict Over All Nodes"></a>Predict Over All Nodes</h3><p>Given a trained base predictor, we apply it  to obtain soft labels for all the nodes. </p>
<ul>
<li>We expect these soft labels to be decently accurate. </li>
<li>Can we use graph structure to post-process the  predictions to make them more accurate?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234246360.png" alt=""></p>
<h3 id="Post-process-Predictions"><a href="#Post-process-Predictions" class="headerlink" title="Post-process Predictions"></a>Post-process Predictions</h3><p>C&amp;S uses the 2-step procedure to post-process the soft predictions. </p>
<ol>
<li>Correct step</li>
<li>Smooth step</li>
</ol>
<h3 id="C-amp-S-Post-processing-Correct-Step"><a href="#C-amp-S-Post-processing-Correct-Step" class="headerlink" title="C&amp;S Post-processing: Correct Step"></a>C&amp;S Post-processing: Correct Step</h3><ul>
<li>The key idea is that we expect errors in the base  prediction to be positively correlated along  edges in the graph.  </li>
<li>In other words, an error at node u increases the  chance of a similar error at neighbors of u.  </li>
<li>Thus, we should “spread” such uncertainty over the  graph</li>
</ul>
<h3 id="Intuition-of-Correct-amp-Smooth"><a href="#Intuition-of-Correct-amp-Smooth" class="headerlink" title="Intuition of Correct &amp; Smooth"></a>Intuition of Correct &amp; Smooth</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234441693.png" alt=""></p>
<h3 id="Correct-Step"><a href="#Correct-Step" class="headerlink" title="Correct Step"></a>Correct Step</h3><ul>
<li>Compute training errors of nodes. <ul>
<li>Training error: Ground-truth label minus soft label.  Defined as 0 for unlabeled nodes.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234544537.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234836282.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234914939.png" alt=""></p>
<p><a href="https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf" target="_blank" rel="noopener">Zhu et al. ICML 2013</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234952059.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235007332.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235025205.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235042742.png" alt=""></p>
<h3 id="Smooth-Step"><a href="#Smooth-Step" class="headerlink" title="Smooth Step"></a>Smooth Step</h3><ul>
<li>Smoothen the corrected soft labels along the  edges. <ul>
<li>Assumption: Neighboring nodes tend to share the  same labels.  </li>
<li>Note: For training nodes, we use the ground-truth  hard labels instead of the soft labels.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235129283.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235142063.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235155937.png" alt=""></p>
<h3 id="Toy-Example-Summary"><a href="#Toy-Example-Summary" class="headerlink" title="Toy Example Summary"></a>Toy Example Summary</h3><p>Our toy example shows that C&amp;S successfully  improves base model performance using  graph structure.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235223544.png" alt=""></p>
<h3 id="C-amp-S-on-a-Real-world-Dataset"><a href="#C-amp-S-on-a-Real-world-Dataset" class="headerlink" title="C&amp;S on a Real-world Dataset"></a>C&amp;S on a Real-world Dataset</h3><p>C&amp;S significantly improves the performance  of the base model (MLP). </p>
<p>C&amp;S outperforms Smooth-only (no correct  step) baseline.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235256008.png" alt=""></p>
<h3 id="Summary-7"><a href="#Summary-7" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Correct &amp; Smooth (C&amp;S) uses graph structure  to post-process the soft node labels predicted  by any base model. </li>
<li><strong>Correction step</strong>: Diffuse and correct for the  training errors of the base predictor. </li>
<li><strong>Smooth step</strong>: Smoothen the prediction of the  base predictor. </li>
<li>C&amp;S achieves strong performance on semisupervised node classification</li>
</ul>
<p>We learned how to leverage correlation in  graphs to make prediction on nodes. </p>
<p>Key techniques: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h1 id="Graph-Neural-Networks"><a href="#Graph-Neural-Networks" class="headerlink" title="Graph Neural Networks"></a>Graph Neural Networks</h1><h2 id="Basics-of-Deep-Learning"><a href="#Basics-of-Deep-Learning" class="headerlink" title="Basics of Deep Learning"></a>Basics of Deep Learning</h2><h2 id="Deep-Learning-for-Graphs"><a href="#Deep-Learning-for-Graphs" class="headerlink" title="Deep Learning for Graphs"></a>Deep Learning for Graphs</h2><h3 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h3><ul>
<li>Local network neighborhoods: <ul>
<li>Describe aggregation strategies </li>
<li>Define computation graphs </li>
</ul>
</li>
<li>Stacking multiple layers: <ul>
<li>Describe the model, parameters, training </li>
<li>How to fit the model? </li>
<li>Simple example for unsupervised and  supervised training</li>
</ul>
</li>
</ul>
<h3 id="Setup-1"><a href="#Setup-1" class="headerlink" title="Setup"></a>Setup</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160355282.png" alt=""></p>
<h3 id="A-Naive-Approach"><a href="#A-Naive-Approach" class="headerlink" title="A Naive Approach"></a>A Naive Approach</h3><ul>
<li>Join adjacency matrix and features </li>
<li>Feed them into a deep neural net:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160533035.png" alt=""></p>
<p>Issues with this idea: </p>
<ul>
<li>O(|V|) parameters </li>
<li>Not applicable to graphs of different sizes </li>
<li>Sensitive to node ordering</li>
</ul>
<h3 id="Idea-Convolutional-Networks"><a href="#Idea-Convolutional-Networks" class="headerlink" title="Idea: Convolutional Networks"></a>Idea: Convolutional Networks</h3><p>Goal is to generalize convolutions beyond simple lattices（格子） </p>
<p>Leverage node features/attributes (e.g., text, images)</p>
<h3 id="Real-world-Graphs"><a href="#Real-world-Graphs" class="headerlink" title="Real-world Graphs"></a><img src="/images/loading.gif" data-original="../images/basic/image-20211118160820640.png" alt="">Real-world Graphs</h3><p>But our graphs look like this:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160936978.png" alt=""></p>
<p>There is no fixed notion of locality or sliding  window on the graph </p>
<p>Graph is permutation invariant</p>
<h3 id="Permutation-Invariance（置换不变性）"><a href="#Permutation-Invariance（置换不变性）" class="headerlink" title="Permutation Invariance（置换不变性）"></a><strong>Permutation Invariance（置换不变性）</strong></h3><ul>
<li>Graph does not have a canonical order of the nodes! </li>
<li>We can have many different order plans.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161107818.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161127139.png" alt=""></p>
<p>Graph and node representations  should be the same for Order plan 1 and Order plan 2</p>
<p>What does it mean by “graph representation is  same for two order plans”?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161207951.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118171943856.png" alt=""></p>
<h3 id="Permutation-Equivariance（置换等变）"><a href="#Permutation-Equivariance（置换等变）" class="headerlink" title="Permutation Equivariance（置换等变）"></a>Permutation Equivariance（置换等变）</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172015343.png" alt="">For node representation</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172455838.png" alt=""></p>
<h3 id="Graph-Neural-Network-Overview"><a href="#Graph-Neural-Network-Overview" class="headerlink" title="Graph Neural Network Overview"></a>Graph Neural Network Overview</h3><p>Graph neural networks consist of multiple  permutation equivariant / invariant functions</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172659819.png" alt=""></p>
<p>Next: Design graph neural  networks that are permutation  invariant / equivariant by  passing and aggregating  information from neighbors</p>
<h2 id="Graph-Convolutional-Networks"><a href="#Graph-Convolutional-Networks" class="headerlink" title="Graph Convolutional Networks"></a>Graph Convolutional Networks</h2><p>Idea: Node’s neighborhood defines a  computation graph</p>
<p>Learn how to propagate information across the  graph to compute node features</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173222021.png" alt=""></p>
<h3 id="Idea-Aggregate-Neiahbors"><a href="#Idea-Aggregate-Neiahbors" class="headerlink" title="Idea: Aggregate Neiahbors"></a>Idea: Aggregate Neiahbors</h3><p>Key idea: Generate node embeddings based  on local network neighborhoods</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173341846.png" alt=""></p>
<p>Intuition: Nodes aggregate information from  their neighbors using neural networks</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173504017.png" alt=""></p>
<h3 id="Deep-Model-Many-Layers"><a href="#Deep-Model-Many-Layers" class="headerlink" title="Deep Model: Many Layers"></a>Deep Model: Many Layers</h3><p>Model can be of arbitrary depth: </p>
<p>Nodes have embeddings at each layer </p>
<p>Layer-0 embedding of node v is its input feature, x_v </p>
<p>Layer-k embedding gets information from nodes that are k hops away</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173642097.png" alt=""></p>
<h3 id="Neighborhood-Aggregation-聚集"><a href="#Neighborhood-Aggregation-聚集" class="headerlink" title="Neighborhood Aggregation(聚集)"></a>Neighborhood Aggregation(聚集)</h3><p>Neighborhood aggregation: Key distinctions  are in how different approaches aggregate  information across the layers</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173805151.png" alt=""></p>
<p>Basic approach: Average information from  neighbors and apply a neural network</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173840669.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173904027.png" alt=""></p>
<h3 id="Equivariant-Property"><a href="#Equivariant-Property" class="headerlink" title="Equivariant Property"></a>Equivariant Property</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174540447.png" alt=""></p>
<p>The target node (blue) has  the same computation graph  for different order plans</p>
<h3 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174741645.png" alt=""></p>
<p>Need to define a loss function on the embeddings.</p>
<h3 id="Model-Parameters"><a href="#Model-Parameters" class="headerlink" title="Model Parameters"></a>Model Parameters</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174912365.png" alt=""></p>
<h3 id="Matrix-Formulation"><a href="#Matrix-Formulation" class="headerlink" title="Matrix Formulation"></a>Matrix Formulation</h3><p>Many aggregations can be performed  efficiently by (sparse) matrix operations</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175202660.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175300420.png" alt=""></p>
<p>Note: not all GNNs can be expressed in matrix form, when  aggregation function is complex</p>
<h3 id="How-to-Train-A-GNN"><a href="#How-to-Train-A-GNN" class="headerlink" title="How to Train A GNN"></a>How to Train A GNN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175458003.png" alt=""></p>
<h4 id="Unsupervised-Training"><a href="#Unsupervised-Training" class="headerlink" title="Unsupervised Training"></a>Unsupervised Training</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175554816.png" alt=""></p>
<p>Node similarity can be anything from  Lecture 3, e.g., a loss based on: </p>
<ul>
<li>Random walks (node2vec, DeepWalk, struc2vec) </li>
<li>Matrix factorization </li>
<li>Node proximity in the grap</li>
</ul>
<h4 id="Supervised-Training"><a href="#Supervised-Training" class="headerlink" title="Supervised Training"></a>Supervised Training</h4><p>Directly train the model for a supervised task  (e.g., node classification)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175707510.png" alt=""></p>
<p>Directly train the model for a supervised task  (e.g., node classification) </p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175750731.png" alt=""></p>
<h3 id="Model-Design-Overview"><a href="#Model-Design-Overview" class="headerlink" title="Model Design: Overview"></a>Model Design: Overview</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175855277.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175932975.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175959015.png" alt=""></p>
<h3 id="Inductive-Capability"><a href="#Inductive-Capability" class="headerlink" title="Inductive Capability"></a>Inductive Capability</h3><p>The same aggregation parameters are shared  for all nodes: </p>
<ul>
<li><p>The number of model parameters is sublinear in  |V| and we can <strong>generalize to unseen nodes</strong>!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180108993.png" alt=""></p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180222936.png" alt=""></p>
<p>Inductive node embedding  =&gt; Generalize to entirely unseen graphs </p>
<p>E.g., train on protein interaction graph from model organism A and generate  embeddings on newly collected data about organism B</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180326559.png" alt=""></p>
<p>Many application settings constantly encounter  previously unseen nodes: </p>
<ul>
<li>E.g., Reddit, YouTube, Google Scholar </li>
</ul>
<p>Need to generate new embeddings “on the fly”</p>
<h2 id="GNNs-subsume-CNNs-and-Transformers"><a href="#GNNs-subsume-CNNs-and-Transformers" class="headerlink" title="GNNs subsume CNNs and  Transformers"></a>GNNs subsume CNNs and  Transformers</h2><h3 id="Architecture-Comparison"><a href="#Architecture-Comparison" class="headerlink" title="Architecture Comparison"></a>Architecture Comparison</h3><p>How does GNNs compare to prominent  architectures such as Convolutional Neural  Nets, and Transformers?</p>
<h3 id="GNN-VS-CNN"><a href="#GNN-VS-CNN" class="headerlink" title="GNN VS. CNN"></a>GNN VS. CNN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180612722.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180749671.png" alt=""></p>
<p>CNN can be seen as a special GNN with fixed neighbor  size and ordering: </p>
<ul>
<li>The size of the filter is pre-defined for a CNN. </li>
<li>The advantage of GNN is it processes arbitrary  graphs with different degrees for each node</li>
</ul>
<p>CNN is not permutation equivariant. </p>
<ul>
<li>Switching the order of pixels will leads to different  outputs</li>
</ul>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>[Attention is all you need. Vaswani et al., NeurIPS 2017]</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181019045.png" alt=""></p>
<h3 id="GNN-vs-Transformer"><a href="#GNN-vs-Transformer" class="headerlink" title="GNN vs, Transformer"></a>GNN vs, Transformer</h3><p>A nice blog plot for this: <a href="https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa" target="_blank" rel="noopener">https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181135494.png" alt=""></p>
<h3 id="Summary-8"><a href="#Summary-8" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Basics of neural networks <ul>
<li>Loss, Optimization, Gradient, SGD, non-linearity, MLP</li>
</ul>
</li>
<li>Idea for Deep Learning for Graphs <ul>
<li>Multiple layers of embedding transformation </li>
<li>At every layer, use the embedding at previous layer as  the input </li>
<li>Aggregation of neighbors and self-embeddings </li>
</ul>
</li>
<li>Graph Convolutional Network <ul>
<li>Mean aggregation; can be expressed in matrix form </li>
</ul>
</li>
<li>GNN is a general architecture <ul>
<li>CNN and Transformer can be viewed as a special GNN</li>
</ul>
</li>
</ul>
<h1 id="Graph-Neural-Networks-2"><a href="#Graph-Neural-Networks-2" class="headerlink" title="Graph Neural Networks[2]"></a>Graph Neural Networks[2]</h1><h2 id="A-General-Perspective-on-Graph-Neural-Networks"><a href="#A-General-Perspective-on-Graph-Neural-Networks" class="headerlink" title="A General Perspective on Graph Neural Networks"></a>A General Perspective on Graph Neural Networks</h2><h3 id="A-Genera-GNN-Framework"><a href="#A-Genera-GNN-Framework" class="headerlink" title="A Genera GNN Framework"></a>A Genera GNN Framework</h3><p><a href="https://arxiv.org/pdf/2011.08843.pdf" target="_blank" rel="noopener">J. You, R. Ying, J. Leskovec. Design Space of Graph Neural Networks, NeurIPS 2020</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181625296.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181708448.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181736747.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181750672.png" alt=""></p>
<h3 id="Summary-9"><a href="#Summary-9" class="headerlink" title="Summary"></a>Summary</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181828938.png" alt=""></p>
<h2 id="A-Single-Layer-of-a-GNN"><a href="#A-Single-Layer-of-a-GNN" class="headerlink" title="A Single Layer of a GNN"></a>A Single Layer of a GNN</h2><h3 id="A-Single-GNN-Layer"><a href="#A-Single-GNN-Layer" class="headerlink" title="A Single GNN Layer"></a>A Single GNN Layer</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181939133.png" alt=""></p>
<h4 id="Message-Computation"><a href="#Message-Computation" class="headerlink" title="Message Computation"></a>Message Computation</h4><h4 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a><img src="/images/loading.gif" data-original="../images/basic/image-20211118182057368.png" alt="">Aggregation</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182129781.png" alt=""></p>
<h4 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182215334.png" alt=""></p>
<h4 id="Putting-things-together"><a href="#Putting-things-together" class="headerlink" title="Putting things together"></a>Putting things together</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182315450.png" alt=""></p>
<h3 id="Classical-GNN-Layers-GCN"><a href="#Classical-GNN-Layers-GCN" class="headerlink" title="Classical GNN Layers: GCN"></a>Classical GNN Layers: GCN</h3><p><a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">T. Kipf, M. Welling. Semi-Supervised Classification with Graph Convolutional Networks, ICLR 2017</a></p>
<p>Graph Convolutional Networks (GCN)</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211118182440842.png" style="zoom:50%;">

<p>How to write this as Message + Aggregation?</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211118182508447.png" style="zoom:67%;">

<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182531818.png" alt=""></p>
<h3 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h3><p><a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Hamilton et al. Inductive Representation Learning on Large Graphs, NeurIPS 2017</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182605344.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182721525.png" alt=""></p>
<h4 id="L2-Normalization"><a href="#L2-Normalization" class="headerlink" title="L2 Normalization"></a>L2 Normalization</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182808881.png" alt=""></p>
<h3 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h3><p>Graph Attention Networks</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182917446.png" alt=""></p>
<p>Not all node’s neighbors are equally important </p>
<ul>
<li><p>Attention is inspired by cognitive attention.  </p>
</li>
<li><p>The attention a_uv focuses on the important parts of  the input data and fades out the rest.  </p>
<ul>
<li><p>Idea: the NN should devote more computing power on that  small but important part of the data.  </p>
</li>
<li><p>Which part of the data is more important depends on the  context and is learned through training.</p>
</li>
</ul>
</li>
</ul>
<p>Can we do better than simple  neighborhood aggregation?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183053526.png" alt=""></p>
<h4 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183127306.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183206950.png" alt=""></p>
<p>What is the form of attention mechanism a? </p>
<ul>
<li>The approach is agnostic to the choice of a </li>
<li>E.g., use a simple single-layer neural network </li>
<li>a have trainable parameters (weights in the Linear layer)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183316007.png" alt=""></p>
<p><strong>Multi-head attention</strong>: Stabilizes the learning  process of attention mechanism</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183340078.png" alt=""></p>
<h4 id="Benefits-of-Attention-Mechanism"><a href="#Benefits-of-Attention-Mechanism" class="headerlink" title="Benefits of Attention Mechanism"></a>Benefits of Attention Mechanism</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183547862.png" alt=""></p>
<h2 id="GNN-Layers-in-Practice"><a href="#GNN-Layers-in-Practice" class="headerlink" title="GNN Layers in Practice"></a>GNN Layers in Practice</h2><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183651153.png" alt=""></p>
<p>Many modern deep learning modules can be  incorporated into a GNN layer </p>
<ul>
<li>Batch Normalization: <ul>
<li>Stabilize neural network training </li>
</ul>
</li>
<li>Dropout: <ul>
<li>Prevent overfitting </li>
</ul>
</li>
<li>Attention/Gating: <ul>
<li>Control the importance of a message </li>
</ul>
</li>
<li>More: <ul>
<li>Any other useful deep learning modules</li>
</ul>
</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">S. Loffe, C.Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, ICML 2015</a></p>
<ul>
<li>Goal: Stabilize neural networks training </li>
<li>Idea: Given a batch of inputs (node embeddings) <ul>
<li>Re-center the node embeddings into zero mean  </li>
<li>Re-scale the variance into unit variance</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183903183.png" alt=""></p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><ul>
<li>Goal: Regularize a neural net to prevent overfitting. </li>
<li>Idea:  <ul>
<li>During training: with some probability p, randomly set  neurons to zero (turn off) </li>
<li>During testing: Use all the neurons for computation</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184007286.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184033018.png" alt=""></p>
<h3 id="Activation-Non-linearity"><a href="#Activation-Non-linearity" class="headerlink" title="Activation(Non-linearity)"></a>Activation(Non-linearity)</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184103165.png" alt=""></p>
<p>Summary: </p>
<ul>
<li>Modern deep learning  modules can be included into a GNN  layer for better performance </li>
<li>Designing novel GNN layers is still  an active research frontier! </li>
<li>Suggested resources: You can  explore diverse GNN designs or try  out your own ideas in GraphGym</li>
</ul>
<h3 id="Stacking-Layers-of-a-GNN"><a href="#Stacking-Layers-of-a-GNN" class="headerlink" title="Stacking Layers of a GNN"></a>Stacking Layers of a GNN</h3><ul>
<li>How to construct a Graph Neural Network? </li>
<li>The standard way: Stack GNN layers sequentially</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184246785.png" alt=""></p>
<h3 id="The-Over-smoothing-Problem"><a href="#The-Over-smoothing-Problem" class="headerlink" title="The Over-smoothing Problem"></a>The Over-smoothing Problem</h3><ul>
<li>The Issue of stacking many GNN layers <ul>
<li>GNN suffers from the over-smoothing problem </li>
</ul>
</li>
<li>The over-smoothing problem: all the node  embeddings converge to the same value <ul>
<li>This is bad because we want to use node  embeddings to differentiate nodes </li>
</ul>
</li>
<li>Why does the over-smoothing problem  happen?</li>
</ul>
<h3 id="Receptive-Field-of-a-GNN"><a href="#Receptive-Field-of-a-GNN" class="headerlink" title="Receptive Field of a GNN"></a>Receptive Field of a GNN</h3><ul>
<li>Receptive field: the set of nodes that determine  the embedding of a node of interest <ul>
<li>In a k-layer GNN, each node has a receptive field of  k-hop neighborhood</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184451889.png" alt=""></p>
<ul>
<li>Receptive field overlap for two nodes <ul>
<li>The shared neighbors quickly grows when we  increase the number of hops (num of GNN layers)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184537134.png" alt=""></p>
<ul>
<li>We can explain over-smoothing via the notion  of receptive field <ul>
<li>We knew the embedding of a node is determined  by its receptive field <ul>
<li>If two nodes have highly-overlapped receptive fields, then  their embeddings are highly similar </li>
</ul>
</li>
</ul>
</li>
<li>Stack many GNN layers -&gt; nodes will have highlyoverlapped receptive fields -&gt; node embeddings  will be highly similar -&gt; suffer from the over-smoothing problem </li>
<li>Next: how do we overcome over-smoothing problem?</li>
</ul>
<h3 id="Design-GNN-Layer-Connectivity"><a href="#Design-GNN-Layer-Connectivity" class="headerlink" title="Design GNN Layer Connectivity"></a>Design GNN Layer Connectivity</h3><ul>
<li>What do we learn from the over-smoothing problem?  </li>
<li>Lesson 1: Be cautious when adding GNN layers <ul>
<li>Unlike neural networks in other domains (CNN for image  classification), adding more GNN layers do not always help </li>
<li>Step 1: Analyze the necessary receptive field to solve your  problem. E.g., by computing the diameter of the graph </li>
<li>Step 2: Set number of GNN layers L to be a bit more than the  receptive field we like. Do not set L to be unnecessarily  large! </li>
</ul>
</li>
<li>Question: How to enhance the expressive power of a  GNN, if the number of GNN layers is small?</li>
</ul>
<h3 id="Expressive-Power-for-Shallow-GNNS"><a href="#Expressive-Power-for-Shallow-GNNS" class="headerlink" title="Expressive Power for Shallow GNNS"></a>Expressive Power for Shallow GNNS</h3><ul>
<li>How to make a shallow GNN more expressive? </li>
<li>Solution 1: Increase the expressive power within  each GNN layer <ul>
<li>In our previous examples, each transformation or  aggregation function only include one linear layer </li>
<li>We can make aggregation / transformation become a  deep neural network!</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184904401.png" alt=""></p>
<ul>
<li>Solution 2: Add layers that do not pass messages <ul>
<li>A GNN does not necessarily only contain GNN layers <ul>
<li>E.g., we can add MLP layers (applied to each node) before and after  GNN layers, as pre-process layers and post-process layers </li>
</ul>
</li>
<li>Pre-processing layers: Important when  encoding node features is necessary. </li>
<li>E.g., when nodes represent images/text </li>
<li>Post-processing layers: Important when  reasoning / transformation over node  embeddings are needed </li>
<li>E.g., graph classification, knowledge graphs </li>
<li>In practice, adding these layers works great</li>
</ul>
</li>
</ul>
<p>What if my problem still requires many GNN layers? </p>
<ul>
<li><p>Lesson 2: Add skip connections in GNNs </p>
<ul>
<li><p>Observation from over-smoothing: Node embeddings in  earlier GNN layers can sometimes better differentiate nodes </p>
</li>
<li><p>Solution: We can increase the impact of earlier layers on the  final node embeddings, by adding shortcuts in GNN</p>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185158513.png" alt=""></p>
<p><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener">He et al. Deep Residual Learning for Image Recognition, CVPR 2015</a></p>
<h3 id="Idea-of-Skip-Connections"><a href="#Idea-of-Skip-Connections" class="headerlink" title="Idea of Skip Connections"></a>Idea of Skip Connections</h3><p>Why do skip connections work?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185307362.png" alt=""></p>
<p><a href="https://arxiv.org/abs/1605.06431" target="_blank" rel="noopener">Veit et al. Residual Networks Behave Like Ensembles of Relatively Shallow Networks, ArXiv 2016</a></p>
<h3 id="Example-GCN-with-Skip-Connections"><a href="#Example-GCN-with-Skip-Connections" class="headerlink" title="Example: GCN with Skip Connections"></a>Example: GCN with Skip Connections</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185405314.png" alt=""></p>
<h3 id="Other-Options-of-Skip-Connections"><a href="#Other-Options-of-Skip-Connections" class="headerlink" title="Other Options of Skip Connections"></a>Other Options of Skip Connections</h3><p><a href="https://arxiv.org/abs/1806.03536" target="_blank" rel="noopener">Xu et al. Representation learning on graphs with jumping knowledge networks, ICML 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185509213.png" alt=""></p>
<h1 id="GNN-Augmentation-增强-and-Training"><a href="#GNN-Augmentation-增强-and-Training" class="headerlink" title="GNN Augmentation(增强) and Training"></a>GNN Augmentation(增强) and Training</h1><h2 id="Graph-Augmentation-for-GNNS"><a href="#Graph-Augmentation-for-GNNS" class="headerlink" title="Graph Augmentation for GNNS"></a>Graph Augmentation for GNNS</h2><p>Our assumption so far has been  </p>
<ul>
<li>Raw input graph = computational graph </li>
</ul>
<p>Reasons for breaking this assumption </p>
<ul>
<li><p>Features:  </p>
<ul>
<li>The input graph lacks features </li>
</ul>
</li>
<li><p>Graph structure: </p>
<ul>
<li>The graph is too sparse(稀疏的) -&gt; inefficient message passing </li>
<li>The graph is too dense -&gt; message passing is too costly </li>
<li>The graph is too large -&gt; cannot fit the computational  graph into a GPU </li>
</ul>
</li>
<li><p>It’s unlikely that the input graph happens to be  the optimal computation graph for embeddings</p>
</li>
</ul>
<h3 id="Graph-Augmentation-Approaches"><a href="#Graph-Augmentation-Approaches" class="headerlink" title="Graph Augmentation Approaches"></a>Graph Augmentation Approaches</h3><ul>
<li>Graph Feature augmentation <ul>
<li>The input graph lacks features -&gt; feature  augmentation </li>
</ul>
</li>
<li>Graph Structure augmentation <ul>
<li>The graph is too sparse -&gt; Add virtual nodes / edges </li>
<li>The graph is too dense -&gt; Sample neighbors when  doing message passing </li>
<li>The graph is too large -&gt; Sample subgraphs to  compute embeddings  </li>
</ul>
</li>
<li>Will cover later in lecture: Scaling up GNNs</li>
</ul>
<p>Why do we need feature augmentation? </p>
<p><strong>(1) Input graph does not have node features</strong> </p>
<p>This is common when we only have the adj. matrix ¡ Standard approaches: </p>
<p>​    a) Assign constant values to node</p>
<p>​    b) Assign unique IDs to nodes </p>
<p>​        These IDs are converted into one-hot vectors</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121121440814.png" alt=""></p>
<h3 id="Feature-augmentation-constant-vs-one-hot"><a href="#Feature-augmentation-constant-vs-one-hot" class="headerlink" title="Feature augmentation: constant vs. one-hot"></a>Feature augmentation: constant vs. one-hot</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121121513731.png" alt=""></p>
<p>J. You, J. Gomes-Selman, R. Ying, J. Leskovec. Identity-aware Graph Neural Networks, AAAI 2021</p>
<p><strong>(2) Certain structures are hard to learn by GNN</strong> </p>
<p>​    Example: Cycle count feature: </p>
<p>​        Can GNN learn the length of a cycle that v1 resides in? </p>
<p>​        Unfortunately, no</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122002057.png" alt=""></p>
<p>​    v1 cannot differentiate which graph it resides in  </p>
<ul>
<li>Because all the nodes in the graph have degree of 2 </li>
<li>The computational graphs will be the same binary tree</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122106176.png" alt=""></p>
<p>Solution:  </p>
<ul>
<li>We can use cycle count as augmented node features</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122157777.png" alt=""></p>
<p>Other commonly used augmented features: </p>
<ul>
<li>Node degree </li>
<li>Clustering coefficient </li>
<li>PageRank </li>
<li>Centrality </li>
<li>…</li>
</ul>
<h3 id="Add-Virtual-Nodes-Edges"><a href="#Add-Virtual-Nodes-Edges" class="headerlink" title="Add Virtual Nodes/ Edges"></a>Add Virtual Nodes/ Edges</h3><p>Motivation: Augment sparse graphs </p>
<p>(1) Add virtual edges </p>
<ul>
<li>Common approach: Connect 2-hop neighbors via  virtual edges </li>
<li>Intuition: Instead of using adj. matrix A for GNN  computation, use A + A^2,</li>
</ul>
<p>Use cases: Bipartite graphs </p>
<ul>
<li>Author-to-papers (they authored) </li>
<li>2-hop virtual edges make an author-author collaboration graph</li>
</ul>
<p>(2) Add virtual nodes </p>
<ul>
<li><p>The virtual node will connect to all the  nodes in the graph </p>
<ul>
<li><p>Suppose in a sparse graph, two nodes have  shortest path distance of 10 </p>
</li>
<li><p>After adding the virtual node, all the nodes  will have a distance of two </p>
<ul>
<li>Node A – Virtual node – Node B </li>
</ul>
</li>
</ul>
</li>
<li><p>Benefits: Greatly improves message  passing in sparse graphs</p>
</li>
</ul>
<img src="/images/loading.gif" data-original="../images/basic/image-20211121123047322.png" style="zoom:67%;">

<h3 id="Node-Neighborhood-Sampling"><a href="#Node-Neighborhood-Sampling" class="headerlink" title="Node Neighborhood Sampling"></a>Node Neighborhood Sampling</h3><p><a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Hamilton et al. Inductive Representation Learning on Large Graphs, NeurIPS 2017</a></p>
<p>Previously: </p>
<ul>
<li>All the nodes are used for message passing</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123211164.png" alt=""></p>
<p>New idea: (Randomly) sample a node’s  neighborhood for message passing</p>
<p>For example, we can randomly choose 2 neighbors to pass messages in a given layer </p>
<ul>
<li>Only nodes B and D will pass messages to A</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123313579.png" alt=""></p>
<p>In the next layer when we compute the embeddings, we can sample different  neighbors </p>
<ul>
<li>Only nodes C and D will pass messages to A</li>
</ul>
<p>In expectation, we get embeddings similar to  the case where all the neighbors are used </p>
<ul>
<li>Benefits: Greatly reduces computational cost <ul>
<li>Allows for scaling to large graphs (more about this later) </li>
</ul>
</li>
<li>And in practice it works great!</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123433789.png" alt=""></p>
<h2 id="Prediction-with-GNNS"><a href="#Prediction-with-GNNS" class="headerlink" title="Prediction with GNNS"></a>Prediction with GNNS</h2><h3 id="GNN-Training-Pipeline"><a href="#GNN-Training-Pipeline" class="headerlink" title="GNN Training Pipeline"></a>GNN Training Pipeline</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123545999.png" alt=""></p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(1) Different prediction heads: </p>
<ul>
<li>Node-level tasks </li>
<li>Edge-level tasks </li>
<li>Graph-level tasks</li>
</ul>
<h3 id="GNN-Prediction-Heads"><a href="#GNN-Prediction-Heads" class="headerlink" title="GNN Prediction Heads"></a>GNN Prediction Heads</h3><p>Idea: Different task levels require different  prediction heads</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123718495.png" alt=""></p>
<h4 id="Node-level"><a href="#Node-level" class="headerlink" title="Node-level"></a>Node-level</h4><p><strong>Node-level prediction</strong>: We can directly make  prediction using node embeddings!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123800804.png" alt=""></p>
<h4 id="Edae-level"><a href="#Edae-level" class="headerlink" title="Edae-level"></a>Edae-level</h4><p><strong>Edge-level prediction</strong>: Make prediction using  pairs of node embeddings</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124152229.png" alt=""></p>
<p><strong>(1) Concatenation + Linear</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124251201.png" alt=""></p>
<p><strong>(2) Dot product</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124319360.png" alt=""></p>
<h4 id="Graph-level"><a href="#Graph-level" class="headerlink" title="Graph-level"></a>Graph-level</h4><p><strong>Graph-level prediction</strong>: Make prediction using  all the node embeddings in our graph</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124422963.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1810.00826.pdf" target="_blank" rel="noopener">K. Xu<em>, W. Hu</em>, J. Leskovec, S. Jegelka. How Powerful Are Graph Neural Networks, ICLR 2019</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124519131.png" alt=""></p>
<h5 id="Issue-of-Global-Pooling"><a href="#Issue-of-Global-Pooling" class="headerlink" title="Issue of Global Pooling"></a>Issue of Global Pooling</h5><p>Issue: Global pooling over a (large) graph will lose  information</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124630985.png" alt=""></p>
<h5 id="Hierarchical-Global-Pooling"><a href="#Hierarchical-Global-Pooling" class="headerlink" title="Hierarchical Global Pooling"></a>Hierarchical Global Pooling</h5><p>A solution: Let’s aggregate all the node  embeddings hierarchically(等级的)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124801967.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1806.08804.pdf" target="_blank" rel="noopener">Ying et al. Hierarchical Graph Representation Learning with Differentiable Pooling, NeurIPS 2018</a></p>
<p>DiffPool idea: </p>
<ul>
<li>Hierarchically pool node embedding</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124919721.png" alt=""></p>
<p>Leverage 2 independent GNNs at each level </p>
<ul>
<li>GNN A: Compute node embeddings </li>
<li>GNN B: Compute the cluster that a node belongs to </li>
</ul>
<p>GNNs A and B at each level can be executed in parallel</p>
<p>For each Pooling layer </p>
<ul>
<li>Use clustering assignments from GNN B to aggregate node  embeddings generated by GNN A </li>
<li>Create a single new node for each cluster, maintaining  edges between clusters to generated a new pooled network </li>
</ul>
<p>Jointly train GNN A and GNN B</p>
<h2 id="Training-Graph-Neural-Networks"><a href="#Training-Graph-Neural-Networks" class="headerlink" title="Training Graph Neural Networks"></a>Training Graph Neural Networks</h2><h3 id="Pipeline-1"><a href="#Pipeline-1" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(2) Where does ground-truth come from?  </p>
<ul>
<li>Supervised labels </li>
<li>Unsupervised signals</li>
</ul>
<h3 id="Supervised-Vs-Unsupervised"><a href="#Supervised-Vs-Unsupervised" class="headerlink" title="Supervised Vs Unsupervised"></a>Supervised Vs Unsupervised</h3><ul>
<li>Supervised learning on graphs <ul>
<li>Labels come from external sources <ul>
<li>E.g., predict drug likeness of a molecular graph </li>
</ul>
</li>
</ul>
</li>
<li>Unsupervised learning on graphs <ul>
<li>Signals come from graphs themselves  <ul>
<li>E.g., link prediction: predict if two nodes are connected </li>
</ul>
</li>
</ul>
</li>
<li>Sometimes the differences are blurry <ul>
<li>We still have “supervision” in unsupervised learning <ul>
<li>E.g., train a GNN to predict node clustering coefficient </li>
</ul>
</li>
<li>An alternative name for “unsupervised” is “self-supervised”</li>
</ul>
</li>
</ul>
<h3 id="Supervised-Labels-on-Graphs"><a href="#Supervised-Labels-on-Graphs" class="headerlink" title="Supervised Labels on Graphs"></a>Supervised Labels on Graphs</h3><p>Supervised labels come from the specific use  cases. For example:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125549048.png" alt=""></p>
<p>Advice: Reduce your task to node / edge / graph  labels, since they are easy to work with </p>
<ul>
<li>E.g., we knew some nodes form a cluster. We can treat  the cluster that a node belongs to as a node label</li>
</ul>
<h3 id="Unsupervised-Signals-on-Graphs"><a href="#Unsupervised-Signals-on-Graphs" class="headerlink" title="Unsupervised Signals on Graphs"></a>Unsupervised Signals on Graphs</h3><ul>
<li>The problem: sometimes we only have a graph,  without any external labels </li>
<li>The solution: “self-supervised learning”, we can  find supervision signals within the graph. <ul>
<li>For example, we can let GNN predict the following:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125728956.png" alt=""></p>
<p>These tasks do not require any external labels!</p>
<h3 id="Pipeline-2"><a href="#Pipeline-2" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(3) How do we compute the final loss? </p>
<ul>
<li>Classification loss </li>
<li>Regression loss</li>
</ul>
<h3 id="Settings-for-GNN-Training"><a href="#Settings-for-GNN-Training" class="headerlink" title="Settings for GNN Training"></a>Settings for GNN Training</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125933719.png" alt=""></p>
<h3 id="Classification-or-Rearession"><a href="#Classification-or-Rearession" class="headerlink" title="Classification or Rearession"></a>Classification or Rearession</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130003206.png" alt=""></p>
<h4 id="Classification-LOSS"><a href="#Classification-LOSS" class="headerlink" title="Classification LOSS"></a>Classification LOSS</h4><p>As discussed in lecture 6, cross entropy (CE) is a very common loss function in classification</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130041014.png" alt=""></p>
<h4 id="Regression-Loss"><a href="#Regression-Loss" class="headerlink" title="Regression Loss"></a>Regression Loss</h4><p>For regression tasks we often use Mean Squared  Error (MSE) a.k.a. L2 loss</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130126580.png" alt=""></p>
<h3 id="Pipeline-3"><a href="#Pipeline-3" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(4) How do we measure the success of a GNN? </p>
<ul>
<li>Accuracy </li>
<li>ROC AUC</li>
</ul>
<h3 id="Evaluation-Metrics-Rearession"><a href="#Evaluation-Metrics-Rearession" class="headerlink" title="Evaluation Metrics: Rearession"></a>Evaluation Metrics: Rearession</h3><ul>
<li>We use standard evaluation metrics for GNN <ul>
<li>(Content below can be found in any ML course)</li>
<li>In practice we will use sklearn for implementation </li>
<li>Suppose we make predictions for N data points </li>
</ul>
</li>
<li>Evaluate regression tasks on graphs:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130302297.png" alt=""></p>
<h3 id="Evaluation-Metrics-Classification"><a href="#Evaluation-Metrics-Classification" class="headerlink" title="Evaluation Metrics: Classification"></a>Evaluation Metrics: Classification</h3><p>Evaluate classification tasks on graphs:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130344635.png" alt=""></p>
<h3 id="Metrics-for-Binary-Classification"><a href="#Metrics-for-Binary-Classification" class="headerlink" title="Metrics for Binary Classification"></a>Metrics for Binary Classification</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130405807.png" alt=""></p>
<p>ROC Curve: Captures the tradeoff in TPR and  FPR as the classification threshold is varied  for a binary classifier.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130436056.png" alt=""></p>
<p>ROC AUC: Area under the ROC Curve.  </p>
<p>Intuition: The probability that a classifier will rank a  randomly chosen positive instance higher than a  randomly chosen negative one</p>
<h2 id="Setting-up-GNN-Prediction-Tasks"><a href="#Setting-up-GNN-Prediction-Tasks" class="headerlink" title="Setting-up GNN Prediction Tasks"></a>Setting-up GNN Prediction Tasks</h2><h3 id="Pipeline-4"><a href="#Pipeline-4" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(5) How do we split our dataset  into train / validation / test set?</p>
<h3 id="Dataset-Split-Fixed-Random-Split"><a href="#Dataset-Split-Fixed-Random-Split" class="headerlink" title="Dataset Split: Fixed/ Random Split"></a>Dataset Split: Fixed/ Random Split</h3><ul>
<li>Fixed split: We will split our dataset once <ul>
<li>Training set: used for optimizing GNN parameters </li>
<li>Validation set: develop model/hyperparameters </li>
<li>Test set: held out until we report final performance </li>
</ul>
</li>
<li>A concern: sometimes we cannot guarantee  that the test set will really be held out </li>
<li>Random split: we will randomly split our  dataset into training / validation / test <ul>
<li>We report average performance over different  random seeds</li>
</ul>
</li>
</ul>
<h3 id="Why-Splitting-Graphs-is-Special"><a href="#Why-Splitting-Graphs-is-Special" class="headerlink" title="Why Splitting Graphs is Special"></a>Why Splitting Graphs is Special</h3><p>Suppose we want to split an image dataset </p>
<ul>
<li>Image classification: Each data point is an image </li>
<li>Here data points are independent <ul>
<li>Image 5 will not affect our prediction on image 1</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130839404.png" alt=""></p>
<p>Splitting a graph dataset is different! </p>
<ul>
<li>Node classification: Each data point is a node </li>
<li>Here data points are NOT independent<ul>
<li>Node 5 will affect our prediction on node 1, because it will  participate in message passing -&gt; affect node 1’s embedding</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130957508.png" alt=""></p>
<p>What are our options?</p>
<p>Solution 1 (<strong>Transductive(传导的) setting</strong>): The input  graph can be observed in all the dataset splits  (training, validation and test set).  </p>
<p>We will only split the (node) labels </p>
<ul>
<li>At training time, we compute embeddings using the  entire graph, and train using node 1&amp;2’s labels </li>
<li>At validation time, we compute embeddings using  the entire graph, and evaluate on node 3&amp;4’s labels</li>
</ul>
<p>Solution 2 (<strong>Inductive(归纳法的) setting</strong>): We break the edges  between splits to get multiple graphs </p>
<ul>
<li>Now we have 3 graphs that are independent. Node 5 will  not affect our prediction on node 1 any more </li>
<li>At training time, we compute embeddings using the  graph over node 1&amp;2, and train using node 1&amp;2’s labels </li>
<li>At validation time, we compute embeddings using the  graph over node 3&amp;4, and evaluate on node 3&amp;4’s labels</li>
</ul>
<p>Transductive setting: training / validation / test  sets are on the same graph </p>
<ul>
<li>The dataset consists of one graph </li>
<li>The entire graph can be observed in all dataset splits,  we only split the labels </li>
<li>Only applicable to node / edge prediction tasks </li>
</ul>
<p>Inductive setting: training / validation / test sets  are on different graphs </p>
<ul>
<li>The dataset consists of multiple graphs </li>
<li>Each split can only observe the graph(s) within the split.  A successful model should generalize to unseen graphs </li>
<li>Applicable to node / edge / graph tasks</li>
</ul>
<h3 id="Graph-Classification"><a href="#Graph-Classification" class="headerlink" title="Graph Classification"></a>Graph Classification</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121131929640.png" alt=""></p>
<p>Only the <strong>inductive setting is well defined for  graph classification</strong> </p>
<ul>
<li>Because we have to test on unseen graphs</li>
<li>Suppose we have a dataset of 5 graphs. Each split  will contain independent graph(s)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132032550.png" alt=""></p>
<h3 id="Link-Prediction"><a href="#Link-Prediction" class="headerlink" title="Link Prediction"></a>Link Prediction</h3><p>Goal of link prediction: predict missing edges </p>
<p>Setting up link prediction is tricky: </p>
<ul>
<li>Link prediction is an unsupervised / self-supervised  task. We need to create the labels and dataset  splits on our own </li>
<li>Concretely, we need to hide some edges from the  GNN and the let the GNN predict if the edges exist</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132251694.png" alt=""></p>
<p>For link prediction, we will split edges twice </p>
<p>Step 1: Assign 2 types of edges in the original graph </p>
<ul>
<li><p>Message edges: Used for GNN message passing </p>
</li>
<li><p>Supervision edges: Use for computing objectives </p>
</li>
<li><p>After step 1: </p>
<ul>
<li><p>Only message edges will remain in the graph </p>
</li>
<li><p>Supervision edges are used as supervision for edge  predictions made by the model, will not be fed into GNN!</p>
</li>
</ul>
</li>
</ul>
<p>Step 2: Split edges into train / validation / test </p>
<ul>
<li>Option 1: Inductive link prediction split <ul>
<li>Suppose we have a dataset of 3 graphs. Each  inductive split will contain an independent grap</li>
<li>Suppose we have a dataset of 3 graphs. Each  inductive split will contain an independent graph </li>
<li>In train or val or test set, each graph will have 2 types of edges: message edges + supervision edges § Supervision edges are not the input to GNN</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132836775.png" alt=""></p>
<ul>
<li><p>Option 2: Transductive link prediction split: </p>
<ul>
<li><p>This is the default setting when people talk about  link prediction </p>
</li>
<li><p>Suppose we have a dataset of 1 graph</p>
</li>
<li><p>By definition of “transductive”, the entire graph can  be observed in all dataset splits </p>
<ul>
<li>But since edges are both part of graph structure and the  supervision, we need to hold out validation / test edges </li>
<li>To train the training set, we further need to hold out  supervision edges for the training set</li>
</ul>
</li>
<li><p>Next: we will show the exact settings</p>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133040720.png" alt=""></p>
<p>Summary: Transductive link prediction split</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133105561.png" alt=""></p>
<ul>
<li>Note: Link prediction settings are tricky and complex. You may find papers do link prediction differently.  </li>
<li>Luckily, we have full support in PyG and <a href="https://github.com/snap-stanford/GraphGym" target="_blank" rel="noopener">GraphGym</a></li>
</ul>
<h3 id="GNN-Training-Pipeline-1"><a href="#GNN-Training-Pipeline-1" class="headerlink" title="GNN Training Pipeline"></a>GNN Training Pipeline</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133226107.png" alt=""></p>
<p>Implementation resources: </p>
<ul>
<li><a href="https://github.com/snap-stanford/deepsnap" target="_blank" rel="noopener">DeepSNAP</a> provides core modules for this pipeline  </li>
<li><a href="https://github.com/snap-stanford/GraphGym" target="_blank" rel="noopener">GraphGym</a> further implements the full pipeline to facilitate GNN design</li>
</ul>
<h3 id="Summary-10"><a href="#Summary-10" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>GNN Layer:  <ul>
<li>Transformation + Aggregation </li>
<li>Classic GNN layers: GCN, GraphSAGE, GAT </li>
</ul>
</li>
<li>Layer connectivity:  <ul>
<li>The over-smoothing problem </li>
<li>Solution: skip connections </li>
</ul>
</li>
<li>Graph Augmentation: <ul>
<li>Feature augmentation </li>
<li>Structure augmentation </li>
</ul>
</li>
<li>Learning Objectives <ul>
<li>The full training pipeline of a GNN</li>
</ul>
</li>
</ul>
<h2 id="When-Things-Dont-Go-As-Planned"><a href="#When-Things-Dont-Go-As-Planned" class="headerlink" title="When Things Dont Go As Planned"></a>When Things Dont Go As Planned</h2><h3 id="General-Tips"><a href="#General-Tips" class="headerlink" title="General Tips"></a>General Tips</h3><ul>
<li>Data preprocessing is important:  <ul>
<li>Node attributes can vary a lot! <ul>
<li>E.g. probability ranges (0,1), but some inputs could have much  larger range, say (−1000, 1000) </li>
</ul>
</li>
<li>Use normalization </li>
</ul>
</li>
<li>Optimizer:  <ul>
<li>ADAM is relatively robust to learning rate </li>
</ul>
</li>
<li>Activation function <ul>
<li>ReLU activation function often works well </li>
<li>Other alternatives: LeakyReLU, SWISH, rational activation </li>
<li>No activation function at your output layer:  </li>
</ul>
</li>
<li>Include bias term in every layer  </li>
<li>Embedding dimensions: <ul>
<li>32, 64 and 128 are often good starting points</li>
</ul>
</li>
</ul>
<h3 id="Debugging-Deep-Networks"><a href="#Debugging-Deep-Networks" class="headerlink" title="Debugging Deep Networks"></a>Debugging Deep Networks</h3><ul>
<li>Debug issues: Loss/accuracy not converging  during training <ul>
<li>Check pipeline (e.g. in PyTorch we need zero_grad) </li>
<li>Adjust hyperparameters such as learning rate </li>
<li>Pay attention to weight parameter initialization </li>
</ul>
</li>
<li>Important for model development: <ul>
<li>Overfit on (part of) training data:  <ul>
<li>With a small training dataset, loss should be essentially close  to 0, with an expressive neural network </li>
<li>If neural network cannot overfit a single data point, something  is wrong </li>
</ul>
</li>
<li>Scrutinize loss function! </li>
<li>Scrutinize visualizations!</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133751138.png" alt=""></p>
<h1 id="Setting-up-GNN-Prediction-Tasks-1"><a href="#Setting-up-GNN-Prediction-Tasks-1" class="headerlink" title="Setting-up GNN Prediction Tasks"></a>Setting-up GNN Prediction Tasks</h1><h2 id="How-Expressive-are-Graph-Neural-Networks"><a href="#How-Expressive-are-Graph-Neural-Networks" class="headerlink" title="How Expressive are Graph Neural Networks?"></a>How Expressive are Graph Neural Networks?</h2><h3 id="Theory-of-GNNS"><a href="#Theory-of-GNNS" class="headerlink" title="Theory of GNNS"></a>Theory of GNNS</h3><p>How powerful are GNNs? </p>
<ul>
<li>Many GNN models have been proposed (e.g.,  GCN, GAT, GraphSAGE, design space). </li>
<li>What is the expressive power (ability to  distinguish different graph structures) of these  GNN models? </li>
<li>How to design a maximally expressive GNN  model?</li>
</ul>
<h3 id="Background-Many-GNN-Models"><a href="#Background-Many-GNN-Models" class="headerlink" title="Background: Many GNN Models"></a>Background: Many GNN Models</h3><p>Many GNN models have been proposed: </p>
<ul>
<li>GCN, GraphSAGE, GAT, Design Space etc.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232206183.png" alt=""></p>
<h3 id="GNN-Model-Example"><a href="#GNN-Model-Example" class="headerlink" title="GNN Model Example"></a>GNN Model Example</h3><ul>
<li>GCN (mean-pool) [Kipf and Welling ICLR 2017]</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232333035.png" alt=""></p>
<ul>
<li>GraphSAGE (max-pool) [Hamilton et al. NeurIPS 2017]</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232404770.png" alt=""></p>
<h3 id="Note-Node-Colors"><a href="#Note-Node-Colors" class="headerlink" title="Note: Node Colors"></a>Note: Node Colors</h3><ul>
<li>We use node same/different colors to represent  nodes with same/different features. <ul>
<li>For example, the graph below assumes all the nodes share the same feature.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232516186.png" alt=""></p>
<ul>
<li>Key question: How well can a GNN distinguish  different graph structures?</li>
</ul>
<h3 id="Local-Neighborhood-Structures"><a href="#Local-Neighborhood-Structures" class="headerlink" title="Local Neighborhood Structures"></a>Local Neighborhood Structures</h3><p>We specifically consider local neighborhood  structures around each node in a graph.</p>
<ul>
<li>Example: Nodes 1 and 5  have different  neighborhood structures  because they have  different node degrees.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232626141.png" alt=""></p>
<p>We specifically consider local neighborhood  structures around each node in a graph. 1 2 3 5 4 </p>
<ul>
<li>Example: Nodes 1 and 4 both have the same node  degree of 2. However, they  still have different neighborhood structures  because their neighbors  have different node degrees</li>
</ul>
<p>Node 1 has neighbors of degrees 2 and 3. Node 4 has neighbors of degrees 1 and 3.</p>
<p>We specifically consider local neighborhood  structures around each node in a graph. 1 2 3 5 4 </p>
<ul>
<li>Example: Nodes 1 and 2  have the same neighborhood structure  because they are  symmetric within the  graph.</li>
</ul>
<p>Node 1 has neighbors of degrees 2 and 3. Node 2 has neighbors of degrees 2 and 3. And even if we go a step deeper to 2nd hop neighbors, both nodes have the same degrees (Node 4 of degree 2)</p>
<ul>
<li>Key question: Can GNN node embeddings  distinguish different node’s local  neighborhood structures? <ul>
<li>If so, when? If not, when will a GNN fail? </li>
</ul>
</li>
<li>Next: We need to understand how a GNN  captures local neighborhood structures. <ul>
<li>Key concept: Computational graph</li>
</ul>
</li>
</ul>
<h3 id="Computational-Graph"><a href="#Computational-Graph" class="headerlink" title="Computational Graph"></a>Computational Graph</h3><p>In each layer, a GNN aggregates neighboring node  embeddings. </p>
<p>A GNN generates node embeddings through a  computational graph defined by the neighborhood. </p>
<ul>
<li>Ex: Node 1’s computational graph (2-layer GNN)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233256304.png" alt=""></p>
<ul>
<li>Ex: Nodes 1 and 2’s computational graphs.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233315665.png" alt=""></p>
<ul>
<li>Ex: Nodes 1 and 2’s computational graphs. </li>
<li>But GNN only sees node features (not IDs):</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233337139.png" alt=""></p>
<p>A GNN will generate the same embedding for  nodes 1 and 2 because: </p>
<ul>
<li>Computational graphs are the same. </li>
<li>Node features (colors) are identical.</li>
</ul>
<p>Note: GNN does not care about node ids, it just aggregates features vectors of different nodes.</p>
<p>In general, different local neighborhoods  define different computational graphs</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233437411.png" alt=""></p>
<p>Computational graphs are identical to rooted  subtree structures around each node.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233458316.png" alt=""></p>
<p>GNN‘s node embeddings capture rooted  subtree structures.</p>
<p>Most expressive GNN maps different rooted  subtrees into different node embeddings  (represented by different colors).</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233528263.png" alt=""></p>
<h3 id="Recall-Iniective-Function"><a href="#Recall-Iniective-Function" class="headerlink" title="Recall: Iniective Function"></a>Recall: Iniective Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233555015.png" alt=""></p>
<h3 id="How-Expressive-is-a-GNN"><a href="#How-Expressive-is-a-GNN" class="headerlink" title="How Expressive is a GNN?"></a>How Expressive is a GNN?</h3><p>Most expressive GNN should map subtrees to  the node embeddings injectively.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233631327.png" alt=""></p>
<p>Key observation: Subtrees of the same depth  can be recursively characterized from the leaf  nodes to the root nodes.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233656532.png" alt=""></p>
<p>If each step of GNN’s aggregation can fully  retain the neighboring information, the  generated node embeddings can distinguish  different rooted subtrees.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233724688.png" alt=""></p>
<p>In other words, most expressive GNN would  use an injective neighbor aggregation function at each step. </p>
<p>Maps different neighbors to different embeddings.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233745404.png" alt=""></p>
<p>Summary so far </p>
<ul>
<li>To generate a node embedding, GNNs use a computational graph corresponding to a subtree  rooted around each node.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233818826.png" alt=""></p>
<ul>
<li>GNN can fully distinguish different subtree  structures if every step of its neighbor  aggregation is injective.</li>
</ul>
<h2 id="Designing-the-Most-Powerful-Graph-Neural-Network"><a href="#Designing-the-Most-Powerful-Graph-Neural-Network" class="headerlink" title="Designing the Most Powerful Graph Neural Network"></a>Designing the Most Powerful Graph Neural Network</h2><h3 id="Expressive-Power-of-GNNS"><a href="#Expressive-Power-of-GNNS" class="headerlink" title="Expressive Power of GNNS"></a>Expressive Power of GNNS</h3><ul>
<li>Key observation: Expressive power of GNNs  can be characterized by that of neighbor  aggregation functions they use. <ul>
<li>A more expressive aggregation function leads to a  more expressive a GNN. </li>
<li>Injective aggregation function leads to the most  expressive GNN. </li>
</ul>
</li>
<li>Next: <ul>
<li>Theoretically analyze expressive power of  aggregation functions.</li>
</ul>
</li>
</ul>
<h3 id="Neighbor-Aggregation"><a href="#Neighbor-Aggregation" class="headerlink" title="Neighbor Aggregation"></a>Neighbor Aggregation</h3><p>Observation: Neighbor aggregation can be abstracted as a function over a multi-set (a  set with repeating elements).</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234114863.png" alt=""></p>
<p>Next: We analyze aggregation functions of  two popular GNN models</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234133971.png" alt=""></p>
<ul>
<li>GCN (mean-pool) [Kipf &amp; Welling ICLR 2017] <ul>
<li>Take element-wise mean, followed by linear  function and ReLU activation, i.e., max(0, x). </li>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GCN’s aggregation function cannot distinguish different  multi-sets with the same color proportion.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234305197.png" alt=""></p>
<p>For simplicity, we assume node colors are  represented by one-hot encoding. </p>
<p>Example) If there are two distinct colors:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234323852.png" alt=""></p>
<p>This assumption is sufficient to illustrate how GCN  fails.</p>
<p> <strong>Failure case illustration</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234427536.png" alt=""></p>
<ul>
<li>GraphSAGE (max-pool) [Hamilton et al. NeurIPS 2017] <ul>
<li>Apply an MLP, then take element-wise max. </li>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GraphSAGE’s aggregation function cannot distinguish  different multi-sets with the same set of distinct colors. </li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234506874.png" alt=""></p>
<p><strong>Failure case illustration</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234534845.png" alt=""></p>
<h3 id="Summary-So-Far"><a href="#Summary-So-Far" class="headerlink" title="Summary So Far"></a>Summary So Far</h3><p>We analyzed the expressive power of GNNs. </p>
<p>Main takeaways:  </p>
<ul>
<li>Expressive power of GNNs can be characterized by  that of the neighbor aggregation function. </li>
<li>Neighbor aggregation is a function over multi-sets  (sets with repeating elements)  </li>
<li>GCN and GraphSAGE’s aggregation functions fail to  distinguish some basic multi-sets; hence not injective. </li>
<li>Therefore, GCN and GraphSAGE are not maximally  powerful GNNs.</li>
</ul>
<h3 id="Designing-Most-Expressive-GNNS"><a href="#Designing-Most-Expressive-GNNS" class="headerlink" title="Designing Most Expressive GNNS"></a>Designing Most Expressive GNNS</h3><ul>
<li>Our goal: Design maximally powerful GNNs  in the class of message-passing GNNs. </li>
<li>This can be achieved by designing injective neighbor aggregation function over multi-sets. </li>
<li>Here, we design a neural network that can  model injective multiset function.</li>
</ul>
<h3 id="Injective-Multi-set-Function"><a href="#Injective-Multi-set-Function" class="headerlink" title="Injective Multi-set Function"></a>Injective Multi-set Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234725881.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234816499.png" alt=""></p>
<h3 id="Universal-Approximation-Theorem"><a href="#Universal-Approximation-Theorem" class="headerlink" title="Universal Approximation Theorem"></a>Universal Approximation Theorem</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234842803.png" alt=""></p>
<h3 id="Injective-Multi-set-Function-1"><a href="#Injective-Multi-set-Function-1" class="headerlink" title="Injective Multi-set Function"></a>Injective Multi-set Function</h3><p>We have arrived at a neural network that can  model any injective multi-set function.</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124234919909.png" style="zoom:50%;">

<p>In practice, MLP hidden dimensionality of 100 to  500 is sufficient.</p>
<h3 id="Most-Expressive-GNN"><a href="#Most-Expressive-GNN" class="headerlink" title="Most Expressive GNN"></a>Most Expressive GNN</h3><p>Graph Isomorphism Network (GIN) [Xu et al. ICLR 2019] </p>
<p>Apply an MLP, element-wise sum, followed by  another MLP</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124235014695.png" style="zoom:50%;">

<ul>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GIN‘s neighbor aggregation function is injective. </li>
</ul>
</li>
<li>No failure cases! </li>
<li>GIN is THE most expressive GNN in the class of  message-passing GNNs!</li>
</ul>
<h3 id="Full-Model-of-GIN"><a href="#Full-Model-of-GIN" class="headerlink" title="Full Model of GIN"></a>Full Model of GIN</h3><p>So far: We have described the neighbor  aggregation part of GIN. </p>
<p>We now describe the full model of GIN by  relating it to WL graph kernel (traditional way  of obtaining graph-level features). </p>
<ul>
<li>We will see how GIN is a “neural network” version  of the WL graph kernel.</li>
</ul>
<h3 id="Relation-to-WL-Graph-Kernel"><a href="#Relation-to-WL-Graph-Kernel" class="headerlink" title="Relation to WL Graph Kernel"></a>Relation to WL Graph Kernel</h3><p>Recall: Color refinement algorithm in WL kernel.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235238709.png" alt=""></p>
<h3 id="Color-Refinement"><a href="#Color-Refinement" class="headerlink" title="Color Refinement"></a>Color Refinement</h3><p>Example of color refinement given two graphs</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235311686.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235328474.png" alt=""></p>
<p>Example of color refinement given two graphs </p>
<ul>
<li>Process continues until a stable coloring is  reached </li>
<li>Two graphs are considered isomorphic if they  have the same set of colors.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235354421.png" alt=""></p>
<h3 id="The-Complete-GIN-Mode"><a href="#The-Complete-GIN-Mode" class="headerlink" title="The Complete GIN Mode"></a>The Complete GIN Mode</h3><p>GIN uses a neural network to model the  injective HASH function.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235423462.png" alt=""></p>
<p>Specifically, we will model the injective  function over the tuple:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235437403.png" alt=""></p>
<p>Theorem (Xu et al. ICLR 2019) </p>
<p>Any injective function over the tuple</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124235529779.png" style="zoom:50%;">

<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235552059.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235634820.png" alt=""></p>
<h3 id="GIN-and-WL-Graph-Kernel"><a href="#GIN-and-WL-Graph-Kernel" class="headerlink" title="GIN and WL Graph Kernel"></a>GIN and WL Graph Kernel</h3><p>GIN can be understood as differentiable neural  version of the WL graph Kernel:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235709357.png" alt=""></p>
<p>Advantages of GIN over the WL graph kernel are: </p>
<ul>
<li>Node embeddings are low-dimensional; hence, they can  capture the fine-grained similarity of different nodes. </li>
<li>Parameters of the update function can be learned for the  downstream tasks.</li>
</ul>
<h3 id="Expressive-Power-of-GIN"><a href="#Expressive-Power-of-GIN" class="headerlink" title="Expressive Power of GIN"></a>Expressive Power of GIN</h3><ul>
<li>Because of the relation between GIN and the  WL graph kernel, their expressive is exactly the  same. <ul>
<li>If two graphs can be distinguished by GIN, they can be  also distinguished by the WL kernel, and vice versa. </li>
</ul>
</li>
<li>How powerful is this? <ul>
<li>WL kernel has been both theoretically and  empirically shown to distinguish most of the real-world graphs [Cai et al. 1992]. </li>
<li>Hence, GIN is also powerful enough to distinguish  most of the real graphs!</li>
</ul>
</li>
</ul>
<h3 id="Summary-of-the-Lecture"><a href="#Summary-of-the-Lecture" class="headerlink" title="Summary of the Lecture"></a>Summary of the Lecture</h3><ul>
<li>We design a neural network that can model  injective multi-set function. </li>
<li>We use the neural network for neighbor  aggregation function and arrive at GIN—the  most expressive GNN model. </li>
<li>The key is to use element-wise sum pooling,  instead of mean-/max-pooling. </li>
<li>GIN is closely related to the WL graph kernel. </li>
<li>Both GIN and WL graph kernel can distinguish  most of the real graphs!</li>
</ul>
<h3 id="The-Power-of-Pooling"><a href="#The-Power-of-Pooling" class="headerlink" title="The Power of Pooling"></a>The Power of Pooling</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235927640.png" alt=""></p>
<p>Can expressive power of GNNs be improved? </p>
<p>There are basic graph structures that existing GNN  framework cannot distinguish, such as difference in cycles.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235955061.png" alt=""></p>
<p>GNNs’ expressive power can be improved to resolve  the above problem. [You et al. AAAI 2021, Li et al. NeurIPS 2020]</p>
<h3 id="Summary-11"><a href="#Summary-11" class="headerlink" title="Summary"></a>Summary</h3><p>GNNs and connection to bijective functions  on sets. </p>
<p>Most powerful GNN is equivalent to WL graph  isomorphism test. </p>
<p>GIN is the most powerful GNN. </p>
<ul>
<li>Sum aggregator is more powerful than mean is  more powerful than max.</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html">https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Lesson/">
                                    <span class="chip bg-color">Lesson</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-11-12T12-20-03',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/blog-python28.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="Python-学习资料">
                        
                        <span class="card-title">Python-学习资料</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Python-学习资料汇总
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-11-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/dl-series18.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/5.jpg" class="responsive-img" alt="DL专栏18-Normalization">
                        
                        <span class="card-title">DL专栏18-Normalization</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Normalization方法
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Normalization/">
                        <span class="chip bg-color">Normalization</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3122.6k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

