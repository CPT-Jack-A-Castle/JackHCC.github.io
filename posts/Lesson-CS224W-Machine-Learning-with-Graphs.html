<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CS224W-Machine Learning with Graphs, JackHCC">
    <meta name="description" content="Machine Learning with Graphs Notes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>CS224W-Machine Learning with Graphs | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CS224W-Machine Learning with Graphs</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Lesson/">
                                <span class="chip bg-color">Lesson</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-11-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-11-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    37 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a href="http://web.stanford.edu/class/cs224w/" target="_blank" rel="noopener">CS224W | Home (stanford.edu)</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Machine-Learning-with-Graphs"><a href="#Machine-Learning-with-Graphs" class="headerlink" title="Machine Learning with Graphs"></a>Machine Learning with Graphs</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150408195.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150422199.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150432882.png" alt=""></p>
<h3 id="Why-is-Graph-Deep-Learning-Hard"><a href="#Why-is-Graph-Deep-Learning-Hard" class="headerlink" title="Why is Graph Deep Learning Hard?"></a>Why is Graph Deep Learning Hard?</h3><ul>
<li>Networks are complex<ul>
<li>Arbitrary size and complex topological structure (i.e., no spatial locality like grids)</li>
<li>No fixed node ordering or reference point </li>
<li>Often dynamic and have multimodal features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150633660.png" alt=""></p>
<h3 id="Deep-Learning-in-Graphs"><a href="#Deep-Learning-in-Graphs" class="headerlink" title="Deep Learning in Graphs"></a>Deep Learning in Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150708217.png" alt=""></p>
<h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p>(Supervised) Machine Learning Lifecycle:  This feature, that feature. Every single time!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151141340.png" alt=""></p>
<p>Map nodes to d-dimensional  embeddings such that similar nodes in  the network are embedded close  together</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151205981.png" alt=""></p>
<h3 id="Course-Outline"><a href="#Course-Outline" class="headerlink" title="Course Outline"></a>Course Outline</h3><p>We are going to cover various topics in Machine  Learning and Representation Learning for graph  structured data: </p>
<ul>
<li>Traditional methods: Graphlets, Graph Kernels </li>
<li>Methods for node embeddings: DeepWalk, Node2Vec</li>
<li>Graph Neural Networks: GCN, GraphSAGE, GAT,  Theory of GNNs </li>
<li>Knowledge graphs and reasoning: TransE, BetaE </li>
<li>Deep generative models for graphs: GraphRNN </li>
<li>Applications to Biomedicine, Science, Industry</li>
</ul>
<h2 id="Applications-of-Graph-ML"><a href="#Applications-of-Graph-ML" class="headerlink" title="Applications of Graph ML"></a>Applications of Graph ML</h2><h3 id="Different-Types-of-Tasks"><a href="#Different-Types-of-Tasks" class="headerlink" title="Different Types of Tasks"></a>Different Types of Tasks</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151422981.png" alt=""></p>
<h3 id="Classic-Graph-ML-Tasks"><a href="#Classic-Graph-ML-Tasks" class="headerlink" title="Classic Graph ML Tasks"></a>Classic Graph ML Tasks</h3><ul>
<li>Node classification: Predict a property of a node <ul>
<li>Example: Categorize online users / items </li>
</ul>
</li>
<li>Link prediction: Predict whether there are missing  links between two nodes <ul>
<li>Example: Knowledge graph completion </li>
</ul>
</li>
<li>Graph classification: Categorize different graphs <ul>
<li>Example: Molecule property prediction </li>
</ul>
</li>
<li>Clustering: Detect if nodes form a community <ul>
<li>Example: Social circle detection </li>
</ul>
</li>
<li>Other tasks: <ul>
<li>Graph generation: Drug discovery </li>
<li>Graph evolution: Physical simulation</li>
</ul>
</li>
</ul>
<h2 id="Node-level-ML-Tasks"><a href="#Node-level-ML-Tasks" class="headerlink" title="Node-level ML Tasks"></a>Node-level ML Tasks</h2><h3 id="Protein-Folding"><a href="#Protein-Folding" class="headerlink" title="Protein Folding"></a>Protein Folding</h3><p><strong>A protein chain acquires its native 3D structure</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151653238.png" alt=""></p>
<p><strong>The Protein Folding Problem</strong></p>
<p>Computationally predict a protein’s 3D structure  based solely on its amino acid sequence</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151741995.png" alt=""></p>
<h3 id="Alphafold-Impact"><a href="#Alphafold-Impact" class="headerlink" title="Alphafold: Impact"></a>Alphafold: Impact</h3><ul>
<li>Key idea: “Spatial graph” <ul>
<li>Nodes: Amino acids in a protein sequence </li>
<li>Edges: Proximity between amino acids (residues)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151833311.png" alt=""></p>
<h2 id="Edge-level-ML-Tasks"><a href="#Edge-level-ML-Tasks" class="headerlink" title="Edge-level ML Tasks"></a>Edge-level ML Tasks</h2><h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><ul>
<li>Users interacts with items <ul>
<li>Watch movies, buy merchandise, listen to music </li>
<li>Nodes: Users and items </li>
<li>Edges: User-item interactions </li>
</ul>
</li>
<li>Goal: Recommend items users might like</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151940591.png" alt=""></p>
<h3 id="Pinsage-Graph-based-Recommender"><a href="#Pinsage-Graph-based-Recommender" class="headerlink" title="Pinsage: Graph-based Recommender"></a>Pinsage: Graph-based Recommender</h3><p><a href="https://arxiv.org/pdf/1806.01973.pdf" target="_blank" rel="noopener">Ying et al., Graph Convolutional Neural Networks for Web-Scale Recommender Systems, KDD 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152019114.png" alt=""></p>
<h3 id="Drug-Side-Effects"><a href="#Drug-Side-Effects" class="headerlink" title="Drug Side Effects"></a>Drug Side Effects</h3><ul>
<li>Many patients take multiple drugs to treat  complex or co-existing diseases:<ul>
<li>46% of people ages 70-79 take more than 5 drugs </li>
<li>Many patients take more than 20 drugs to treat  heart disease, depression, insomnia, etc.</li>
</ul>
</li>
<li>Task: Given a pair of drugs predict  adverse side effects</li>
</ul>
<h3 id="Biomedical-Graph-Link-Prediction"><a href="#Biomedical-Graph-Link-Prediction" class="headerlink" title="Biomedical Graph Link Prediction"></a>Biomedical Graph Link Prediction</h3><p><a href="https://arxiv.org/pdf/1802.00543.pdf" target="_blank" rel="noopener">Zitnik et al., Modeling Polypharmacy Side Effects with Graph Convolutional Networks, Bioinformatics 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152134532.png" alt=""></p>
<h2 id="Subgraph-level-ML-Tasks"><a href="#Subgraph-level-ML-Tasks" class="headerlink" title="Subgraph-level ML Tasks"></a>Subgraph-level ML Tasks</h2><h3 id="Traffic-Prediction"><a href="#Traffic-Prediction" class="headerlink" title="Traffic Prediction"></a>Traffic Prediction</h3><p><strong>Road Network as a Graph</strong></p>
<ul>
<li>Nodes: Road segments </li>
<li>Edges: Connectivity between road segments </li>
<li>Prediction: Time of Arrival (ETA)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152251501.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152307879.png" alt=""></p>
<h2 id="Graph-level-ML-Tasks"><a href="#Graph-level-ML-Tasks" class="headerlink" title="Graph-level ML Tasks"></a>Graph-level ML Tasks</h2><h3 id="Drug-Discovery"><a href="#Drug-Discovery" class="headerlink" title="Drug Discovery"></a>Drug Discovery</h3><ul>
<li>Antibiotics are small molecular graphs <ul>
<li>Nodes: Atoms </li>
<li>Edges: Chemical bonds</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152411240.png" alt=""></p>
<p><a href="https://www.mdpi.com/2079-6382/3/2/128" target="_blank" rel="noopener">Konaklieva, Monika I. “Molecular targets of β-lactam-based antimicrobials:  beyond the usual suspects.” Antibiotics 3.2 (2014): 128-142.</a></p>
<h3 id="Deep-Learning-for-Antibiotic-Discovery"><a href="#Deep-Learning-for-Antibiotic-Discovery" class="headerlink" title="Deep Learning for Antibiotic Discovery"></a>Deep Learning for Antibiotic Discovery</h3><p><a href="https://www.sciencedirect.com/science/article/pii/S0092867420301021" target="_blank" rel="noopener">Stokeset al., A Deep Learning Approach to Antibiotic Discovery, Cell 2020</a></p>
<ul>
<li>A Graph Neural Network graph classification model </li>
<li>Predict promising molecules from a pool of candidates</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152915938.png" alt=""></p>
<h3 id="Molecule-Generation-Optimization"><a href="#Molecule-Generation-Optimization" class="headerlink" title="Molecule Generation/Optimization"></a>Molecule Generation/Optimization</h3><p><a href="https://arxiv.org/pdf/1806.02473.pdf" target="_blank" rel="noopener">Youet al., Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation, NeurIPS 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152955374.png" alt=""></p>
<h3 id="Physics-Simulation"><a href="#Physics-Simulation" class="headerlink" title="Physics Simulation"></a>Physics Simulation</h3><p><a href="https://arxiv.org/pdf/2002.09405.pdf" target="_blank" rel="noopener">Sanchez-Gonzalez et al., Learning to simulate complex physics with graph networks, ICML 2020</a></p>
<ul>
<li>Physical simulation as a graph: <ul>
<li>Nodes: Particles</li>
<li>Edges: Interaction between particles</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153108274.png" alt=""></p>
<h4 id="Simulation-Learning-Framework"><a href="#Simulation-Learning-Framework" class="headerlink" title="Simulation Learning Framework"></a>Simulation Learning Framework</h4><p>A graph evolution task: </p>
<ul>
<li>Goal: Predict how a graph will evolve over</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153212413.png" alt=""></p>
<h2 id="Choice-of-Graph-Representation"><a href="#Choice-of-Graph-Representation" class="headerlink" title="Choice of Graph Representation"></a>Choice of Graph Representation</h2><h3 id="Components-of-a-Network"><a href="#Components-of-a-Network" class="headerlink" title="Components of a Network"></a>Components of a Network</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153253676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153319772.png" alt=""></p>
<h3 id="Choosing-a-Proper-Representation"><a href="#Choosing-a-Proper-Representation" class="headerlink" title="Choosing a Proper Representation"></a>Choosing a Proper Representation</h3><ul>
<li>If you connect individuals that work  with each other, you will explore a  professional network </li>
<li>If you connect those that have a  sexual relationship, you will be  exploring sexual networks </li>
<li>If you connect scientific papers that cite each other, you will be studying the citation network</li>
<li>If you connect all papers with the same word in the title,  what will you be exploring? It is a network, nevertheless</li>
</ul>
<h3 id="How-do-you-define-a-graph"><a href="#How-do-you-define-a-graph" class="headerlink" title="How do you define a graph"></a>How do you define a graph</h3><ul>
<li>How to build a graph: <ul>
<li>What are nodes? </li>
<li>What are edges? </li>
</ul>
</li>
<li>Choice of the proper network representation  of a given domain/problem determines our  ability to use networks successfully: <ul>
<li>In some cases, there is a unique, unambiguous  representation</li>
<li>In other cases, the representation is by no means unique </li>
<li>The way you assign links will determine the nature  of the question you can study</li>
</ul>
</li>
</ul>
<h3 id="Directed-vs-Undirected-Graphs"><a href="#Directed-vs-Undirected-Graphs" class="headerlink" title="Directed vs Undirected Graphs"></a>Directed vs Undirected Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153516654.png" alt=""></p>
<h3 id="Heterogeneous-Graphs"><a href="#Heterogeneous-Graphs" class="headerlink" title="Heterogeneous Graphs"></a>Heterogeneous Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153544194.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153559429.png" alt=""></p>
<h3 id="Node-Degrees"><a href="#Node-Degrees" class="headerlink" title="Node Degrees"></a>Node Degrees</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153620904.png" alt=""></p>
<h3 id="Bipartite-Graph"><a href="#Bipartite-Graph" class="headerlink" title="Bipartite Graph"></a>Bipartite Graph</h3><ul>
<li>Bipartite graph is a graph whose nodes can  be divided into two disjoint sets U and V such that  every link connects a node in U to one in V; that is,  U and V are independent sets </li>
<li>Examples: <ul>
<li>Authors-to-Papers (they authored) </li>
<li>Actors-to-Movies (they appeared in) </li>
<li>Users-to-Movies (they rated) </li>
<li>Recipes-to-Ingredients (they contain) </li>
</ul>
</li>
<li>“Folded” networks: <ul>
<li>Author collaboration networks </li>
<li>Movie co-rating networks</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153743707.png" alt=""></p>
<h3 id="FoldedProjected-Bipartite-Graphs"><a href="#FoldedProjected-Bipartite-Graphs" class="headerlink" title="FoldedProjected Bipartite Graphs"></a>FoldedProjected Bipartite Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153806330.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-Matrix"><a href="#Representing-Graphs-Adjacency-Matrix" class="headerlink" title="Representing Graphs: Adjacency Matrix"></a>Representing Graphs: Adjacency Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153828291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153842858.png" alt=""></p>
<h3 id="Networks-are-Sparse-Graphs"><a href="#Networks-are-Sparse-Graphs" class="headerlink" title="Networks are Sparse Graphs"></a>Networks are Sparse Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153938780.png" alt=""></p>
<h3 id="Representing-Graphs-Edge-list"><a href="#Representing-Graphs-Edge-list" class="headerlink" title="Representing Graphs: Edge list"></a>Representing Graphs: Edge list</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154021381.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-list"><a href="#Representing-Graphs-Adjacency-list" class="headerlink" title="Representing Graphs: Adjacency list"></a>Representing Graphs: Adjacency list</h3><ul>
<li><p>Adjacency list: </p>
<ul>
<li><p>Easier to work with if network is </p>
<ul>
<li><p>Large </p>
</li>
<li><p>Sparse </p>
</li>
</ul>
</li>
<li><p>Allows us to quickly retrieve all  neighbors of a given node </p>
<ul>
<li><p>1: </p>
</li>
<li><p>2: 3, 4 </p>
</li>
<li><p>3: 2, 4 </p>
</li>
<li><p>4: 5 </p>
</li>
<li><p>5: 1, 2</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Node-and-Edge-Attributes"><a href="#Node-and-Edge-Attributes" class="headerlink" title="Node and Edge Attributes"></a>Node and Edge Attributes</h3><ul>
<li>Possible options: <ul>
<li>Weight (e.g., frequency of communication) </li>
<li>Ranking (best friend, second best friend…) </li>
<li>Type (friend, relative, co-worker) </li>
<li>Sign: Friend vs. Foe, Trust vs. Distrust </li>
<li>Properties depending on the structure of the rest  of the graph: Number of common friends</li>
</ul>
</li>
</ul>
<h3 id="More-Types-of-Graphs"><a href="#More-Types-of-Graphs" class="headerlink" title="More Types of Graphs"></a>More Types of Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154354051.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154418078.png" alt=""></p>
<h3 id="Connectivity-of-Undirected-Graphs"><a href="#Connectivity-of-Undirected-Graphs" class="headerlink" title="Connectivity of Undirected Graphs"></a>Connectivity of Undirected Graphs</h3><ul>
<li>Connected (undirected) graph: <ul>
<li>Any two vertices can be joined by a path </li>
</ul>
</li>
<li>A disconnected graph is made up by two or  more connected components</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154501411.png" alt=""></p>
<h3 id="Connectivity-Example"><a href="#Connectivity-Example" class="headerlink" title="Connectivity: Example"></a>Connectivity: Example</h3><p>The adjacency matrix of a network with several  components can be written in a block- diagonal  form, so that nonzero elements are confined to  squares, with all other elements being zero:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154537953.png" alt=""></p>
<h3 id="Connectivity-of-Directed-Graphs"><a href="#Connectivity-of-Directed-Graphs" class="headerlink" title="Connectivity of Directed Graphs"></a>Connectivity of Directed Graphs</h3><ul>
<li>Strongly connected directed graph <ul>
<li>has a path from each node to every other node  and vice versa (e.g., A-B path and B-A path)</li>
</ul>
</li>
<li>Weakly connected directed graph <ul>
<li>is connected if we disregard the edge directions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154640547.png" alt=""></p>
<p>Strongly connected components (SCCs) can  be identified, but not every node is part of a  nontrivial strongly connected component.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154659259.png" alt=""></p>
<h1 id="Traditional-Methods-for-Machine-Learning-in-Graphs"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h1><h2 id="Traditional-Methods-for-Machine-Learning-in-Graphs-1"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs-1" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h2><h3 id="Traditional-ML-Pipeline"><a href="#Traditional-ML-Pipeline" class="headerlink" title="Traditional ML Pipeline"></a>Traditional ML Pipeline</h3><p>Design features for nodes/links/graphs </p>
<p>Obtain features for all training data</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155029705.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155040109.png" alt=""></p>
<h3 id="Feature-Desian"><a href="#Feature-Desian" class="headerlink" title="Feature Desian"></a>Feature Desian</h3><ul>
<li><p>Using effective features over graphs is the key  to achieving good model performance. </p>
</li>
<li><p>Traditional ML pipeline uses hand-designed  features. </p>
</li>
<li><p>In this lecture, we overview the traditional  features for: </p>
<ul>
<li>Node-level prediction </li>
<li>Link-level prediction </li>
<li>Graph-level prediction </li>
</ul>
</li>
<li><p>For simplicity, we focus on undirected graphs.</p>
</li>
<li><p>Goal: Make predictions for a set of objects </p>
</li>
<li><p>Design choices: </p>
<ul>
<li>Features: d-dimensional vectors </li>
<li>Objects: Nodes, edges, sets of nodes,  entire graphs </li>
<li>Objective function: <ul>
<li>What task are we aiming to solve?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155314744.png" alt=""></p>
<h2 id="Node-level-Tasks-and-Features"><a href="#Node-level-Tasks-and-Features" class="headerlink" title="Node-level Tasks and Features"></a>Node-level Tasks and Features</h2><h3 id="Node-level-Features-Overview"><a href="#Node-level-Features-Overview" class="headerlink" title="Node-level Features: Overview"></a>Node-level Features: Overview</h3><ul>
<li>Goal: Characterize the structure and position of  a node in the network: <ul>
<li>Node degree </li>
<li>Node centrality </li>
<li>Clustering coefficient </li>
<li>Graphlets</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155446882.png" alt=""></p>
<h3 id="Node-Degree"><a href="#Node-Degree" class="headerlink" title="Node Degree"></a>Node Degree</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155516487.png" alt=""></p>
<h3 id="Node-Centrality"><a href="#Node-Centrality" class="headerlink" title="Node Centrality"></a>Node Centrality</h3><ul>
<li>Node degree counts the neighboring nodes  without capturing their importance. </li>
<li>Node centrality 𝑐_𝑣 takes the node importance  in a graph into account </li>
<li>Different ways to model importance: <ul>
<li>Engienvector centrality </li>
<li>Betweenness centrality </li>
<li>Closeness centrality </li>
<li>and many others…</li>
</ul>
</li>
</ul>
<h4 id="Eigenvector-centrality"><a href="#Eigenvector-centrality" class="headerlink" title="Eigenvector centrality"></a>Eigenvector centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155636291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155651475.png" alt=""></p>
<h4 id="Betweenness-centrality"><a href="#Betweenness-centrality" class="headerlink" title="Betweenness centrality"></a>Betweenness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155709827.png" alt=""></p>
<h4 id="Closeness-centrality"><a href="#Closeness-centrality" class="headerlink" title="Closeness centrality"></a>Closeness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155731340.png" alt=""></p>
<h3 id="Clustering-Coefficient"><a href="#Clustering-Coefficient" class="headerlink" title="Clustering Coefficient"></a>Clustering Coefficient</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155816102.png" alt=""></p>
<h3 id="Graphlets"><a href="#Graphlets" class="headerlink" title="Graphlets"></a>Graphlets</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155840431.png" alt=""></p>
<ul>
<li><p>Goal: Describe network structure around node 𝑢 </p>
<ul>
<li>Graphlets are small subgraphs that describe the  structure of node 𝑢’s network neighborhood Analogy: </li>
</ul>
</li>
<li><p>Degree counts #(edges) that a node touches </p>
</li>
<li><p>Clustering coefficient counts #(triangles) that a  node touches. </p>
</li>
<li><p>Graphlet Degree Vector (GDV): Graphlet-base  features for nodes </p>
<ul>
<li>GDV counts #(graphlets) that a node touches</li>
</ul>
</li>
<li><p>Considering graphlets of size 2-5 nodes we get: </p>
<ul>
<li>Vector of 73 coordinates is a signature of a node  that describes the topology of node’s neighborhood  </li>
</ul>
</li>
<li><p>Graphlet degree vector provides a measure of  a node’s local network topology: </p>
<ul>
<li>Comparing vectors of two nodes provides a more  detailed measure of local topological similarity than  node degrees or clustering coefficient.</li>
</ul>
</li>
</ul>
<h4 id="Induced-Subgraph-Isomorphism"><a href="#Induced-Subgraph-Isomorphism" class="headerlink" title="Induced Subgraph Isomorphism"></a>Induced Subgraph Isomorphism</h4><p>Def: Induced subgraph is another graph, formed  from a subset of vertices and all of the edges  connecting the vertices in that subset.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160056026.png" alt=""></p>
<p>Def: Graph Isomorphism(同构) </p>
<ul>
<li>Two graphs which contain the same number of nodes  connected in the same way are said to be isomorphic.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160128187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160159336.png" alt=""></p>
<p><strong>Graphlet Degree Vector</strong> (GDV): A count  vector of graphlets rooted at a given node</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160238072.png" alt=""></p>
<h3 id="Node-level-Feature-Summary"><a href="#Node-level-Feature-Summary" class="headerlink" title="Node-level Feature: Summary"></a>Node-level Feature: Summary</h3><ul>
<li><p>We have introduced different ways to obtain  node features. </p>
</li>
<li><p>They can be categorized as: </p>
<ul>
<li>Importance-based features: <ul>
<li>Node degree </li>
<li>Different node centrality measures </li>
</ul>
</li>
<li>Structure-based features: <ul>
<li>Node degree </li>
<li>Clustering coefficient </li>
<li>Graphlet count vector</li>
</ul>
</li>
</ul>
</li>
<li><p>Importance-based features: capture the  importance of a node in a graph </p>
<ul>
<li>Node degree: <ul>
<li>Simply counts the number of neighboring nodes </li>
</ul>
</li>
<li>Node centrality: <ul>
<li>Models importance of neighboring nodes in a graph </li>
<li>Different modeling choices: eigenvector centrality,  betweenness centrality, closeness centrality</li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting influential nodes in a graph </p>
<ul>
<li>Example: predicting celebrity users in a social  network</li>
</ul>
</li>
<li><p>Structure-based features: Capture topological  properties of local neighborhood around a node. </p>
<ul>
<li>Node degree: <ul>
<li>Counts the number of neighboring nodes </li>
</ul>
</li>
<li>Clustering coefficient: <ul>
<li>Measures how connected neighboring nodes are </li>
</ul>
</li>
<li>Graphlet degree vector: <ul>
<li>Counts the occurrences of different graphlets </li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting a particular role a node  plays in a graph: </p>
<ul>
<li>Example: Predicting protein functionality in a  protein-protein interaction network</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164204808.png" alt=""></p>
<h2 id="Link-Prediction-Task-and-Features"><a href="#Link-Prediction-Task-and-Features" class="headerlink" title="Link Prediction Task and Features"></a>Link Prediction Task and Features</h2><h3 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h3><ul>
<li>The task is to predict new links based on the  existing links. </li>
<li>At test time, node pairs (with no existing links)  are ranked, and top 𝐾 node pairs are predicted. </li>
<li>The key is to design features for a pair of nodes.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164300332.png" alt=""></p>
<p><strong>Two formulations of the link prediction task:</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164327858.png" alt=""></p>
<h3 id="Link-Prediction-via-Proximity"><a href="#Link-Prediction-via-Proximity" class="headerlink" title="Link Prediction via Proximity"></a>Link Prediction via Proximity</h3><ul>
<li>Methodology: <ul>
<li>For each pair of nodes (x,y) compute score c(x,y) <ul>
<li>For example, c(x,y) could be the # of common neighbors  of x and y </li>
</ul>
</li>
<li>Sort pairs (x,y) by the decreasing score c(x,y) </li>
<li>Predict top n pairs as new links </li>
<li>See which of these links actually appear in 𝐺[𝑡1 ,𝑡1 ′ ]</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164503916.png" alt=""></p>
<h3 id="Link-level-Features-Overview"><a href="#Link-level-Features-Overview" class="headerlink" title="Link-level Features: Overview"></a>Link-level Features: Overview</h3><ul>
<li>Distance-based feature </li>
<li>Local neighborhood overlap </li>
<li>Global neighborhood overlap</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164529982.png" alt=""></p>
<h3 id="Distance-based-Features"><a href="#Distance-based-Features" class="headerlink" title="Distance-based Features"></a>Distance-based Features</h3><p>Shortest-path distance between two nodes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164603800.png" alt=""></p>
<p>However, this does not capture the degree of  neighborhood overlap: </p>
<ul>
<li>Node pair (B, H) has 2 shared neighboring nodes,  while pairs (B, E) and (A, B) only have 1 such node</li>
</ul>
<h3 id="Local-Neighborhood-Overlap"><a href="#Local-Neighborhood-Overlap" class="headerlink" title="Local Neighborhood Overlap"></a>Local Neighborhood Overlap</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164647894.png" alt=""></p>
<h3 id="Global-Neighborhood-Overlap"><a href="#Global-Neighborhood-Overlap" class="headerlink" title="Global Neighborhood Overlap"></a>Global Neighborhood Overlap</h3><ul>
<li><p>Limitation of local neighborhood features: </p>
<ul>
<li><p>Metric is always zero if the two nodes do not have  any neighbors in common.</p>
</li>
<li><p>However, the two nodes may still potentially be  connected in the future. </p>
</li>
</ul>
</li>
<li><p>Global neighborhood overlap metrics resolve  the limitation by considering the entire graph.</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164745624.png" alt=""></p>
<ul>
<li>Katz index: count the number of walks of all  lengths between a given pair of nodes. </li>
<li>Q: How to compute #walks between two  nodes? <ul>
<li>Use powers of the graph adjacency matrix!</li>
</ul>
</li>
</ul>
<h4 id="Intuition-Powers-of-Adj-Matrices"><a href="#Intuition-Powers-of-Adj-Matrices" class="headerlink" title="Intuition: Powers of Adj Matrices"></a>Intuition: Powers of Adj Matrices</h4><p><strong>Computing #walks between two nodes</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164853647.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164908991.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165005720.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165018384.png" alt=""></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Distance-based features: <ul>
<li>Uses the shortest path length between two nodes  but does not capture how neighborhood overlaps. </li>
</ul>
</li>
<li>Local neighborhood overlap: <ul>
<li>Captures how many neighboring nodes are shared  by two nodes. </li>
<li>Becomes zero when no neighbor nodes are shared. </li>
</ul>
</li>
<li>Global neighborhood overlap: <ul>
<li>Uses global graph structure to score two nodes. </li>
<li>Katz index counts #walks of all lengths between two  nodes.</li>
</ul>
</li>
</ul>
<h2 id="Graph-level-Features-and-Graph-Kernels"><a href="#Graph-level-Features-and-Graph-Kernels" class="headerlink" title="Graph-level Features and Graph Kernels"></a>Graph-level Features and Graph Kernels</h2><h3 id="Graph-level-Features"><a href="#Graph-level-Features" class="headerlink" title="Graph-level Features"></a>Graph-level Features</h3><p>Goal: We want features that characterize the  structure of an entire graph</p>
<h3 id="Backaround-Kernel-Methods"><a href="#Backaround-Kernel-Methods" class="headerlink" title="Backaround Kernel Methods"></a>Backaround Kernel Methods</h3><ul>
<li>Kernel methods are widely-used for traditional  ML for graph-level prediction. </li>
<li>Idea: Design kernels instead of feature vectors. </li>
<li>A quick introduction to Kernels:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165703860.png" alt=""></p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li>Graph Kernels: Measure similarity between  two graphs: <ul>
<li>Graphlet Kernel [1] </li>
<li>Weisfeiler-Lehman Kernel [2] </li>
<li>Other kernels are also proposed in the literature  (beyond the scope of this lecture) <ul>
<li>Random-walk kernel </li>
<li>Shortest-path graph kernel </li>
<li>And many more…</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>[1] Shervashidze, Nino, et al. “Efficient graphlet kernels for large graph comparison.” Artificial Intelligence and Statistics. 2009. </p>
<p>[2] Shervashidze, Nino, et al. “Weisfeiler-lehman graph kernels.” Journal of Machine Learning Research 12.9 (2011).</p>
<h3 id="Graph-Kernel-Key-Idea"><a href="#Graph-Kernel-Key-Idea" class="headerlink" title="Graph Kernel: Key Idea"></a>Graph Kernel: Key Idea</h3><ul>
<li>Goal: Design graph feature vector 𝜙(𝐺) </li>
<li>Key idea: Bag-of-Words (BoW) for a graph <ul>
<li>Recall: BoW simply uses the word counts as  features for documents (no ordering considered). </li>
<li>Naïve extension to a graph: Regard nodes as words. </li>
<li>Since both graphs have 4 red nodes, we get the  same feature vector for two different graphs…</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170336494.png" alt=""></p>
<p>What if we use Bag of node degrees?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170358374.png" alt=""></p>
<p>Both Graphlet Kernel and Weisfeiler-Lehman  (WL) Kernel use Bag-of-* representation of  graph, where * is more sophisticated than  node degrees!</p>
<h3 id="Graphlet-Features"><a href="#Graphlet-Features" class="headerlink" title="Graphlet Features"></a>Graphlet Features</h3><ul>
<li>Key idea: Count the number of different  graphlets in a graph. <ul>
<li>Note: Definition of graphlets here is slightly  different from node-level features.  </li>
<li>The two differences are: <ul>
<li>Nodes in graphlets here do not need to be connected (allows for  isolated nodes) </li>
<li>The graphlets here are not rooted. </li>
<li>Examples in the next slide illustrate this.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170616974.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170627979.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170640069.png" alt=""></p>
<h3 id="Graphlet-Kernel"><a href="#Graphlet-Kernel" class="headerlink" title="Graphlet Kernel"></a>Graphlet Kernel</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170712399.png" alt=""></p>
<ul>
<li><p>Limitations: Counting graphlets is expensive! </p>
</li>
<li><p>Counting size-𝑘 graphlets for a graph with size 𝑛 by enumeration takes 𝑛^𝑘 . </p>
</li>
<li><p>This is unavoidable in the worst-case since  subgraph isomorphism test (judging whether a  graph is a subgraph of another graph) is NP-hard. </p>
</li>
<li><p>If a graph’s node degree is bounded by 𝑑, an  𝑂(𝑛𝑑^(𝑘−1)) algorithm exists to count all the  graphlets of size 𝑘.  </p>
<p><strong>Can we design a more efficient graph kernel?</strong></p>
</li>
</ul>
<h3 id="Weisfeiler-lehman-Kernel"><a href="#Weisfeiler-lehman-Kernel" class="headerlink" title="Weisfeiler-lehman Kernel"></a>Weisfeiler-lehman Kernel</h3><ul>
<li>Goal: Design an efficient graph feature  descriptor 𝜙 (𝐺) </li>
<li>Idea: Use neighborhood structure to  iteratively enrich node vocabulary.  </li>
<li>Generalized version of Bag of node degrees since  node degrees are one-hop neighborhood  information. </li>
<li>Algorithm to achieve this: Color refinement</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170929956.png" alt=""></p>
<p>Example of color refinement given two graphs</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170948187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170958604.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171007420.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171017926.png" alt=""></p>
<p>After color refinement, WL kernel counts number  of nodes with a given color.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171038806.png" alt=""></p>
<p>The WL kernel value is computed by the inner  product of the color count vectors: </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171053600.png" alt=""></p>
<ul>
<li>WL kernel is computationally efficient <ul>
<li>The time complexity for color refinement at each step is  linear in #(edges), since it involves aggregating neighboring  colors. </li>
</ul>
</li>
<li>When computing a kernel value, only colors  appeared in the two graphs need to be tracked. <ul>
<li>Thus, #(colors) is at most the total number of nodes. </li>
</ul>
</li>
<li>Counting colors takes linear-time w.r.t. #(nodes). </li>
<li>In total, time complexity is linear in #(edges)</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><p>Graphlet Kernel </p>
<ul>
<li>Graph is represented as Bag-of-graphlets </li>
<li>Computationally expensive </li>
</ul>
</li>
<li><p>Weisfeiler-Lehman Kernel </p>
<ul>
<li>Apply 𝐾-step color refinement algorithm to enrich  node colors <ul>
<li>Different colors capture different 𝐾-hop neighborhood  structures </li>
</ul>
</li>
<li>Graph is represented as Bag-of-colors </li>
<li>Computationally efficient </li>
<li>Closely related to Graph Neural Networks (as we  will see!)</li>
</ul>
</li>
<li><p>Traditional ML Pipeline </p>
<ul>
<li>Hand-crafted feature + ML model </li>
</ul>
</li>
<li><p>Hand-crafted features for graph data </p>
<ul>
<li>Node-level: <ul>
<li>Node degree, centrality, clustering coefficient, graphlets </li>
</ul>
</li>
<li>Link-level: <ul>
<li>distance-based feature </li>
<li>local/global neighborhood overlap </li>
</ul>
</li>
<li>Graph-level: <ul>
<li>Graphlet kernel, WL kernel</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Node-Embeddings"><a href="#Node-Embeddings" class="headerlink" title="Node Embeddings"></a>Node Embeddings</h1><p>Goal: Efficient task-independent feature  learning for machine learning with graphs!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114184930238.png" alt=""></p>
<h2 id="Why-Embedding"><a href="#Why-Embedding" class="headerlink" title="Why Embedding?"></a>Why Embedding?</h2><ul>
<li>Task: Map nodes into an embedding space <ul>
<li>Similarity of embeddings between nodes indicates  their similarity in the network. For example: <ul>
<li>Both nodes are close to each other (connected by an edge) </li>
</ul>
</li>
<li>Encode network information </li>
<li>Potentially used for many downstream predictions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185054537.png" alt=""></p>
<p>2D embedding of nodes of the Zachary’s  Karate Club network:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185117044.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Perozzi et al. DeepWalk: Online Learning of Social Representations. KDD 2014</a></p>
<h2 id="Node-Embeddings-Encoder-and-Decoder"><a href="#Node-Embeddings-Encoder-and-Decoder" class="headerlink" title="Node Embeddings Encoder and Decoder"></a>Node Embeddings Encoder and Decoder</h2><h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><ul>
<li>Assume we have a graph G: <ul>
<li>V is the vertex set. </li>
<li>A is the adjacency matrix (assume binary). </li>
<li>For simplicity: No node features or extra  information is used</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185313810.png" alt=""></p>
<h3 id="Embedding-Nodes"><a href="#Embedding-Nodes" class="headerlink" title="Embedding Nodes"></a>Embedding Nodes</h3><p>Goal is to encode nodes so that similarity in  the embedding space (e.g., dot product)  approximates similarity in the graph</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185343379.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185359370.png" alt=""></p>
<h4 id="Learning-Node-Embeddings"><a href="#Learning-Node-Embeddings" class="headerlink" title="Learning Node Embeddings"></a>Learning Node Embeddings</h4><ol>
<li>Encoder maps from nodes to embeddings </li>
<li>Define a node similarity function (i.e., a  measure of similarity in the original network) </li>
<li>Decoder 𝐃𝐄𝐂 maps from embeddings to the  similarity score </li>
<li>Optimize the parameters of the encoder so  that:</li>
</ol>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185507005.png" alt=""></p>
<h4 id="Two-Key-Components"><a href="#Two-Key-Components" class="headerlink" title="Two Key Components"></a>Two Key Components</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185541120.png" alt=""></p>
<h4 id="“shallow”Encoding"><a href="#“shallow”Encoding" class="headerlink" title="“shallow”Encoding"></a>“shallow”Encoding</h4><p>Simplest encoding approach: Encoder is just an  embedding-lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185622676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185653217.png" alt=""></p>
<ul>
<li>Each node is assigned a unique embedding vector (i.e., we directly optimize the embedding of each node) </li>
<li>Many methods: DeepWalk, node2vec</li>
</ul>
<h3 id="Framework-Summary"><a href="#Framework-Summary" class="headerlink" title="Framework Summary"></a>Framework Summary</h3><p>Encoder + Decoder Framework</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185821145.png" alt=""></p>
<h3 id="How-to-Define-Node-Similarit"><a href="#How-to-Define-Node-Similarit" class="headerlink" title="How to Define Node Similarit"></a>How to Define Node Similarit</h3><ul>
<li>Key choice of methods is how they define node similarity. </li>
<li>Should two nodes have a similar embedding if  they… <ul>
<li>are linked? </li>
<li>share neighbors? </li>
<li>have similar “structural roles”? </li>
</ul>
</li>
<li>We will now learn node similarity definition that uses  random walks, and how to optimize embeddings for  such a similarity measure.</li>
</ul>
<h3 id="Note-on-Node-Embeddings"><a href="#Note-on-Node-Embeddings" class="headerlink" title="Note on Node Embeddings"></a>Note on Node Embeddings</h3><ul>
<li>This is unsupervised/self-supervisedway of  learning node embeddings. <ul>
<li>We are not utilizing node labels </li>
<li>We are not utilizing node features </li>
<li>The goal is to directly estimate a set of coordinates  (i.e., the embedding) of a node so that some aspect  of the network structure (captured by DEC) is  preserved. </li>
</ul>
</li>
<li>These embeddings are task independent <ul>
<li>They are not trained for a specific task but can be  used for any task.</li>
</ul>
</li>
</ul>
<h2 id="Random-Walk-Approaches-for-Node-Embeddings"><a href="#Random-Walk-Approaches-for-Node-Embeddings" class="headerlink" title="Random Walk Approaches for Node Embeddings"></a>Random Walk Approaches for Node Embeddings</h2><h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114190246623.png" alt=""></p>
<h3 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191224897.png" alt=""></p>
<h3 id="Random-walk-Embeddings"><a href="#Random-walk-Embeddings" class="headerlink" title="Random-walk Embeddings"></a>Random-walk Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191304620.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191410904.png" alt=""></p>
<h3 id="Why-Random-Walks"><a href="#Why-Random-Walks" class="headerlink" title="Why Random Walks?"></a>Why Random Walks?</h3><ol>
<li>Expressivity: Flexible stochastic(随机的) definition of  node similarity that incorporates both local  and higher-order neighborhood information Idea: if random walk starting from node 𝑢 visits 𝑣 with high probability, 𝑢 and 𝑣 are  similar (high-order multi-hop information) </li>
<li>Efficiency: Do not need to consider all node  pairs when training; only need to consider  pairs that co-occur on random walks</li>
</ol>
<h3 id="Unsupervised-Feature-Learning"><a href="#Unsupervised-Feature-Learning" class="headerlink" title="Unsupervised Feature Learning"></a>Unsupervised Feature Learning</h3><ul>
<li>Intuition: Find embedding of nodes in  𝑑-dimensional space that preserves similarity </li>
<li>Idea: Learn node embedding such that nearby nodes are close together in the network </li>
<li>Given a node 𝑢, how do we define nearby  nodes?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191744402.png" alt=""></p>
<h3 id="Feature-Learning-as-Optimization"><a href="#Feature-Learning-as-Optimization" class="headerlink" title="Feature Learning as Optimization"></a>Feature Learning as Optimization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191851755.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192332640.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192807843.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193211508.png" alt=""></p>
<p>But doing this naively is too expensive!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193322978.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193414462.png" alt=""></p>
<h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193458015.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194423952.png" alt=""></p>
<h4 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194708482.png" alt=""></p>
<p>Stochastic Gradient Descent: Instead of evaluating  gradients over all examples, evaluate it for each  individual training example.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194843074.png" alt=""></p>
<h3 id="Random-Walks：Summary"><a href="#Random-Walks：Summary" class="headerlink" title="Random Walks：Summary"></a>Random Walks：Summary</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195157506.png" alt=""></p>
<h3 id="How-should-we-randomly-walk"><a href="#How-should-we-randomly-walk" class="headerlink" title="How should we randomly walk?"></a>How should we randomly walk?</h3><ul>
<li>So far we have described how to optimize  embeddings given a random walk strategy R -</li>
<li>What strategies should we use to run these  random walks? <ul>
<li>Simplest idea: Just run fixed-length, unbiased  random walks starting from each node (i.e.,  DeepWalk from Perozzi et al., 2013) <ul>
<li>The issue is that such notion of similarity is too constrained </li>
</ul>
</li>
</ul>
</li>
<li>How can we generalize this?</li>
</ul>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Reference: Perozzi et al. 2014. DeepWalk: Online Learning of Social Representations. KDD</a></p>
<h3 id="Overview-of-node2vec"><a href="#Overview-of-node2vec" class="headerlink" title="Overview of node2vec"></a>Overview of node2vec</h3><p><a href="https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf" target="_blank" rel="noopener">Reference: Grover et al. 2016. node2vec: Scalable Feature Learning for Networks. KDD</a></p>
<ul>
<li>Goal: Embed nodes with similar network  neighborhoods close in the feature space. </li>
<li>We frame this goal as a maximum likelihood  optimization problem, independent to the  downstream prediction task.</li>
<li>Key observation: Flexible notion of network  neighborhood 𝑁_𝑅(𝑢) of node 𝑢 leads to rich node  embeddings</li>
<li>Develop biased 2^nd order random walk 𝑅 to  generate network neighborhood 𝑁_𝑅(𝑢) of node 𝑢</li>
</ul>
<h4 id="node2vec-Biased-Walks"><a href="#node2vec-Biased-Walks" class="headerlink" title="node2vec: Biased Walks"></a>node2vec: Biased Walks</h4><p>Idea: use flexible, biased random walks that can  trade off between local and global views of the  network (Grover and Leskovec, 2016). </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195719803.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195734036.png" alt=""></p>
<h4 id="BFS-VS-DFS"><a href="#BFS-VS-DFS" class="headerlink" title="BFS VS.DFS"></a>BFS VS.DFS</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114200935414.png" alt=""></p>
<ul>
<li>Biased fixed-length random walk 𝑹 that given a  node 𝒖 generates neighborhood 𝑵_𝑹(𝒖) <ul>
<li>Two parameters: <ul>
<li>Return parameter 𝒑: <ul>
<li>Return back to the previous node </li>
</ul>
</li>
</ul>
</li>
<li>In-out parameter 𝒒: <ul>
<li>Moving outwards (DFS) vs. inwards (BFS) </li>
<li>Intuitively, 𝑞 is the “ratio” of BFS vs. DFS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Biased-Random-Walks"><a href="#Biased-Random-Walks" class="headerlink" title="Biased Random Walks"></a>Biased Random Walks</h4><ul>
<li>Biased 2nd -order random walks explore network neighborhoods: <ul>
<li>Rnd. walk just traversed edge (𝑠1 , 𝑤) and is now at 𝑤 </li>
<li>Insight: Neighbors of 𝑤 can only be:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201220400.png" alt=""></p>
<p>Idea: Remember where the walk came from</p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
<li>𝑝, 𝑞 model transition probabilities <ul>
<li>𝑝 … return parameter </li>
<li>𝑞 … ”walk away” parameter</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201325434.png" alt=""></p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201455606.png" alt=""></p>
<h3 id="node2vec-algorithm"><a href="#node2vec-algorithm" class="headerlink" title="node2vec algorithm"></a>node2vec algorithm</h3><p>1) Compute random walk probabilities </p>
<p>2) Simulate 𝑟 random walks of length 𝑙 starting  from each node 𝑢 </p>
<p>3) Optimize the node2vec objective using  Stochastic Gradient Descent </p>
<p>   Linear-time complexity </p>
<p>   All 3 steps are individually parallelizable</p>
<h3 id="Other-Random-Walk-Ideas"><a href="#Other-Random-Walk-Ideas" class="headerlink" title="Other Random Walk Ideas"></a>Other Random Walk Ideas</h3><ul>
<li>Different kinds of biased random walks: <ul>
<li><a href="https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf" target="_blank" rel="noopener">Based on node attributes (Dong et al., 2017).</a> </li>
<li><a href="https://arxiv.org/abs/1710.09599" target="_blank" rel="noopener">Based on learned weights (Abu-El-Haija et al., 2017)</a> </li>
</ul>
</li>
<li>Alternative optimization schemes: <ul>
<li><a href="https://arxiv.org/abs/1503.03578" target="_blank" rel="noopener">Directly optimize based on 1-hop and 2-hop random walk  probabilities (as in LINE from Tang et al. 2015).</a> </li>
</ul>
</li>
<li>Network preprocessing techniques: <ul>
<li><a href="https://arxiv.org/abs/1706.07845" target="_blank" rel="noopener">Run random walks on modified versions of the original  network (e.g., Ribeiro et al. 2017’s struct2vec, Chen et al.  2016’s HARP).</a></li>
</ul>
</li>
</ul>
<h3 id="Summary-so-far"><a href="#Summary-so-far" class="headerlink" title="Summary so far"></a>Summary so far</h3><ul>
<li><p>Core idea: Embed nodes so that distances in  embedding space reflect node similarities in  the original network. </p>
</li>
<li><p>Different notions of node similarity: </p>
<ul>
<li>Naïve: similar if two nodes are connected </li>
<li>Neighborhood overlap (covered in Lecture 2) </li>
<li>Random walk approaches (covered today)</li>
</ul>
</li>
<li><p>So what method should I use..? </p>
</li>
<li><p>No one method wins in all cases…. </p>
<ul>
<li>E.g., node2vec performs better on node classification  while alternative methods perform better on link  prediction (<a href="https://arxiv.org/abs/1705.02801" target="_blank" rel="noopener">Goyal and Ferrara, 2017 survey)</a>. </li>
</ul>
</li>
<li><p>Random walk approaches are generally more  efficient. </p>
</li>
<li><p>In general: Must choose definition of node  similarity that matches your application.</p>
</li>
</ul>
<h2 id="Embedding-Entire-Graphs"><a href="#Embedding-Entire-Graphs" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h2><h3 id="Embedding-Entire-Graphs-1"><a href="#Embedding-Entire-Graphs-1" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114202611575.png" alt=""></p>
<h3 id="Approach-l"><a href="#Approach-l" class="headerlink" title="Approach l"></a>Approach l</h3><ul>
<li><p>Simple (but effective) approach 1:  </p>
<ul>
<li>Run a standard graph embedding  technique on the (sub)graph 𝐺. </li>
<li>Then just sum (or average) the node  embeddings in the (sub)graph 𝐺.</li>
</ul>
<img src="/images/loading.gif" data-original="../images/ML/image-20211114203010880.png" style="zoom:50%;">

</li>
</ul>
<p><a href="https://arxiv.org/abs/1509.09292" target="_blank" rel="noopener">Used by Duvenaud et al., 2016 to classify  molecules based on their graph structure</a></p>
<h3 id="Approach-2"><a href="#Approach-2" class="headerlink" title="Approach 2"></a>Approach 2</h3><p>Approach 2: Introduce a “virtual node” to  represent the (sub)graph and run a standard  graph embedding technique</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203037704.png" alt=""></p>
<p><a href="https://arxiv.org/abs/1511.05493" target="_blank" rel="noopener">Proposed by Li et al., 2016 as a general  technique for subgraph embedding</a></p>
<h3 id="Approach-3-Anonymous-Walk-Embeddings"><a href="#Approach-3-Anonymous-Walk-Embeddings" class="headerlink" title="Approach 3: Anonymous Walk Embeddings"></a>Approach 3: Anonymous Walk Embeddings</h3><p>States in anonymous(匿名的) walks correspond to the index of the first time we visited the node in a  random walk</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203144450.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<ul>
<li><p>Agnostic to the identity of the nodes visited  (hence anonymous) </p>
</li>
<li><p>Example: Random walk w1 :</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203318023.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203337873.png" alt=""></p>
<h4 id="Number-of-Walks-Grows"><a href="#Number-of-Walks-Grows" class="headerlink" title="Number of Walks Grows"></a>Number of Walks Grows</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203413849.png" alt=""></p>
<h4 id="Simple-Use-of-Anonymous-Walks"><a href="#Simple-Use-of-Anonymous-Walks" class="headerlink" title="Simple Use of Anonymous Walks"></a>Simple Use of Anonymous Walks</h4><ul>
<li><p>Simulate anonymous walks 𝑤𝑖 of 𝑙 steps and  record their counts. </p>
</li>
<li><p>Represent the graph as a probability  distribution over these walks. </p>
</li>
<li><p>For example:  </p>
<ul>
<li>Set 𝑙 = 3 </li>
<li>Then we can represent the graph as a 5-dim vector <ul>
<li>Since there are 5 anonymous walks 𝑤𝑖 of length 3: 111, 112,  121, 122, 123 </li>
</ul>
</li>
<li>𝒛_𝑮[𝑖] = probability of anonymous walk 𝑤𝑖 in graph 𝐺.</li>
</ul>
</li>
<li><p>Sampling anonymous walks: Generate  independently a set of 𝑚 random walks. </p>
</li>
<li><p>Represent the graph as a probability distribution  over these walks. </p>
</li>
<li><p>How many random walks 𝑚 do we need?</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203740427.png" alt=""></p>
<h3 id="New-idea-Learn-Walk-Embeddings"><a href="#New-idea-Learn-Walk-Embeddings" class="headerlink" title="New idea: Learn Walk Embeddings"></a>New idea: Learn Walk Embeddings</h3><p>Rather than simply representing each walk by the  fraction of times it occurs, we learn embedding 𝒛_𝒊 of anonymous walk 𝒘_𝒊 .</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203928449.png" alt=""></p>
<p>How to embed walks? </p>
<p>Idea: Embed walks s.t. the next walk can be  predicted</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204007342.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204043648.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204507319.png" alt=""></p>
<h3 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We discussed 3 ideas to graph embeddings: </li>
<li>Approach 1: Embed nodes and sum/avg them </li>
<li>Approach 2: Create super-node that spans the  (sub) graph and then embed that node. </li>
<li>Approach 3: Anonymous Walk Embeddings <ul>
<li>Idea 1: Sample the anon. walks and represent the  graph as fraction of times each anon walk occurs. </li>
<li>Idea 2: Learn graph embedding together with  anonymous walk embeddings.</li>
</ul>
</li>
</ul>
<h3 id="Preview-Hierarchical-Embeddings"><a href="#Preview-Hierarchical-Embeddings" class="headerlink" title="Preview: Hierarchical Embeddings"></a>Preview: Hierarchical Embeddings</h3><ul>
<li>We will discuss more advanced ways to obtain  graph embeddings in Lecture 8. </li>
<li>We can hierarchically cluster nodes in graphs,  and sum/avg the node embeddings according  to these clusters.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204746252.png" alt=""></p>
<h3 id="How-to-Use-Embeddings"><a href="#How-to-Use-Embeddings" class="headerlink" title="How to Use Embeddings"></a>How to Use Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204819921.png" alt=""></p>
<ul>
<li>Encoder-decoder framework: <ul>
<li>Encoder: embedding lookup </li>
<li>Decoder: predict score based on embedding to match  node similarity </li>
</ul>
</li>
<li>Node similarity measure: (biased) random walk <ul>
<li>Examples: DeepWalk, Node2Vec </li>
</ul>
</li>
<li>Extension to Graph embedding: Node embedding  aggregation and Anonymous Walk Embeddings</li>
</ul>
<h1 id="Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings"><a href="#Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings" class="headerlink" title="Graph as Matrix: Pagerank, Random Walks and Embeddings"></a>Graph as Matrix: Pagerank, Random Walks and Embeddings</h1><h2 id="Pagerank-aka-the-Google-Algorithm"><a href="#Pagerank-aka-the-Google-Algorithm" class="headerlink" title="Pagerank(aka the Google Algorithm)"></a>Pagerank(aka the Google Algorithm)</h2><h3 id="Example-The-Web-as-a-Graph"><a href="#Example-The-Web-as-a-Graph" class="headerlink" title="Example: The Web as a Graph"></a>Example: The Web as a Graph</h3><ul>
<li>Q: What does the Web “look like” at  a global level? </li>
<li>Web as a graph: <ul>
<li>Nodes = web pages </li>
<li>Edges = hyperlinks </li>
<li>Side issue: What is a node? <ul>
<li>Dynamic pages created on the fly </li>
<li>“dark matter” – inaccessible  database generated pages</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214917553.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214932840.png" alt=""></p>
<h3 id="What-Does-the-Web-Look-Like"><a href="#What-Does-the-Web-Look-Like" class="headerlink" title="What Does the Web Look Like?"></a>What Does the Web Look Like?</h3><ul>
<li>How is the Web linked? </li>
<li>What is the “map” of the Web? </li>
<li>Web as a directed graph [Broder et al. 2000]: <ul>
<li>Given node v, what nodes can v reach?  </li>
<li>What other nodes can reach v?</li>
</ul>
</li>
</ul>
<h3 id="Ranking-Nodes-on-the-Graph"><a href="#Ranking-Nodes-on-the-Graph" class="headerlink" title="Ranking Nodes on the Graph"></a>Ranking Nodes on the Graph</h3><ul>
<li>All web pages are not equally “important” <a href="http://www.thispersondoesnotexist.com" target="_blank" rel="noopener">www.thispersondoesnotexist.com</a> vs. <a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> </li>
<li>There is large diversity  in the web-graph  node connectivity. </li>
<li>So, let’s rank the pages  using the web graph link structure!</li>
</ul>
<h3 id="Link-Analysis-Algorithms"><a href="#Link-Analysis-Algorithms" class="headerlink" title="Link Analysis Algorithms"></a>Link Analysis Algorithms</h3><ul>
<li>We will cover the following Link Analysis approaches to compute the importance of  nodes in a graph: <ul>
<li>PageRank </li>
<li>Personalized PageRank (PPR) </li>
<li>Random Walk with Restarts</li>
</ul>
</li>
</ul>
<h3 id="Links-as-Votes"><a href="#Links-as-Votes" class="headerlink" title="Links as Votes"></a>Links as Votes</h3><ul>
<li>Idea: Links as votes <ul>
<li>Page is more important if it has more links <ul>
<li>In-coming links? Out-going links? </li>
</ul>
</li>
</ul>
</li>
<li>Think of in-links as votes: <ul>
<li><a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> has 23,400 in-links </li>
<li>thispersondoesnotexist.com has 1 in-link </li>
</ul>
</li>
<li>Are all in-links equal? <ul>
<li>Links from important pages count more </li>
<li>Recursive question! </li>
</ul>
</li>
</ul>
<h3 id="Pagerank-The”Flow”Model"><a href="#Pagerank-The”Flow”Model" class="headerlink" title="Pagerank: The”Flow”Model"></a>Pagerank: The”Flow”Model</h3><ul>
<li>A “vote” from an important page is worth more: <ul>
<li>Each link’s vote is proportional  to the importance of its source  page </li>
<li>If page i with importance ri has  di out-links, each link gets ri / di votes </li>
<li>Page j’s own importance rj is  the sum of the votes on its in-links</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215430610.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215601977.png" alt=""></p>
<h3 id="Pagerank-Matrix-Formulation"><a href="#Pagerank-Matrix-Formulation" class="headerlink" title="Pagerank: Matrix Formulation"></a>Pagerank: Matrix Formulation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215711107.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215755515.png" alt=""></p>
<h3 id="Connection-to-Random-Walk"><a href="#Connection-to-Random-Walk" class="headerlink" title="Connection to Random Walk"></a>Connection to Random Walk</h3><ul>
<li>Imagine a random web surfer: <ul>
<li>At any time 𝒕, surfer is on some page 𝑖 </li>
<li>At time 𝒕 + 𝟏, the surfer follows an  out-link from 𝒊 uniformly at random </li>
<li>Ends up on some page 𝒋 linked from 𝒊 </li>
<li>Process repeats indefinitely </li>
</ul>
</li>
<li>Let: <ul>
<li>𝒑(𝒕) … vector whose 𝑖^th coordinate is the  prob. that the surfer is at page 𝑖 at time 𝑡 </li>
<li>So, 𝒑(𝒕) is a probability distribution over pages</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114220023823.png" alt=""></p>
<h3 id="The-Stationary-Distribution"><a href="#The-Stationary-Distribution" class="headerlink" title="The Stationary Distribution"></a>The Stationary Distribution</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222138055.png" alt=""></p>
<h3 id="Recall-Eigenvector-of-A-Matrix"><a href="#Recall-Eigenvector-of-A-Matrix" class="headerlink" title="Recall Eigenvector of A Matrix"></a>Recall Eigenvector of A Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222334844.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222411167.png" alt=""></p>
<h3 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h3><p>PageRank: </p>
<ul>
<li>Measures importance of nodes in a graph using  the link structure of the web </li>
<li>Models a random web surfer using the stochastic  adjacency matrix 𝑴 </li>
<li>PageRank solves 𝒓 = 𝑴𝒓 where 𝒓 can be viewed  as both the principle eigenvector of 𝑴 and as the  stationary distribution of a random walk over the  graph</li>
</ul>
<h2 id="Pagerank-How-to-solve"><a href="#Pagerank-How-to-solve" class="headerlink" title="Pagerank: How to solve?"></a>Pagerank: How to solve?</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222947387.png" alt=""></p>
<h3 id="Power-Iteration-Method"><a href="#Power-Iteration-Method" class="headerlink" title="Power Iteration Method"></a>Power Iteration Method</h3><p>Given a web graph with N nodes, where the  nodes are pages and edges are hyperlinks</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223059886.png" alt=""></p>
<p>About 50 iterations is sufficient to estimate the limiting solution.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223659426.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223740435.png" alt=""></p>
<h3 id="Three-Ouestions"><a href="#Three-Ouestions" class="headerlink" title="Three Ouestions"></a>Three Ouestions</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223836586.png" alt=""></p>
<ul>
<li>Does this converge? </li>
<li>Does it converge to what we want? </li>
<li>Are results reasonable?</li>
</ul>
<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><p>Two problems: </p>
<p>(1) Some pages are  dead ends (have no out-links) </p>
<p>​    Such pages cause  importance to “leak out” </p>
<p>(2) Spider traps (all out-links are within the group) </p>
<p>​    Eventually spider traps absorb all importance</p>
<h3 id="Does-this-converge"><a href="#Does-this-converge" class="headerlink" title="Does this converge"></a>Does this converge</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224138856.png" alt=""></p>
<h3 id="Does-it-converge-to-what-we-want"><a href="#Does-it-converge-to-what-we-want" class="headerlink" title="Does it converge to what we want?"></a>Does it converge to what we want?</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224207948.png" alt=""></p>
<h3 id="Solution-to-Spider-Traps"><a href="#Solution-to-Spider-Traps" class="headerlink" title="Solution to Spider Traps"></a>Solution to Spider Traps</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224305329.png" alt=""></p>
<h3 id="Solution-to-Dead-Ends"><a href="#Solution-to-Dead-Ends" class="headerlink" title="Solution to Dead Ends"></a>Solution to Dead Ends</h3><ul>
<li>Teleports: Follow random teleport links with  total probability 1.0 from dead-ends <ul>
<li>Adjust matrix accordingly</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224421867.png" alt=""></p>
<h3 id="Why-Teleports-Solve-the-Problem"><a href="#Why-Teleports-Solve-the-Problem" class="headerlink" title="Why Teleports Solve the Problem?"></a>Why Teleports Solve the Problem?</h3><ul>
<li>Why are dead-ends and spider traps a problem  and why do teleports solve the problem? </li>
<li>Spider-traps are not a problem, but with traps  PageRank scores are not what we want <ul>
<li>Solution: Never get stuck in a spider trap by  teleporting out of it in a finite number of steps </li>
</ul>
</li>
<li>Dead-ends are a problem <ul>
<li>The matrix is not column stochastic so our initial  assumptions are not met </li>
<li>Solution: Make matrix column stochastic by always  teleporting when there is nowhere else to go</li>
</ul>
</li>
</ul>
<h3 id="Solution-Random-Teleports"><a href="#Solution-Random-Teleports" class="headerlink" title="Solution: Random Teleports"></a>Solution: Random Teleports</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224754314.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224833186.png" alt=""></p>
<h4 id="Random-Teleports-beta-0-8"><a href="#Random-Teleports-beta-0-8" class="headerlink" title="Random Teleports(beta=0.8)"></a>Random Teleports(beta=0.8)</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224910775.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224924774.png" alt=""></p>
<h3 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank solves for 𝒓 = 𝑮𝒓 and can be  efficiently computed by power iteration of the  stochastic adjacency matrix (𝑮)  </li>
<li>Adding random uniform teleportation solves  issues of dead-ends and spider-traps</li>
</ul>
<h2 id="Random-Walk-with-Restarts-and-Personalized-Pagerank"><a href="#Random-Walk-with-Restarts-and-Personalized-Pagerank" class="headerlink" title="Random Walk with Restarts and Personalized Pagerank"></a>Random Walk with Restarts and Personalized Pagerank</h2><h3 id="Example-Recommendation"><a href="#Example-Recommendation" class="headerlink" title="Example: Recommendation"></a>Example: Recommendation</h3><p>Given:  A bipartite graph representing user and item  interactions (e.g. purchase) </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225052686.png" alt=""></p>
<p>Goal: Proximity on graphs </p>
<ul>
<li>What items should we recommend to a user who  interacts with item Q? </li>
<li>Intuition: if items Q and P are interacted by similar  users, recommend P when user interacts with Q</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225134281.png" alt=""></p>
<p>Which is more related A,A’ or B,B’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225159496.png" alt=""></p>
<h3 id="Node-proximity-Measurements"><a href="#Node-proximity-Measurements" class="headerlink" title="Node proximity Measurements"></a>Node proximity Measurements</h3><p>Which is more related A,A’, B,B’ or C,C’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225227419.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225246889.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225258445.png" alt=""></p>
<h3 id="Proximity-on-Graphs"><a href="#Proximity-on-Graphs" class="headerlink" title="Proximity on Graphs"></a>Proximity on Graphs</h3><p>PageRank: </p>
<ul>
<li>Ranks nodes by “importance” </li>
<li>Teleports(传送) with uniform probability to any node in  the network </li>
</ul>
<p>Personalized PageRank: </p>
<ul>
<li>Ranks proximity of nodes to the teleport nodes 𝑺 </li>
</ul>
<p>Proximity(接近) on graphs: </p>
<ul>
<li>Q: What is most related item to Item Q? </li>
<li>Random Walks with Restarts <ul>
<li>Teleport back to the starting node: 𝑺 = {𝑸}</li>
</ul>
</li>
</ul>
<h3 id="Idea-Random-Walks"><a href="#Idea-Random-Walks" class="headerlink" title="Idea: Random Walks"></a>Idea: Random Walks</h3><ul>
<li>Idea <ul>
<li>Every node has some importance </li>
<li>Importance gets evenly split among all edges and  pushed to the neighbors: </li>
</ul>
</li>
<li>Given a set of QUERY_NODES, we simulate a  random walk: <ul>
<li>Make a step to a random neighbor and record the visit  (visit count) </li>
<li>With probability ALPHA, restart the walk at one of the  QUERY_NODES </li>
<li>The nodes with the highest visit count have highest  proximity to the QUERY_NODES</li>
</ul>
</li>
</ul>
<p>Idea: </p>
<ul>
<li>Every node has some importance <ul>
<li>Importance gets evenly split among all edges and  pushed to the neighbors </li>
<li>Given a set of QUERY NODES Q, simulate a  random walk:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230011267.png" alt=""></p>
<h3 id="Random-Walk-Algorithm"><a href="#Random-Walk-Algorithm" class="headerlink" title="Random Walk Algorithm"></a>Random Walk Algorithm</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230036155.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230058590.png" alt=""></p>
<h3 id="Benefits"><a href="#Benefits" class="headerlink" title="Benefits"></a>Benefits</h3><p>Why is this a good solution? </p>
<p>Because the “similarity” considers: </p>
<ul>
<li>Multiple connections </li>
<li>Multiple paths </li>
<li>Direct and indirect connections </li>
<li>Degree of the node</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230143054.png" alt=""></p>
<h3 id="Summary-Page-Rank-Variants"><a href="#Summary-Page-Rank-Variants" class="headerlink" title="Summary: Page Rank Variants"></a>Summary: Page Rank Variants</h3><ul>
<li><p>PageRank: </p>
<ul>
<li>Teleports to any node </li>
<li>Nodes can have the same probability of the surfer landing: 𝑺 = [0.1,0.1,0.1, 0.1,0.1,0.1, 0.1,0.1,0.1, 0.1] </li>
</ul>
</li>
<li><p>Topic-Specific PageRank aka Personalized PageRank: </p>
<ul>
<li>Teleports to a specific set of nodes </li>
<li>Nodes can have different probabilities of the surfer landing  there: 𝑺 = [0.1,0, 0,0.2, 0, 0,0.5,0,0, 0.2] </li>
</ul>
</li>
<li><p>Random Walk with Restarts: </p>
<ul>
<li>Topic-Specific PageRank where teleport is always to the same  node: 𝑺 = [0,0, 0,0, 𝟏, 0, 0, 0, 0, 0,0]</li>
</ul>
</li>
</ul>
<ul>
<li>A graph is naturally represented as a matrix </li>
<li>We defined a random walk process over the  graph <ul>
<li>Random surfer moving across the links and with  random teleportation </li>
<li>Stochastic adjacency matrix M </li>
</ul>
</li>
<li>PageRank = Limiting distribution of the surfer  location represented node importance <ul>
<li>Corresponds to the leading eigenvector of  transformed adjacency matrix M.</li>
</ul>
</li>
</ul>
<h2 id="Matrix-Factorization-and-Node-Embeddings"><a href="#Matrix-Factorization-and-Node-Embeddings" class="headerlink" title="Matrix Factorization and Node Embeddings"></a>Matrix Factorization and Node Embeddings</h2><h3 id="Embeddings-Matrix-Factorization-因式分解"><a href="#Embeddings-Matrix-Factorization-因式分解" class="headerlink" title="Embeddings Matrix Factorization(因式分解)"></a>Embeddings Matrix Factorization(因式分解)</h3><p>Recall: encoder as an embedding lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230445458.png" alt=""></p>
<h3 id="Connection-to-Matrix-Factorization"><a href="#Connection-to-Matrix-Factorization" class="headerlink" title="Connection to Matrix Factorization"></a>Connection to Matrix Factorization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230551299.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230605362.png" alt=""></p>
<h3 id="Random-Walk-based-Similarity"><a href="#Random-Walk-based-Similarity" class="headerlink" title="Random Walk-based Similarity"></a>Random Walk-based Similarity</h3><ul>
<li>DeepWalk and node2vec have a more  complex node similarity definition based on  random walks </li>
<li>DeepWalk is equivalent to matrix  factorization of the following complex matrix  expression:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230645556.png" alt=""></p>
<p><a href="https://keg.cs.tsinghua.edu.cn/jietang/publications/WSDM18-Qiu-et-al-NetMF-network-embedding.pdf" target="_blank" rel="noopener">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec, WSDM 18</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230726746.png" alt=""></p>
<p>Node2vec can also be formulated as a matrix  factorization (albeit a more complex matrix)</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>Limitations of node embeddings via matrix  factorization and random walks </p>
<ul>
<li>Cannot obtain embeddings for nodes not in the  training set</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230810157.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230825196.png" alt=""></p>
<ul>
<li>Node 1 and 11 are structurally similar – part of  one triangle, degree 2, … </li>
<li>However, they have very different embeddings. <ul>
<li>It’s unlikely that a random walk will reach  node 11 from node 1. </li>
</ul>
</li>
<li>DeepWalk and node2vec do not capture  structural similarity.</li>
<li>Cannot utilize node, edge and graph features</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230907768.png" alt=""></p>
<p>Solution to these limitations: Deep Representation  Learning and Graph Neural Networks </p>
<h3 id="Summary-5"><a href="#Summary-5" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank <ul>
<li>Measures importance of nodes in graph </li>
<li>Can be efficiently computed by power iteration of  adjacency matrix </li>
</ul>
</li>
<li>Personalized PageRank (PPR) <ul>
<li>Measures importance of nodes with respect to a  particular node or set of nodes </li>
<li>Can be efficiently computed by random walk </li>
</ul>
</li>
<li>Node embeddings based on random walks can  be expressed as matrix factorization </li>
<li>Viewing graphs as matrices plays a key role in all  above algorithms!</li>
</ul>
<h1 id="Message-Passing-and-Node-Classification"><a href="#Message-Passing-and-Node-Classification" class="headerlink" title="Message Passing and Node Classification"></a>Message Passing and Node Classification</h1><h2 id="Example-Node-Classification"><a href="#Example-Node-Classification" class="headerlink" title="Example Node Classification"></a>Example Node Classification</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225627573.png" alt=""></p>
<ul>
<li>Given labels of some nodes </li>
<li>Let’s predict labels of unlabeled nodes </li>
<li>This is called <strong>semi-supervised node classification</strong></li>
</ul>
<h3 id="Correlations-相关性-Exist-in-Networks"><a href="#Correlations-相关性-Exist-in-Networks" class="headerlink" title="Correlations(相关性) Exist in Networks"></a>Correlations(相关性) Exist in Networks</h3><ul>
<li><p>Behaviors of nodes are correlated across the  links of the network </p>
</li>
<li><p>Correlation: Nearby nodes have the same  color (belonging to the same class)</p>
</li>
<li><p>Two explanations for why behaviors of nodes  in networks are correlated:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225929813.png" alt=""></p>
<h3 id="Social-Homophily-趋同性"><a href="#Social-Homophily-趋同性" class="headerlink" title="Social Homophily(趋同性)"></a>Social Homophily(趋同性)</h3><ul>
<li>Homophily: The tendency of  individuals to associate and bond  with similar others <ul>
<li>“Birds of a feather flock together”</li>
<li>It has been observed in a vast array of  network studies, based on a variety of  attributes (e.g., age, gender,  organizational role, etc.) </li>
<li>Example: Researchers who focus on  the same research area are more likely  to establish a connection (meeting at  conferences, interacting in academic  talks, etc.)</li>
</ul>
</li>
</ul>
<p><strong>Example of homophily</strong> </p>
<ul>
<li>Online social network <ul>
<li>Nodes = people</li>
<li>Edges = friendship</li>
<li>Node color = interests  (sports, arts, etc.)</li>
</ul>
</li>
<li>People with the same  interest are more closely  connected due to  homophily</li>
</ul>
<h3 id="Social-Influence-Example"><a href="#Social-Influence-Example" class="headerlink" title="Social Influence Example"></a>Social Influence Example</h3><ul>
<li>Influence: Social connections can  influence the individual  characteristics of a person. <ul>
<li>Example: I recommend my musical  preferences to my friends, until one of  them grows to like my same favorite  genres!</li>
</ul>
</li>
</ul>
<h2 id="How-do-we-leverage-node-correlations-in-networks"><a href="#How-do-we-leverage-node-correlations-in-networks" class="headerlink" title="How do we leverage node correlations in networks?"></a>How do we leverage node correlations in networks?</h2><h3 id="Classification-with-Network-Data"><a href="#Classification-with-Network-Data" class="headerlink" title="Classification with Network Data"></a>Classification with Network Data</h3><p>How do we leverage(影响力) this correlation observed  in networks to help predict node labels?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230602159.png" alt=""></p>
<p>How do we predict the labels for the nodes in grey?</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li><p>Similar nodes are typically close together or  directly connected in the network: </p>
<ul>
<li>Guilt-by-association: If I am connected to a  node with label X, then I am likely to have  label X as well. </li>
<li>Example: Malicious/benign web page: Malicious web pages link to one another to  increase visibility, look credible, and rank  higher in search engines</li>
</ul>
</li>
<li><p>Classification label of a node v in network  may depend on: </p>
<ul>
<li>Features of v </li>
<li>Labels of the nodes in v’s neighborhood </li>
<li>Features of the nodes in v’s neighborhood</li>
</ul>
</li>
</ul>
<h3 id="Semi-supervised-Learning"><a href="#Semi-supervised-Learning" class="headerlink" title="Semi-supervised Learning"></a>Semi-supervised Learning</h3><ul>
<li><p>Formal setting: </p>
<ul>
<li>Given:  <ul>
<li>Graph </li>
<li>Few labeled nodes </li>
</ul>
</li>
<li>Find: Class (red/green) of  remaining nodes </li>
<li>Main assumption: There is  homophily in the network</li>
</ul>
</li>
<li><p>Example task:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230940679.png" alt=""></p>
<h4 id="Problem-Setting"><a href="#Problem-Setting" class="headerlink" title="Problem Setting"></a>Problem Setting</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231029875.png" alt=""></p>
<h4 id="Example-applications"><a href="#Example-applications" class="headerlink" title="Example applications"></a>Example applications</h4><ul>
<li>Many applications under this setting: <ul>
<li>Document classification  </li>
<li>Part of speech tagging  </li>
<li>Link prediction  </li>
<li>Optical character recognition  </li>
<li>Image/3D data segmentation  </li>
<li>Entity resolution in sensor networks  </li>
<li>Spam and fraud detection</li>
</ul>
</li>
</ul>
<p>We focus on semi-supervised binary node classification </p>
<p>We will introduce three approaches: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h2 id="Relational-Classification"><a href="#Relational-Classification" class="headerlink" title="Relational Classification"></a>Relational Classification</h2><h3 id="Probabilistic-Relational-Classifier"><a href="#Probabilistic-Relational-Classifier" class="headerlink" title="Probabilistic Relational Classifier"></a>Probabilistic Relational Classifier</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231427817.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231506341.png" alt=""></p>
<p>Challenges: </p>
<ul>
<li>Convergence is not guaranteed </li>
<li>Model cannot use node feature information</li>
</ul>
<h3 id="Example-Initialization"><a href="#Example-Initialization" class="headerlink" title="Example: Initialization"></a>Example: Initialization</h3><p>Initialization: </p>
<ul>
<li>All labeled nodes with their labels </li>
<li>All unlabeled nodes 0.5 (belonging to class 1 with  probability 0.5)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231641765.png" alt=""></p>
<h3 id="Example-lst-Iteration-Update-Node"><a href="#Example-lst-Iteration-Update-Node" class="headerlink" title="Example: lst Iteration, Update Node"></a>Example: lst Iteration, Update Node</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231741748.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231846430.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231924192.png" alt=""></p>
<h3 id="Example-After-1st-Iteration"><a href="#Example-After-1st-Iteration" class="headerlink" title="Example: After 1st Iteration"></a>Example: After 1st Iteration</h3><p>After Iteration 1 (a round of updates for all  unlabeled nodes)</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232015529.png" alt=""></p>
<h3 id="Example-After-2nd-Iteration"><a href="#Example-After-2nd-Iteration" class="headerlink" title="Example: After 2nd Iteration"></a>Example: After 2nd Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232051667.png" alt=""></p>
<h3 id="Example-After-3-Iteration"><a href="#Example-After-3-Iteration" class="headerlink" title="Example: After 3] Iteration"></a>Example: After 3] Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232207605.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232229830.png" alt=""></p>
<h3 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232257216.png" alt=""></p>
<h2 id="Iterative-迭代的-Classification"><a href="#Iterative-迭代的-Classification" class="headerlink" title="Iterative(迭代的) Classification"></a>Iterative(迭代的) Classification</h2><p>Relational classifier does not use node  attributes.  </p>
<p>How can one leverage them?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232406683.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232421194.png" alt=""></p>
<h3 id="Computing-the-Summary-Z-v"><a href="#Computing-the-Summary-Z-v" class="headerlink" title="Computing the Summary Z_v"></a>Computing the Summary Z_v</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232625455.png" alt=""></p>
<h3 id="Architecture-of-Iterative-Classifiers"><a href="#Architecture-of-Iterative-Classifiers" class="headerlink" title="Architecture of Iterative Classifiers"></a>Architecture of Iterative Classifiers</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232728306.png" alt=""></p>
<h3 id="Example-Web-Page-Classification"><a href="#Example-Web-Page-Classification" class="headerlink" title="Example: Web Page Classification"></a>Example: Web Page Classification</h3><ul>
<li>Input: Graph of web pages </li>
<li>Node: Web page </li>
<li>Edge: Hyper-link between web pages </li>
<li>Directed edge: a page points to another page <ul>
<li>Node features: Webpage description </li>
</ul>
</li>
<li>For simplicity, we only consider two binary features <ul>
<li>Task: Predict the topic of the webpage</li>
</ul>
</li>
</ul>
<p>Baseline: Train a classifier (e.g., linear classifier) to  classify pages based on node attributes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232938924.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232956241.png" alt=""></p>
<h3 id="Iterative-Classifier"><a href="#Iterative-Classifier" class="headerlink" title="Iterative Classifier"></a>Iterative Classifier</h3><h4 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233242445.png" alt=""></p>
<h4 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233317039.png" alt=""></p>
<h4 id="step-3-1"><a href="#step-3-1" class="headerlink" title="step 3. 1"></a>step 3. 1<img src="/images/loading.gif" data-original="../images/ML/image-20211116233349992.png" alt=""></h4><h4 id="step-3-2"><a href="#step-3-2" class="headerlink" title="step 3. 2"></a>step 3. 2<img src="/images/loading.gif" data-original="../images/ML/image-20211116233427721.png" alt=""></h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233537476.png" alt=""></p>
<h4 id="Final-Prediction"><a href="#Final-Prediction" class="headerlink" title="Final Prediction"></a>Final Prediction</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233603237.png" alt=""></p>
<h3 id="Summary-6"><a href="#Summary-6" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We talked about 2 approaches to collective  classification </li>
<li>Relational classification <ul>
<li>Iteratively update probabilities of node belonging  to a label class based on its neighbors </li>
</ul>
</li>
<li>Iterative classification <ul>
<li>Improve over collective classification to handle  attribute/feature information </li>
<li>Classify node v based on its features as well as  labels of neighbors</li>
</ul>
</li>
</ul>
<h2 id="Collective-Classification-Correct-amp-Smooth"><a href="#Collective-Classification-Correct-amp-Smooth" class="headerlink" title="Collective Classification Correct &amp; Smooth"></a>Collective Classification Correct &amp; Smooth</h2><h3 id="Correct-amp-Smooth"><a href="#Correct-amp-Smooth" class="headerlink" title="Correct &amp; Smooth"></a>Correct &amp; Smooth</h3><p><a href="https://arxiv.org/abs/2010.13993" target="_blank" rel="noopener">Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</a></p>
<p><a href="https://ogb.stanford.edu/docs/leader_nodeprop/" target="_blank" rel="noopener">OGB leaderboard</a> snapshot at Oct 1st, 2021</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233952486.png" alt=""></p>
<p>Setting: A partially labeled graph and features  over nodes.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234021971.png" alt=""></p>
<p>C&amp;S follows the three-step procedure: </p>
<ol>
<li>Train base predictor </li>
<li>Use the base predictor to predict soft labels of all nodes. </li>
<li>Post-process the predictions using graph structure to  obtain the final predictions of all nodes.</li>
</ol>
<h3 id="Train-Base-Predictor"><a href="#Train-Base-Predictor" class="headerlink" title="Train Base Predictor"></a>Train Base Predictor</h3><p>Train a base predictor that predict soft  labels (class probabilities) over all nodes. </p>
<ul>
<li>Labeled nodes are used for train/validation data. </li>
<li>Base predictor can be simple: <ul>
<li>Linear model/Multi-Layer-Perceptron(MLP) over node  features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234148551.png" alt=""></p>
<h3 id="Predict-Over-All-Nodes"><a href="#Predict-Over-All-Nodes" class="headerlink" title="Predict Over All Nodes"></a>Predict Over All Nodes</h3><p>Given a trained base predictor, we apply it  to obtain soft labels for all the nodes. </p>
<ul>
<li>We expect these soft labels to be decently accurate. </li>
<li>Can we use graph structure to post-process the  predictions to make them more accurate?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234246360.png" alt=""></p>
<h3 id="Post-process-Predictions"><a href="#Post-process-Predictions" class="headerlink" title="Post-process Predictions"></a>Post-process Predictions</h3><p>C&amp;S uses the 2-step procedure to post-process the soft predictions. </p>
<ol>
<li>Correct step</li>
<li>Smooth step</li>
</ol>
<h3 id="C-amp-S-Post-processing-Correct-Step"><a href="#C-amp-S-Post-processing-Correct-Step" class="headerlink" title="C&amp;S Post-processing: Correct Step"></a>C&amp;S Post-processing: Correct Step</h3><ul>
<li>The key idea is that we expect errors in the base  prediction to be positively correlated along  edges in the graph.  </li>
<li>In other words, an error at node u increases the  chance of a similar error at neighbors of u.  </li>
<li>Thus, we should “spread” such uncertainty over the  graph</li>
</ul>
<h3 id="Intuition-of-Correct-amp-Smooth"><a href="#Intuition-of-Correct-amp-Smooth" class="headerlink" title="Intuition of Correct &amp; Smooth"></a>Intuition of Correct &amp; Smooth</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234441693.png" alt=""></p>
<h3 id="Correct-Step"><a href="#Correct-Step" class="headerlink" title="Correct Step"></a>Correct Step</h3><ul>
<li>Compute training errors of nodes. <ul>
<li>Training error: Ground-truth label minus soft label.  Defined as 0 for unlabeled nodes.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234544537.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234836282.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234914939.png" alt=""></p>
<p><a href="https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf" target="_blank" rel="noopener">Zhu et al. ICML 2013</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234952059.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235007332.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235025205.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235042742.png" alt=""></p>
<h3 id="Smooth-Step"><a href="#Smooth-Step" class="headerlink" title="Smooth Step"></a>Smooth Step</h3><ul>
<li>Smoothen the corrected soft labels along the  edges. <ul>
<li>Assumption: Neighboring nodes tend to share the  same labels.  </li>
<li>Note: For training nodes, we use the ground-truth  hard labels instead of the soft labels.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235129283.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235142063.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235155937.png" alt=""></p>
<h3 id="Toy-Example-Summary"><a href="#Toy-Example-Summary" class="headerlink" title="Toy Example Summary"></a>Toy Example Summary</h3><p>Our toy example shows that C&amp;S successfully  improves base model performance using  graph structure.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235223544.png" alt=""></p>
<h3 id="C-amp-S-on-a-Real-world-Dataset"><a href="#C-amp-S-on-a-Real-world-Dataset" class="headerlink" title="C&amp;S on a Real-world Dataset"></a>C&amp;S on a Real-world Dataset</h3><p>C&amp;S significantly improves the performance  of the base model (MLP). </p>
<p>C&amp;S outperforms Smooth-only (no correct  step) baseline.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235256008.png" alt=""></p>
<h3 id="Summary-7"><a href="#Summary-7" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Correct &amp; Smooth (C&amp;S) uses graph structure  to post-process the soft node labels predicted  by any base model. </li>
<li><strong>Correction step</strong>: Diffuse and correct for the  training errors of the base predictor. </li>
<li><strong>Smooth step</strong>: Smoothen the prediction of the  base predictor. </li>
<li>C&amp;S achieves strong performance on semisupervised node classification</li>
</ul>
<p>We learned how to leverage correlation in  graphs to make prediction on nodes. </p>
<p>Key techniques: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h1 id="Graph-Neural-Networks"><a href="#Graph-Neural-Networks" class="headerlink" title="Graph Neural Networks"></a>Graph Neural Networks</h1><h2 id="Basics-of-Deep-Learning"><a href="#Basics-of-Deep-Learning" class="headerlink" title="Basics of Deep Learning"></a>Basics of Deep Learning</h2><h2 id="Deep-Learning-for-Graphs"><a href="#Deep-Learning-for-Graphs" class="headerlink" title="Deep Learning for Graphs"></a>Deep Learning for Graphs</h2><p>todo</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html">https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Lesson/">
                                    <span class="chip bg-color">Lesson</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-11-12T12-20-03',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="CS224W-Machine Learning with Graphs">
                        
                        <span class="card-title">CS224W-Machine Learning with Graphs</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Machine Learning with Graphs Notes
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Lesson/">
                        <span class="chip bg-color">Lesson</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/Language-Python-Lib3.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/7.jpg" class="responsive-img" alt="Python-Standard Library">
                        
                        <span class="card-title">Python-Standard Library</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Python标准库详解【3】
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">2769.6k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

